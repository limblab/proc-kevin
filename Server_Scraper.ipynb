{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Daily Log to SQL\n",
    "\n",
    "This is a file to help clean up data from the daily logs and insert them into the Limblab MySQL database. You will need to know the sesames and either be connected to the VPN or running this remotely on Shrek or Donkey to use this.\n",
    "\n",
    "\n",
    "## Required Dependencies:\n",
    "\n",
    "- sqlalchemy\n",
    "- pymysql\n",
    "- numpy\n",
    "- pandas\n",
    "\n",
    "\n",
    "### Linux specific\n",
    "You'll need to run <code> sudo apt install libmysqlclient mysql-client-core </code>\n",
    "\n",
    "### macOS specific\n",
    "You'll need to run <code> brew install mysql </code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "from os import path, system\n",
    "from sys import platform\n",
    "import glob\n",
    "from tkinter import Tk, ttk # to allow for graphical folder loading\n",
    "from Blackrock_Python_Utilities import brpylib # added an init file so it's seen as a package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background data\n",
    "\n",
    "what is the monkey's name? What directory are we going to be scraping (better to do this once per monkey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monkey data\n",
    "monkeyName = \"Greyson\"\n",
    "ccmID = \"18E2\"\n",
    "\n",
    "# directory info\n",
    "scrape_dir = '/home/kevin/Documents/L_MillerLab/data/Greyson_17L2/CerebusData'\n",
    "if not path.exists(scrape_dir):\n",
    "    print(f\"{scrape_dir} does not exist! Try again!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get a list of all threshold files\n",
    "\n",
    "We'll work with nev and plx files for now. Going to assume that all recordings have those, so we'll work off that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # List of files. Going to take a minute\n",
    "# if 'win' in platform:\n",
    "#     _ = input()\n",
    "#     file_list = system(f\"dir /B /S {scrape_dir}\\\\*.nev \")\n",
    "#     print(file_list[-1])\n",
    "# if 'nix' in platform:\n",
    "#     file_list = system(f\"ls -R {scrape_dir}/*.nev\")\n",
    "\n",
    "nev_list = glob.glob(f\"{scrape_dir}/*/*.nev\")\n",
    "plx_list = glob.glob(f\"{scrape_dir}/*/*.plx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a pandas array to keep track of the files as we go through them\n",
    "\n",
    "Not sure whether it would be better to insert an item as we go through or just insert the entire dataframe when we're done, but we'll just start with the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skipping fields that will need to be parsed from the daily log\n",
    "\n",
    "# a mix of day and session info. Not the cleanest thing, but here we are.\n",
    "session_cols = ['day_key', # The date\n",
    "                'rec_date', # when was this recorded -- we'll want to start with that\n",
    "                'rec_time', # the recording time\n",
    "                'task_id', # foreign key for the task type\n",
    "                'lab_num', # 1,2,6, cage etc\n",
    "                'duration', # in seconds\n",
    "                'numChannels', # how many channels recorded? -- this may be different from num_chans if it has two simulateous recordings\n",
    "                'hasBumps', # from the S1 jobs\n",
    "                'numTrials', # from the trial table\n",
    "                'numReward', # from the trial table\n",
    "                'numAbort', # from the trial table\n",
    "                'numFail', # from the trial table\n",
    "                'numIncomplete'] # from the trial table\n",
    "\n",
    "nev_cols = ['array_serial',\n",
    "                'nev_filename', # like it says on the box...\n",
    "                'sessions_key', # key for the associated session -- this will be incremented automatically\n",
    "                'setting_file', # should be just the filename with .ccf, but can check\n",
    "                'rec_system', # should be cerebus for the .nev files\n",
    "                'threshold_quality', # based on average firing rates, artifact rejection... maybe for later\n",
    "                'num_chans', # will be different from numChannels in session if there are multiple arrays\n",
    "                'num_units'] # number of sorted units. Meaning not 0 or 255\n",
    "\n",
    "kin_cols = ['sessions_key', # session foreign key\n",
    "                'filename', # obvio che\n",
    "                'sampling_rate', # otra vez\n",
    "                'kin_quality'] # how good is the recording? maybe look at psd or something?\n",
    "\n",
    "emg_cols = ['sessions_key',\n",
    "                'filename',\n",
    "                'rec_system', # if .ns3 should be jim baker's or tucker's. Could add rhd and tbsi support]\n",
    "                'sampling_rate', # typically 2k, but sometimes other stuff.\n",
    "                'emg_quality', # refer to Josie's code\n",
    "                'muscle_list'] # what did we record?\n",
    "\n",
    "force_cols = ['sessions_key',\n",
    "                'filename',\n",
    "                'force_labels'] # from the .nsx or whatever file\n",
    "\n",
    "\n",
    "# create the empty dataframes\n",
    "session_df = pd.DataFrame(columns=session_cols)\n",
    "nev_df = pd.DataFrame(columns=nev_cols)\n",
    "kin_df = pd.DataFrame(columns=kin_cols)\n",
    "emg_df = pd.DataFrame(columns=emg_cols)\n",
    "force_df = pd.DataFrame(columns=force_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = {'reward':0x20, 'abort':0x21, 'fail':0x22, 'incomp':0x23}\n",
    "tasks = {'CO':0x01, 'RW':0x02, 'FC':0x03, 'MG':0x06, 'WF':0x07}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now for the interesting stuff -- start ripping through each nev file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_nev, nev_file in enumerate(nev_list):\n",
    "    if i_nev == 0:\n",
    "\n",
    "        NevFileObj = brpylib.NevFile(nev_file) # initialize the Nev\n",
    "        output = NevFileObj.getdata() # load the data -- need it for the num trial info etc\n",
    "\n",
    "        # first let's see if we can find out the task\n",
    "        \n",
    "\n",
    "\n",
    "        # word counts\n",
    "        words_count = {'reward':0, 'abort':0, 'fail': 0, 'incomp':0}\n",
    "\n",
    "        # parse the date info etc\n",
    "        session_dict = dict()\n",
    "\n",
    "        session_dict['rec_date'] = NevFileObj.basic_header['TimeOrigin'].date()\n",
    "        session_dict['rec_time'] = NevFileObj.basic_header['TimeOrigin'].time()\n",
    "\n",
    "        # counting the words\n",
    "        for word,code in words.items():\n",
    "            words_count[word] += np.sum([((out & 0xFF00) >> 8)==code for out in output['digital_events']['UnparsedData']])\n",
    "    \n",
    "        # session_dict['']\n",
    "\n",
    "        if \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NevFileObj = brpylib.NevFile(nev_list[0])\n",
    "# NevFileObj.extended_headers\n",
    "output = NevFileObj.getdata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nev_list = nev_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(session_df['rec_date'] == session_dict['rec_date'])\n",
    "np.where(session_df['rec_time'] == session_dict['rec_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ii,nev in enumerate(nev_list):\n",
    "    print(f\"{ii},{nev}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "20181220_Greyson_FreeReaching_001.nev opened\n"
     ]
    }
   ],
   "source": [
    "NevFileObj = brpylib.NevFile(nev_list[0])\n",
    "output = NevFileObj.getdata()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['TimeStamps', 'InsertionReason', 'UnparsedData'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output['digital_events'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "words = {'reward':0x20, 'abort':0x21, 'fail':0x22, 'incomp':0x23}\n",
    "words_count = {'reward':0, 'abort':0, 'fail':0, 'incomp':0}\n",
    "\n",
    "for word,code in words.items():\n",
    "    words_count[word] += np.sum([((out & 0xFF00) >> 8)==code for out in output['digital_events']['UnparsedData']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique([((out & 0xFF00) >> 8) for out in output['digital_events']['UnparsedData'] if ((out & 0xFF00)>>8)<0x10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('generalDevelopment')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "6255548a5b2d2cac3262c32979492d3f22144548184fa8e1a26df246eb3f6dca"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
