{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM decoding exploration\n",
    "\n",
    "Going to be looking at using LSTMs (with potentially some changes to the cost function) to decode EMGs from cortical data. This is all based off work from Steph and Josh.\n",
    "\n",
    "\n",
    "Going to start with the old Jango data, then update from there as necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import loadmat\n",
    "from scipy.optimize import least_squares\n",
    "from matplotlib import pyplot as plt\n",
    "# import ipympl\n",
    "\n",
    "\n",
    "# we'll use ridge regression as a comparisson\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn import metrics\n",
    "\n",
    "from tkinter import Tk\n",
    "from tkinter import filedialog as fd # just so I don't have to repeatedly manually enter filenames\n",
    "\n",
    "# and tf stuff\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import backend as K # this was in Josh's version. Not sure why can't use numpy\n",
    "\n",
    "# datetime stuff for logs\n",
    "from datetime import datetime as dt\n",
    "\n",
    "\n",
    "# utility functions that I moved to the LSTM_utils.py file\n",
    "from LSTM_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "import ipympl\n",
    "# %matplotlib qt5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# request the filename\n",
    "root = Tk()\n",
    "mat_fn = fd.askopenfilename(master=root,filetypes=[('matlab data','*.mat')])\n",
    "root.destroy()\n",
    "\n",
    "data = loadmat(mat_fn)\n",
    "\n",
    "# Training\n",
    "Iso_train_timestamps, Iso_train_firing, Iso_train_EMG, _, _, = load_josh_mat(data['IsoTrain'])\n",
    "Spr_train_timestamps, Spr_train_firing, Spr_train_EMG, _, _, = load_josh_mat(data['SprTrain'])\n",
    "Mov_train_timestamps, Mov_train_firing, Mov_train_EMG, _, _, = load_josh_mat(data['WmTrain'])\n",
    "\n",
    "# Testing\n",
    "Iso_test_timestamps, Iso_test_firing, Iso_test_EMG, _, _, = load_josh_mat(data['IsoTest'])\n",
    "Spr_test_timestamps, Spr_test_firing, Spr_test_EMG, _, _, = load_josh_mat(data['SprTest'])\n",
    "Mov_test_timestamps, Mov_test_firing, Mov_test_EMG, _, _, = load_josh_mat(data['WmTest'])\n",
    "\n",
    "\n",
    "# EMG names -- makes things easier later on\n",
    "EMG_name = Iso_test_EMG.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize the data\n",
    "\n",
    "Plot out some good information on the max and variances of each muscle. Should also look at something for the cortex, maybe depth of modulation or avg firing rates?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bar plots of representative values (max and 95th pctl) of different EMG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------\n",
    "# Max EMG values bar plot\n",
    "\n",
    "fig_emg_max, ax_emg_max = plt.subplots()\n",
    "i_muscles = np.arange(Mov_train_EMG.shape[1]) # indexing on the x axis\n",
    "bar_width = .25\n",
    "\n",
    "\n",
    "ax_emg_max.bar(i_muscles, np.max(Mov_train_EMG,axis=0), width = bar_width, label='Movement')\n",
    "ax_emg_max.bar(i_muscles+bar_width, np.max(Iso_train_EMG, axis=0), width = bar_width, label='Isometric')\n",
    "ax_emg_max.bar(i_muscles+bar_width*2, np.max(Spr_train_EMG, axis=0), width = bar_width, label='Spring')\n",
    "\n",
    "ax_emg_max.set_xticks(i_muscles+bar_width)\n",
    "ax_emg_max.set_xticklabels(Mov_train_EMG.columns)\n",
    "\n",
    "fig_emg_max.show()\n",
    "_ = ax_emg_max.legend()\n",
    "\n",
    "ax_emg_max.set_xlabel('Muscle')\n",
    "ax_emg_max.set_ylabel('Max Value')\n",
    "\n",
    "# For each bar in the chart, add a text label.\n",
    "for bar in ax_emg_max.patches:\n",
    "    # The text annotation for each bar should be its height.\n",
    "    bar_value = bar.get_height()\n",
    "    # Format the text with commas to separate thousands. You can do\n",
    "    # any type of formatting here though.\n",
    "    text = f'{bar_value:.02f}'\n",
    "    # This will give the middle of each bar on the x-axis.\n",
    "    text_x = bar.get_x() + bar.get_width() / 2\n",
    "    # get_y() is where the bar starts so we add the height to it.\n",
    "    text_y = np.max([bar.get_y() + bar_value, 0.01]) # keep it from going too far below zero, and disappearing\n",
    "    # If we want the text to be the same color as the bar, we can\n",
    "    # get the color like so:\n",
    "    bar_color = bar.get_facecolor()\n",
    "    # If you want a consistent color, you can just set it as a constant, e.g. #222222\n",
    "    ax_emg_max.text(text_x, text_y, text, ha='center', va='bottom', color=bar_color,\n",
    "            size=12)\n",
    "    \n",
    "for spine in ['right','top','bottom','left']:\n",
    "    ax_emg_max.spines[spine].set_visible(False)\n",
    "\n",
    "ax_emg_max.set_title('Maximum EMG Value')\n",
    "\n",
    "# --------------------------------------------\n",
    "# 95th percentile\n",
    "fig_emg_95, ax_emg_95 = plt.subplots()\n",
    "i_muscles = np.arange(Mov_train_EMG.shape[1]) # indexing on the x axis\n",
    "bar_width = .25\n",
    "\n",
    "\n",
    "ax_emg_95.bar(i_muscles, np.percentile(Mov_train_EMG, 95,axis=0), width = bar_width, label='Movement')\n",
    "ax_emg_95.bar(i_muscles+bar_width, np.percentile(Iso_train_EMG, 95, axis=0), width = bar_width, label='Isometric')\n",
    "ax_emg_95.bar(i_muscles+2*bar_width, np.percentile(Spr_train_EMG, 95, axis=0), width = bar_width, label='Spring')\n",
    "\n",
    "ax_emg_95.set_xticks(i_muscles+bar_width)\n",
    "ax_emg_95.set_xticklabels(Mov_train_EMG.columns)\n",
    "\n",
    "# fig_emg_95.show()\n",
    "_ = ax_emg_95.legend()\n",
    "\n",
    "ax_emg_95.set_xlabel('Muscle')\n",
    "ax_emg_95.set_ylabel('95th Percentile')\n",
    "\n",
    "# For each bar in the chart, add a text label.\n",
    "for bar in ax_emg_95.patches:\n",
    "    # The text annotation for each bar should be its height.\n",
    "    bar_value = bar.get_height()\n",
    "    # Format the text with commas to separate thousands. You can do\n",
    "    # any type of formatting here though.\n",
    "    text = f'{bar_value:.02f}'\n",
    "    # This will give the middle of each bar on the x-axis.\n",
    "    text_x = bar.get_x() + bar.get_width() / 2\n",
    "    # get_y() is where the bar starts so we add the height to it.\n",
    "    text_y = np.max([bar.get_y() + bar_value, 0.01]) # keep it from going too far below zero, and disappearing\n",
    "    # If we want the text to be the same color as the bar, we can\n",
    "    # get the color like so:\n",
    "    bar_color = bar.get_facecolor()\n",
    "    # If you want a consistent color, you can just set it as a constant, e.g. #222222\n",
    "    ax_emg_95.text(text_x, text_y, text, ha='center', va='bottom', color=bar_color,\n",
    "            size=12)\n",
    "\n",
    "\n",
    "for spine in ['right','top','bottom','left']:\n",
    "    ax_emg_95.spines[spine].set_visible(False)\n",
    "\n",
    "ax_emg_95.set_title('95th Percentile of EMG')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing mean firing rates of different conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_cort, ax_cort = plt.subplots(ncols=3)\n",
    "\n",
    "Wm_means = np.mean(Mov_train_firing, axis=0)\n",
    "Iso_means = np.mean(Iso_train_firing, axis=0)\n",
    "Spr_means = np.mean(Spr_train_firing, axis=0)\n",
    "\n",
    "\n",
    "\n",
    "# scatters between mean firing rates\n",
    "ax_cort[0].scatter(Wm_means, Iso_means, s=2)\n",
    "ax_cort[0].plot([0,40],[0,40],c='k', alpha=.3)\n",
    "ax_cort[1].scatter(Wm_means, Spr_means, s=2)\n",
    "ax_cort[1].plot([0,40],[0,40],c='k', alpha=.3)\n",
    "ax_cort[2].scatter(Iso_means, Spr_means, s=2)\n",
    "ax_cort[2].plot([0,40],[0,40],c='k', alpha=.3)\n",
    "\n",
    "\n",
    "# x and y labels\n",
    "ax_cort[0].set_xlabel('Movement')\n",
    "ax_cort[0].set_ylabel('Isometric')\n",
    "ax_cort[1].set_xlabel('Movement')\n",
    "ax_cort[1].set_ylabel('Spring')\n",
    "ax_cort[2].set_xlabel('Isometric')\n",
    "ax_cort[2].set_ylabel('Spring')\n",
    "\n",
    "# making the axes square and removing the spines\n",
    "for axis in ax_cort:\n",
    "    axis.set_aspect('equal',adjustable='box')\n",
    "    for spine in ['right','top','bottom','left']:\n",
    "        ax_emg_95.spines[spine].set_visible(False)\n",
    "    axis.set_title('Mean Firing Rates')\n",
    "\n",
    "\n",
    "fig_cort.set_label('Compared Mean Firing Rates across conditions')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same with the variance of the firing rates (thinking depth of modulation sort of thing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_cort, ax_cort = plt.subplots(ncols=3)\n",
    "\n",
    "Wm_vars = np.var(Mov_train_firing, axis=0)\n",
    "Iso_vars = np.var(Iso_train_firing, axis=0)\n",
    "Spr_vars = np.var(Spr_train_firing, axis=0)\n",
    "\n",
    "\n",
    "\n",
    "# scatters between var firing rates\n",
    "ax_cort[0].scatter(Wm_vars, Iso_vars, s=2)\n",
    "ax_cort[1].scatter(Wm_vars, Spr_vars, s=2)\n",
    "ax_cort[2].scatter(Iso_vars, Spr_vars, s=2)\n",
    "\n",
    "\n",
    "# x and y labels\n",
    "ax_cort[0].set_xlabel('Movement')\n",
    "ax_cort[0].set_ylabel('Isometric')\n",
    "ax_cort[1].set_xlabel('Movement')\n",
    "ax_cort[1].set_ylabel('Spring')\n",
    "ax_cort[2].set_xlabel('Isometric')\n",
    "ax_cort[2].set_ylabel('Spring')\n",
    "\n",
    "# making the axes square and removing the spines\n",
    "for axis in ax_cort:\n",
    "    axis.set_aspect('equal',adjustable='box')\n",
    "    max_lim = np.max([axis.get_xlim()[1],axis.get_ylim()[1]])\n",
    "    min_lim = np.min([axis.get_xlim()[0],axis.get_ylim()[1]])\n",
    "    axis.set_xlim([min_lim, max_lim])\n",
    "    axis.set_ylim([min_lim, max_lim])\n",
    "    for spine in ['right','top','bottom','left']:\n",
    "        axis.spines[spine].set_visible(False)\n",
    "    axis.set_title('Variance of Firing Rates')\n",
    "    axis.plot([min_lim, max_lim],[min_lim, max_lim],c='k', alpha=.3)\n",
    "\n",
    "fig_cort.set_label('Compared var Firing Rates across conditions')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model building \n",
    "Look through a couple of different model types, look to see how they are trained\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear with Static Non-linearity\n",
    "\n",
    "Using the lab default -- build a wiener filter, fit it, then fit with a static polynomial on top of the form\n",
    "\n",
    "$Ax^2 + Bx + C$\n",
    "\n",
    "Where $x$ is the original EMG prediction, and the output is the new EMG prediction\n",
    "\n",
    "Alternatively, I have also allowed to predict using an exponential activation \n",
    "\n",
    "$Ae^{Bx} + C$\n",
    "\n",
    "Also giving the options for a sigmoid\n",
    "\n",
    "\n",
    "**Starting with defining our nonlinearity methods**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using scipy's least_squares:\n",
    "def non_linearity(p, y_pred, nonlinear_type):\n",
    "    if nonlinear_type == 'poly':\n",
    "        return p[0] + p[1]*y_pred + p[2]*y_pred**2\n",
    "    elif nonlinear_type == 'exponential':\n",
    "        return p[0]*np.exp(p[1]*y_pred) + p[2]\n",
    "    elif nonlinear_type == 'sigmoid':\n",
    "        return p[1] * 1/(1 + np.exp(-10*(y_pred-p[0])))\n",
    "\n",
    "def non_linearity_residuals(p, y_pred, y_act, nonlinear_type):\n",
    "    if nonlinear_type == 'poly':\n",
    "        return y_act - (p[0] + p[1]*y_pred + p[2]*y_pred**2)\n",
    "    elif nonlinear_type == 'exponential':\n",
    "        return y_act - (p[0]*np.exp(p[1]*y_pred) + p[2])\n",
    "    elif nonlinear_type == 'sigmoid':\n",
    "        return y_act - (p[1] * 1/(1 + np.exp(-10*(y_pred-p[0]))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next a function that compares Wiener filter models with Wiener cascades, reports the VAF (Cooefficient of Determination) and gives plots for the validation predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a function that we can just call multiple times, so then we can just quickly run through all of the different combinations\n",
    "\n",
    "\n",
    "def basic_decoder_comparison(train_firing, train_EMG, retrain_firing, retrain_EMG, test_firing, test_EMG, test_timestamps, nonlinear_type, save_plot=True):\n",
    "    wiener_input = pd.DataFrame() # empty dataframe\n",
    "    n_lags = 10 # number of lags\n",
    "    for ii in np.arange(n_lags): # create the lagged dataframe\n",
    "        col_dict = dict(zip(train_firing.columns, train_firing.columns+f\"_lag{ii}\"))\n",
    "        wiener_input = wiener_input.join(train_firing.shift(-ii, fill_value=0).rename(columns=col_dict), how='outer')\n",
    "\n",
    "    wiener_test = pd.DataFrame() # empty dataframe\n",
    "    for ii in np.arange(n_lags): # create the lagged dataframe\n",
    "        col_dict = dict(zip(test_firing.columns, test_firing.columns+f\"_lag{ii}\"))\n",
    "        wiener_test = wiener_test.join(test_firing.shift(-ii, fill_value=0).rename(columns=col_dict), how='outer')\n",
    "        \n",
    "    wiener_retrain = pd.DataFrame() # empty dataframe\n",
    "    for ii in np.arange(n_lags): # create the lagged dataframe\n",
    "        col_dict = dict(zip(retrain_firing.columns, retrain_firing.columns+f\"_lag{ii}\"))\n",
    "        wiener_retrain = wiener_retrain.join(retrain_firing.shift(-ii, fill_value=0).rename(columns=col_dict), how='outer')\n",
    "\n",
    "\n",
    "\n",
    "    if nonlinear_type == 'poly':\n",
    "        init_pred = [.1, .1, .1]\n",
    "    elif nonlinear_type == 'exponential':\n",
    "        init_pred = [1, .1, .2]\n",
    "    elif nonlinear_type == 'sigmoid':\n",
    "        init_pred = [.1, .5]\n",
    "\n",
    "    mdl_A = linear_model.LinearRegression(fit_intercept=True)\n",
    "    mdl_B = {} # a dictionary of numpy polynomials. Probably a better way to do this, maybe Xuan's method... oh well\n",
    "\n",
    "    mdl_A.fit(wiener_input, train_EMG)# fit the first model\n",
    "    prefit_EMG = mdl_A.predict(wiener_input) # get the initially predicted EMGs\n",
    "    retrain_pred = mdl_A.predict(wiener_retrain) # from a training set on a separate condition -- to properly hold out test data\n",
    "    prefit_VAF = metrics.explained_variance_score(train_EMG, prefit_EMG, multioutput='raw_values')\n",
    "    nonlin_EMG = np.zeros(prefit_EMG.shape)\n",
    "\n",
    "    print('Training Results\\n')\n",
    "\n",
    "    for ii in np.arange(len(train_EMG.columns)):\n",
    "        muscle = train_EMG.columns[ii]\n",
    "        mdl_B[muscle] = least_squares(non_linearity_residuals, init_pred, args=(prefit_EMG[:,ii], train_EMG.iloc[:,ii].to_numpy(), nonlinear_type)).x\n",
    "        # print('--------------------------------------------------------')\n",
    "        print(muscle)\n",
    "        print(f\"\\tLinear VAF: {prefit_VAF[ii]:.03f}\")\n",
    "        nonlin_EMG[:,ii] = non_linearity(mdl_B[muscle],(prefit_EMG[:,ii]), nonlinear_type)\n",
    "        print(f\"\\tNonLinear VAF: {metrics.explained_variance_score(train_EMG.iloc[:,ii],nonlin_EMG[:,ii]):.03f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # predicting the test set\n",
    "    prefit_test = mdl_A.predict(wiener_test)\n",
    "    prefit_test_VAF = metrics.explained_variance_score(test_EMG, prefit_test, multioutput='raw_values')\n",
    "    nonlin_test = np.zeros(prefit_test.shape)\n",
    "    nonlin_within_test = np.zeros(prefit_test.shape)\n",
    "    nonlin_VAF = np.zeros(prefit_test_VAF.shape)\n",
    "    nonlin_within_VAF = np.zeros(prefit_test_VAF.shape)\n",
    "    mdl_C = {} # for a separate non-linearity, built for the second condition.\n",
    "\n",
    "    print('\\n------------------------------------------------------------\\n')\n",
    "    print('Testing Results\\n')\n",
    "    for ii in np.arange(len(train_EMG.columns)):\n",
    "        muscle = test_EMG.columns[ii]\n",
    "        mdl_C[muscle] = least_squares(non_linearity_residuals, init_pred, args=(retrain_pred[:,ii], retrain_EMG.iloc[:,ii].to_numpy(), nonlinear_type)).x\n",
    "        # print('--------------------------------------------------------')\n",
    "        print(muscle)\n",
    "        print(f\"\\tLinear VAF: {prefit_test_VAF[ii]:.03f}\")\n",
    "        nonlin_test[:,ii] = non_linearity(mdl_B[muscle],(prefit_test[:,ii]), nonlinear_type)\n",
    "        nonlin_within_test[:,ii] = non_linearity(mdl_C[muscle],(prefit_test[:,ii]), nonlinear_type)\n",
    "        nonlin_VAF[ii] = metrics.explained_variance_score(test_EMG.iloc[:,ii],nonlin_test[:,ii])\n",
    "        nonlin_within_VAF[ii] = metrics.explained_variance_score(test_EMG.iloc[:,ii],nonlin_within_test[:,ii])\n",
    "        print(f\"\\tPre-built Nonlinearity VAF: {nonlin_VAF[ii]:.03f}\")\n",
    "        print(f\"\\tRe-built Nonlinearity VAF: {nonlin_within_VAF[ii]:.03f}\")\n",
    "\n",
    "    # Plotting the test data -- so that we can see how  the non-linearities act between types\n",
    "    n_rows = int(np.ceil(np.sqrt(len(train_EMG.columns))))\n",
    "    fig_nl_test, ax_nl_test = plt.subplots(nrows=n_rows, ncols=n_rows, sharex=True, constrained_layout=True)\n",
    "\n",
    "    for muscle_ii in np.arange(len(train_EMG.columns)):\n",
    "        row_i = int(muscle_ii//n_rows)\n",
    "        col_i = int(muscle_ii%n_rows)\n",
    "        ax_nl_test[row_i,col_i].plot(test_timestamps, test_EMG.iloc[:,muscle_ii], label='Recorded')\n",
    "        ax_nl_test[row_i,col_i].plot(test_timestamps,prefit_test[:,muscle_ii], label=f'Linear VAF: {prefit_test_VAF[muscle_ii]:.03f}')\n",
    "        ax_nl_test[row_i,col_i].plot(test_timestamps,nonlin_test[:,muscle_ii], label=f'NonLin VAF: {nonlin_VAF[muscle_ii]:.03f}')\n",
    "        ax_nl_test[row_i,col_i].plot(test_timestamps,nonlin_within_test[:,muscle_ii], label=f'Rebuilt NonLin VAF: {nonlin_within_VAF[muscle_ii]:.03f}')\n",
    "        ax_nl_test[row_i,col_i].set_title(f\"{test_EMG.columns[muscle_ii]}\")\n",
    "        ax_nl_test[row_i,col_i].set_xlabel(f\"Time (s)\")\n",
    "        ax_nl_test[row_i,col_i].set_ylabel(\"EMG envelope\")\n",
    "        \n",
    "        _ = ax_nl_test[row_i,col_i].legend()\n",
    "\n",
    "        # turn off the spines\n",
    "        for spine in ['right','top','bottom','left']:\n",
    "            ax_nl_test[row_i,col_i].spines[spine].set_visible(False)\n",
    "            \n",
    "    if save_plot:\n",
    "        fig_nl_test.savefig('Wiener_Cascade_Comparison.svg')\n",
    "\n",
    "    # let's also plot the VAFs in a clean manner so that it's easy to compare\n",
    "    fig_vaf, ax_vaf = plt.subplots()\n",
    "    i_muscles = np.arange(len(test_EMG.columns)) # indexing on the x axis\n",
    "    bar_width = .25\n",
    "\n",
    "    ax_vaf.bar(i_muscles, prefit_test_VAF, width = bar_width, label='Linear')\n",
    "    ax_vaf.bar(i_muscles + bar_width, nonlin_VAF, width = bar_width, label='Nonlinear')\n",
    "    ax_vaf.bar(i_muscles + 2*bar_width, nonlin_within_VAF, width = bar_width, label='Rebuilt Nonlinear')\n",
    "\n",
    "    ax_vaf.set_xticks(i_muscles + 1*bar_width)\n",
    "    ax_vaf.set_xticklabels(test_EMG.columns)\n",
    "\n",
    "    ax_vaf.set_ylim([-.05, 1.05])\n",
    "    ax_vaf.set_xlabel('Muscle')\n",
    "    ax_vaf.set_ylabel('Coefficient of Determination')\n",
    "\n",
    "    ax_vaf.legend()\n",
    "\n",
    "    # For each bar in the chart, add a text label.\n",
    "    for bar in ax_vaf.patches:\n",
    "        # The text annotation for each bar should be its height.\n",
    "        bar_value = bar.get_height()\n",
    "        # Format the text with commas to separate thousands. You can do\n",
    "        # any type of formatting here though.\n",
    "        text = f'{bar_value:.02f}'\n",
    "        # This will give the middle of each bar on the x-axis.\n",
    "        text_x = bar.get_x() + bar.get_width() / 2\n",
    "        # get_y() is where the bar starts so we add the height to it.\n",
    "        text_y = np.max([bar.get_y() + bar_value, 0.01]) # keep it from going too far below zero, and disappearing\n",
    "        # If we want the text to be the same color as the bar, we can\n",
    "        # get the color like so:\n",
    "        bar_color = bar.get_facecolor()\n",
    "        # If you want a consistent color, you can just set it as a constant, e.g. #222222\n",
    "        ax_vaf.text(text_x, text_y, text, ha='center', va='bottom', color=bar_color,\n",
    "                size=12)\n",
    "\n",
    "    # turn off the spines\n",
    "    for spine in ['right','top','bottom','left']:\n",
    "        ax_vaf.spines[spine].set_visible(False)\n",
    "\n",
    "\n",
    "    if save_plot:\n",
    "        fig_vaf.savefig('Wiener_VAF.svg')\n",
    "\n",
    "    return nonlin_EMG\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_comparisons(train_firing_dict:dict, train_EMG_dict:dict, \n",
    "        test_firing_dict:dict, test_EMG_dict:dict, EMG_name, \n",
    "        plot_sig_flag:bool=False, plot_VAF_flag:bool = True, \n",
    "        return_VAF_flag:bool = False):\n",
    "    # hyper params\n",
    "    layer_0_units = 300\n",
    "    drop_in = .25     # input dropout percentage for LSTM layer\n",
    "    drop_rec = 0    # recurrent dropout for LSTM\n",
    "    drop_lay = .15    # dropout layer?\n",
    "\n",
    "\n",
    "    # append the variance to the EMG values\n",
    "    n_EMGs = len(EMG_name)\n",
    "    seq_len = train_firing_dict['Combined'].shape[1] # num of lags\n",
    "    n_neurons = train_firing_dict['Combined'].shape[2]\n",
    "\n",
    "    # pull out the \"Combined\" conditions for training\n",
    "    train_i = train_firing_dict['Combined']\n",
    "    train_o = train_EMG_dict['Combined']\n",
    "\n",
    "        # Set up the LSTMs\n",
    "    mdl = tf.keras.models.Sequential()\n",
    "\n",
    "    mdl.add(tf.keras.layers.LSTM(layer_0_units, input_shape = (seq_len,n_neurons), dropout=drop_in, recurrent_dropout=drop_rec))\n",
    "    if drop_lay:\n",
    "        mdl.add(tf.keras.layers.Dropout(drop_lay)) # dropout layer if wanted\n",
    "    mdl.add(tf.keras.layers.Dense(n_EMGs)) # try with linear -- how does it compare?\n",
    "    mdl.compile(loss='mse', optimizer='rmsprop', metrics=['MeanAbsoluteError'])\n",
    "\n",
    "    mdl.fit(train_i, train_o, epochs=50, verbose=False)\n",
    "\n",
    "    train_preds = {}\n",
    "    train_VAFs = {}\n",
    "    test_preds = {}\n",
    "    test_VAFs = {}\n",
    "\n",
    "    for cond in train_firing_dict.keys():\n",
    "        train_preds[cond] = mdl.predict(train_firing_dict[cond])\n",
    "        train_VAFs[cond] = metrics.r2_score(train_EMG_dict[cond][:,:n_EMGs], train_preds[cond][:,:n_EMGs], multioutput='raw_values')\n",
    "\n",
    "    for cond in test_firing_dict.keys():\n",
    "        if cond != 'Combined': # don't really care about the \"combined\" test case\n",
    "            test_preds[cond] = mdl.predict(test_firing_dict[cond])\n",
    "            test_VAFs[cond] = metrics.r2_score(test_EMG_dict[cond][:,:n_EMGs], test_preds[cond][:,:n_EMGs], multioutput='raw_values')\n",
    "\n",
    "\n",
    "    print('----------------------------------------')\n",
    "    for ii_name, name in enumerate(EMG_name):\n",
    "        print(name)\n",
    "        for in_name, in_vaf in train_VAFs.items():\n",
    "            print(f\"\\tTrain VAF for {in_name}: {in_vaf[ii_name]}\")\n",
    "        for out_name,out_vaf in test_VAFs.items():\n",
    "            print(f\"\\tTest VAF for {out_name}: {out_vaf[ii_name]}\")\n",
    "\n",
    "    if plot_sig_flag:\n",
    "        plot_rec_pred(train_EMG_dict, train_preds, EMG_name, train_VAFs, title_append = 'training set')\n",
    "        plot_rec_pred(test_EMG_dict, test_preds, EMG_name, test_VAFs, title_append = 'testing set')\n",
    "\n",
    "    if plot_VAF_flag:\n",
    "        plot_VAFs(train_VAFs, test_VAFs, EMG_name, sup_title='Vanilla LSTM')\n",
    "\n",
    "    if return_VAF_flag:\n",
    "        return train_VAFs, test_VAFs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Custom Loss functions\n",
    "\n",
    "First the weighted loss function. This one calculates the MSE, but weights the value for each point in time by the variance of that particular task. This balances the training so that the model is able to train for conditions with different EMG ranges (the whole idea behind our system...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weight the losses by the std of that particular range in time and muscle.\n",
    "# for hybrid decoders\n",
    "def hybrid_weight_loss(target, pred):\n",
    "    # inputs: \n",
    "    #         target is the recorded data, plus the weights since this needs to be callable by tf\n",
    "    #                First half of the columns of the data will be EMG, second half will be the weights\n",
    "    #         pred   is the current prediction values\n",
    "    num_targets = K.shape(target)[1]//2 # number of cols / 2\n",
    "    err = (target[:, :num_targets] - pred[:,:num_targets]) # subtract the values\n",
    "    se = tf.divide(K.square(err), target[:,num_targets:]) # multiply the square error by the gains\n",
    "    mse = K.mean(se, axis=-1)\n",
    "#     tf.print(f\"Error Shape: {mse.shape}\")\n",
    "    \n",
    "    return mse\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_across_weighted(train_firing_dict: dict, train_EMG_orig: dict,\n",
    "        train_var_dict: dict, test_firing_dict: dict, test_EMG_dict: dict, \n",
    "        EMG_name, plot_sig_flag:bool=False, plot_VAF_flag:bool=True,\n",
    "        return_VAF_flag:bool = False):\n",
    "    # hyper params\n",
    "    layer_0_units = 300\n",
    "    drop_in = .25     # input dropout percentage for LSTM layer\n",
    "    drop_rec = 0    # recurrent dropout for LSTM\n",
    "    drop_lay = .15    # dropout layer?\n",
    "\n",
    "\n",
    "    # append the variance to the EMG values\n",
    "    n_EMGs = len(EMG_name)\n",
    "    seq_len = train_firing_dict['Combined'].shape[1] # num of lags\n",
    "    n_neurons = train_firing_dict['Combined'].shape[2]\n",
    "    train_EMG_dict = {}\n",
    "    for ii_cond, cond in enumerate(train_EMG_orig.keys()):\n",
    "        train_EMG_dict[cond] = train_EMG_orig[cond].copy()\n",
    "        train_EMG_dict[cond] = np.append(train_EMG_dict[cond], train_var_dict[cond], axis=1)\n",
    "\n",
    "    # pull out the \"Combined\" conditions for training\n",
    "    train_i = train_firing_dict['Combined']\n",
    "    train_o = train_EMG_dict['Combined']\n",
    "\n",
    "        # Set up the LSTMs\n",
    "    mdl = tf.keras.models.Sequential()\n",
    "\n",
    "    mdl.add(tf.keras.layers.LSTM(layer_0_units, input_shape = (seq_len,n_neurons), dropout=drop_in, recurrent_dropout=drop_rec))\n",
    "    if drop_lay:\n",
    "        mdl.add(tf.keras.layers.Dropout(drop_lay)) # dropout layer if wanted\n",
    "    mdl.add(tf.keras.layers.Dense(n_EMGs*2)) # try with linear -- how does it compare?\n",
    "    mdl.compile(loss=hybrid_weight_loss, optimizer='rmsprop', metrics=['MeanAbsoluteError'])\n",
    "\n",
    "    mdl.fit(train_i, train_o, epochs=50, verbose=False)\n",
    "\n",
    "    train_preds = {}\n",
    "    train_VAFs = {}\n",
    "    test_preds = {}\n",
    "    test_VAFs = {}\n",
    "\n",
    "    for cond in train_firing_dict.keys():\n",
    "        train_preds[cond] = mdl.predict(train_firing_dict[cond])\n",
    "        train_VAFs[cond] = metrics.r2_score(train_EMG_dict[cond][:,:n_EMGs], train_preds[cond][:,:n_EMGs], multioutput='raw_values')\n",
    "\n",
    "    for cond in test_firing_dict.keys():\n",
    "        if cond != 'Combined': # don't really care about the \"combined\" test case\n",
    "            test_preds[cond] = mdl.predict(test_firing_dict[cond])\n",
    "            test_VAFs[cond] = metrics.r2_score(test_EMG_dict[cond][:,:n_EMGs], test_preds[cond][:,:n_EMGs], multioutput='raw_values')\n",
    "\n",
    "\n",
    "    print('----------------------------------------')\n",
    "    for ii_name, name in enumerate(EMG_name):\n",
    "        print(name)\n",
    "        for in_name, in_vaf in train_VAFs.items():\n",
    "            print(f\"\\tTrain VAF for {in_name}: {in_vaf[ii_name]}\")\n",
    "        for out_name,out_vaf in test_VAFs.items():\n",
    "            print(f\"\\tTest VAF for {out_name}: {out_vaf[ii_name]}\")\n",
    "\n",
    "    if plot_sig_flag:\n",
    "        plot_rec_pred(train_EMG_dict, train_preds, EMG_name, train_VAFs, title_append = 'training set')\n",
    "        plot_rec_pred(test_EMG_dict, test_preds, EMG_name, test_VAFs, title_append = 'testing set')\n",
    "\n",
    "    if plot_VAF_flag:\n",
    "        plot_VAFs(train_VAFs, test_VAFs, EMG_name, sup_title = f'LSTM with weighting')\n",
    "\n",
    "    if return_VAF_flag:\n",
    "        return train_VAFs, test_VAFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_grid_search(firing, EMG, n_iter = 150, n_fold = 10, n_epochs = 20, unit_range = [100, 400], drop_in_range = [0,.5], drop_rec_range = [0,.5], drop_lay_range = [0,.5], seq_range=[5,20], plot=True):\n",
    "    # Runs a monte-carlo style grid search on hyper parameters\n",
    "    # It will run mfxval, so there is no need for a separate training group\n",
    "    #\n",
    "    #  This will allow me to compare the number of lstm units, drop percentages,\n",
    "    #  batch and sequence sizes, etc.\n",
    "    \n",
    "    EMG_names = EMG.columns\n",
    "    cols = [f\"{name}_train_VAF\" for name in EMG_names]\n",
    "    cols += [f'{name}_test_VAF' for name in EMG_names]\n",
    "    cols += ['n_units','drop_in','drop_rec','drop_lay','seq_len']\n",
    "    log = pd.DataFrame(columns=cols)\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir='./logs/LSTM_exploration', histogram_freq=1)\n",
    "\n",
    "    \n",
    "    n_neurons = firing.shape[1] # number of neurons\n",
    "    n_EMGs = EMG.shape[1]\n",
    "    \n",
    "    # get the indices of the folds\n",
    "    kf = KFold(n_splits=n_fold, random_state=None, shuffle=False) # working in chunks, not random indices\n",
    "#     train_idx,test_idx = kf.split(firing) # get the indices. Won't split until later, since we will need to set up the sequences each round\n",
    "    \n",
    "    # intiialize the random number generator for the monte carlo\n",
    "    rng = np.random.default_rng()\n",
    "    \n",
    "    for iter in np.arange(n_iter):\n",
    "        layer_0_units = rng.integers(unit_range[0],unit_range[1])\n",
    "        drop_in = rng.uniform(drop_in_range[0], drop_in_range[1])\n",
    "        drop_rec = rng.uniform(drop_rec_range[0], drop_rec_range[1])\n",
    "        drop_lay = rng.uniform(drop_lay_range[0], drop_lay_range[1])\n",
    "        seq_len = rng.integers(seq_range[0], seq_range[1])\n",
    "        \n",
    "        rnn_i = np.ndarray((firing.shape[0], seq_len, firing.shape[1]))\n",
    "        for ii in np.arange(seq_len):\n",
    "            rnn_i[:,ii,:] = firing.shift(-ii, fill_value=0).to_numpy()\n",
    "        \n",
    "        \n",
    "        train_VAFs = np.zeros((n_fold, n_EMGs))\n",
    "        test_VAFs = np.zeros((n_fold, n_EMGs))\n",
    "        \n",
    "        log_entry = {'n_units':layer_0_units, 'drop_in':drop_in, 'drop_rec':drop_rec,\\\n",
    "                        'drop_lay':drop_lay, 'seq_len':seq_len}\n",
    "        \n",
    "        fold_idx = 0\n",
    "        for train_idx,test_idx in kf.split(firing):\n",
    "\n",
    "            rnn_train_i = np.zeros((len(train_idx),seq_len, firing.shape[1]))\n",
    "            rnn_test_i = np.zeros((len(test_idx),seq_len, firing.shape[1]))\n",
    "            rnn_train_o = EMG.iloc[train_idx,:].to_numpy()\n",
    "            rnn_test_o = EMG.iloc[test_idx,:].to_numpy()\n",
    "            \n",
    "            # split training and testing inputs\n",
    "            rnn_train_i = rnn_i[train_idx,:,:]\n",
    "            rnn_test_i = rnn_i[test_idx,:,:]\n",
    "\n",
    "\n",
    "            # normalize the EMGs\n",
    "            EMG_std = np.std(rnn_train_o, axis=0)\n",
    "            for ii in np.arange(rnn_train_o.shape[1]):\n",
    "                rnn_train_o[:,ii] = rnn_train_o[:,ii]/EMG_std[ii]\n",
    "                rnn_test_o[:,ii] = rnn_test_o[:,ii]/EMG_std[ii]\n",
    "\n",
    "            # Set up the LSTMs\n",
    "            mdl = tf.keras.models.Sequential()\n",
    "\n",
    "\n",
    "            mdl.add(tf.keras.layers.LSTM(layer_0_units, input_shape = (seq_len,n_neurons), dropout=drop_in, recurrent_dropout=drop_rec))\n",
    "            if drop_lay:\n",
    "                mdl.add(tf.keras.layers.Dropout(drop_lay)) # dropout layer if wanted\n",
    "        #     mdl.add(tf.keras.layers.Dense(n_EMGs, activation='relu')) # dense combination layer\n",
    "            mdl.add(tf.keras.layers.Dense(n_EMGs)) # dense combination layer\n",
    "            mdl.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "            mdl.fit(rnn_train_i, rnn_train_o, epochs=n_epochs, verbose=False, callbacks=[tensorboard_callback])\n",
    "\n",
    "\n",
    "            train_pred = mdl.predict(rnn_train_i, verbose=False)\n",
    "            test_pred = mdl.predict(rnn_test_i, verbose=False)\n",
    "            train_VAFs[fold_idx,:] = metrics.explained_variance_score(rnn_train_o, train_pred, multioutput='raw_values')\n",
    "            test_VAFs[fold_idx,:] = metrics.explained_variance_score(rnn_test_o, test_pred, multioutput='raw_values')\n",
    "            \n",
    "            fold_idx += 1\n",
    "            \n",
    "        # store the VAFs in the log entry\n",
    "        for emg_iter,emg_name in enumerate(EMG_names):\n",
    "            log_entry[f\"{emg_name}_train_VAF\"] = np.mean(train_VAFs[:,emg_iter])\n",
    "            log_entry[f\"{emg_name}_test_VAF\"] = np.mean(test_VAFs[:,emg_iter])\n",
    "        \n",
    "        \n",
    "#         return log_entry\n",
    "#         print(pd.DataFrame.from_records([log_entry]))\n",
    "        log = pd.concat([log,pd.DataFrame.from_records([log_entry])], ignore_index=True)\n",
    "        print(f\"Looped iteration {iter} of {n_iter}\")\n",
    "        \n",
    "    return log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_rex(train_firing_dict: dict, train_EMG_orig: dict, train_oh_dict:dict,\n",
    "        test_firing_dict: dict, test_EMG_dict: dict, EMG_name, beta=3,\n",
    "        plot_sig_flag:bool=False, plot_VAF_flag:bool=True,\n",
    "        return_VAF_flag:bool=False):\n",
    "\n",
    "    # hyper params\n",
    "    layer_0_units = 300\n",
    "    drop_in = .25     # input dropout percentage for LSTM layer\n",
    "    drop_rec = 0    # recurrent dropout for LSTM\n",
    "    drop_lay = .15    # dropout layer?\n",
    "\n",
    "    # append the variance to the EMG values\n",
    "    n_EMGs = len(EMG_name)\n",
    "    seq_len = train_firing_dict['Combined'].shape[1] # num of lags\n",
    "    n_neurons = train_firing_dict['Combined'].shape[2]\n",
    "    train_EMG_dict = {}\n",
    "    for ii_cond, cond in enumerate(train_EMG_orig.keys()):\n",
    "        train_EMG_dict[cond] = train_EMG_orig[cond]\n",
    "        train_EMG_dict[cond] = np.append(train_EMG_dict[cond], train_oh_dict[cond], axis=1)\n",
    "\n",
    "    # pull out the \"Combined\" conditions for training\n",
    "    train_i = train_firing_dict['Combined'] \n",
    "    train_o = train_EMG_dict['Combined']\n",
    "\n",
    "    # define the vrex loss function -- so that we can dynamically change the Beta value etc\n",
    "    def vrex_loss(target, pred):\n",
    "        # from the Risk Extrapolation paper\n",
    "        B = beta #\n",
    "\n",
    "        n_target = n_EMGs\n",
    "        err = target[:,:n_target] - pred[:,:n_target] # without the condition flag\n",
    "        se = K.square(err) # squared error -- TxM\n",
    "        mse = K.mean(se, axis=-1) # mean squared error for each sample -- Tx1\n",
    "\n",
    "        # now pull in the one-hot matrix for flagging\n",
    "        cond_oh = tf.transpose(target[:,n_target:]) # transpose it so that we can add everything later CxT\n",
    "\n",
    "        # risk for each condition -- ie MSE for each condition\n",
    "        risk = tf.matmul(cond_oh,se) # Cx1\n",
    "        risk = tf.divide(risk, tf.reduce_sum(cond_oh, 1, keepdims=1)) # mean to account for differen num samples\n",
    "\n",
    "        rex = B*K.var(risk) + K.sum(risk)\n",
    "\n",
    "        return rex\n",
    "\n",
    "    # create the model\n",
    "    mdl = tf.keras.models.Sequential()\n",
    "    # add the LSTM layer\n",
    "    mdl.add(tf.keras.layers.LSTM(layer_0_units, input_shape = (seq_len,n_neurons), dropout=drop_in, recurrent_dropout=drop_rec))\n",
    "    mdl.add(tf.keras.layers.Dropout(drop_lay))\n",
    "    mdl.add(tf.keras.layers.Dense(train_o.shape[1]))\n",
    "\n",
    "    mdl.compile(loss=vrex_loss, optimizer='rmsprop', metrics='mse')\n",
    "    mdl.fit(train_i, train_o, epochs=50, verbose=0)\n",
    "\n",
    "    # Get the predictions\n",
    "    train_preds = {}\n",
    "    train_VAFs = {}\n",
    "    test_preds = {}\n",
    "    test_VAFs = {}\n",
    "\n",
    "    for cond in train_firing_dict.keys():\n",
    "        train_preds[cond] = mdl.predict(train_firing_dict[cond])\n",
    "        train_VAFs[cond] = metrics.r2_score(train_EMG_dict[cond][:,:n_EMGs], train_preds[cond][:,:n_EMGs], multioutput='raw_values')\n",
    "    \n",
    "    for cond in test_firing_dict.keys():\n",
    "        if cond != 'Combined': # don't really care about the \"combined\" test case\n",
    "            test_preds[cond] = mdl.predict(test_firing_dict[cond])\n",
    "            test_VAFs[cond] = metrics.r2_score(test_EMG_dict[cond][:,:n_EMGs], test_preds[cond][:,:n_EMGs], multioutput='raw_values')\n",
    "\n",
    "\n",
    "    print('----------------------------------------')\n",
    "    for ii_name, name in enumerate(EMG_name):\n",
    "        print(name)\n",
    "        for in_name, in_vaf in train_VAFs.items():\n",
    "            print(f\"\\tTrain VAF for {in_name}: {in_vaf[ii_name]}\")\n",
    "        for out_name,out_vaf in test_VAFs.items():\n",
    "            print(f\"\\tTest VAF for {out_name}: {out_vaf[ii_name]}\")\n",
    "\n",
    "    if plot_sig_flag:\n",
    "        plot_rec_pred(train_EMG_dict, train_preds, EMG_name, train_VAFs, title_append = 'training set')\n",
    "        plot_rec_pred(test_EMG_dict, test_preds, EMG_name, test_VAFs, title_append = 'testing set')\n",
    "\n",
    "    if plot_VAF_flag:\n",
    "        plot_VAFs(train_VAFs, test_VAFs, EMG_name, sup_title=f'REx, Beta = {beta}')\n",
    "\n",
    "    if return_VAF_flag:\n",
    "        return train_VAFs, test_VAFs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_rex_weighted(train_firing_dict: dict, train_EMG_orig: dict, \n",
    "        train_var_dict:dict, train_oh_dict:dict, test_firing_dict: dict,\n",
    "        test_EMG_dict: dict, EMG_name, beta=3,\n",
    "        plot_sig_flag:bool=False, plot_VAF_flag:bool=True,\n",
    "        return_VAF_flag:bool=True):\n",
    "    # hyper params\n",
    "    layer_0_units = 300\n",
    "    drop_in = .25     # input dropout percentage for LSTM layer\n",
    "    drop_rec = 0    # recurrent dropout for LSTM\n",
    "    drop_lay = .15    # dropout layer?\n",
    "\n",
    "    # append the variance to the EMG values\n",
    "    n_EMGs = len(EMG_name)\n",
    "    seq_len = train_firing_dict['Combined'].shape[1] # num of lags\n",
    "    n_neurons = train_firing_dict['Combined'].shape[2]\n",
    "    n_cond = len(list(train_firing_dict.keys()))-1 # to avoid counting \"Combined\"\n",
    "    train_EMG_dict = {}\n",
    "    for ii_cond, cond in enumerate(train_EMG_orig.keys()):\n",
    "        train_EMG_dict[cond] = train_EMG_orig[cond].copy()\n",
    "        train_EMG_dict[cond] = np.append(train_EMG_dict[cond], train_var_dict[cond], axis=1)\n",
    "        train_EMG_dict[cond] = np.append(train_EMG_dict[cond], train_oh_dict[cond], axis=1)\n",
    "\n",
    "    # pull out the \"Combined\" conditions for training\n",
    "    train_i = train_firing_dict['Combined'] \n",
    "    train_o = train_EMG_dict['Combined']\n",
    "\n",
    "    # define the loss function -- allows us to change beta etc dynamically\n",
    "    def vrex_weighted(target, pred):\n",
    "        B = beta \n",
    "\n",
    "        n_target = n_EMGs\n",
    "        n_conds = n_cond\n",
    "\n",
    "        err = target[:,:n_target] - pred[:,:n_target] # find the error\n",
    "        se_musc = K.square(err) # square error per muscle per timepoint\n",
    "        # pull out the variances and divide, then take the mean. Tx1\n",
    "        se = K.mean(tf.divide(se_musc, target[:,n_target:2*n_target]), axis=1, keepdims=True) \n",
    "\n",
    "        # pull out the one-hot matrix for flagging\n",
    "        cond_oh = tf.transpose(target[:,-n_conds:]) # transpose -- CxT\n",
    "\n",
    "        risk = tf.matmul(cond_oh, se) # this should give us a Cx1 array\n",
    "        risks = tf.divide(risk, tf.reduce_sum(cond_oh, 1, keepdims=1))\n",
    "\n",
    "        rex = B*K.var(risks) + K.sum(risks)\n",
    "        return rex\n",
    "\n",
    "\n",
    "    # create the model\n",
    "    mdl = tf.keras.models.Sequential()\n",
    "\n",
    "    # add the LSTM layer\n",
    "    mdl.add(tf.keras.layers.LSTM(layer_0_units, input_shape = (seq_len,n_neurons), dropout=drop_in, recurrent_dropout=drop_rec))\n",
    "    mdl.add(tf.keras.layers.Dropout(drop_lay))\n",
    "    mdl.add(tf.keras.layers.Dense(train_o.shape[1]))\n",
    "\n",
    "    mdl.compile(loss=vrex_weighted, optimizer='rmsprop', metrics='mse')\n",
    "\n",
    "    mdl.fit(train_i, train_o, epochs=50, verbose=0)\n",
    "\n",
    "\n",
    "\n",
    "    train_preds = {}\n",
    "    train_VAFs = {}\n",
    "    test_preds = {}\n",
    "    test_VAFs = {}\n",
    "\n",
    "    for cond in train_firing_dict.keys():\n",
    "        train_preds[cond] = mdl.predict(train_firing_dict[cond])\n",
    "        train_VAFs[cond] = metrics.r2_score(train_EMG_dict[cond][:,:n_EMGs], train_preds[cond][:,:n_EMGs], multioutput='raw_values')\n",
    "    \n",
    "    for cond in test_firing_dict.keys():\n",
    "        if cond != 'Combined': # don't really care about the \"combined\" test case\n",
    "            test_preds[cond] = mdl.predict(test_firing_dict[cond])\n",
    "            test_VAFs[cond] = metrics.r2_score(test_EMG_dict[cond][:,:n_EMGs], test_preds[cond][:,:n_EMGs], multioutput='raw_values')\n",
    "\n",
    "\n",
    "    print('----------------------------------------')\n",
    "    for ii_name, name in enumerate(EMG_name):\n",
    "        print(name)\n",
    "        for in_name, in_vaf in train_VAFs.items():\n",
    "            print(f\"\\tTrain VAF for {in_name}: {in_vaf[ii_name]}\")\n",
    "        for out_name,out_vaf in test_VAFs.items():\n",
    "            print(f\"\\tTest VAF for {out_name}: {out_vaf[ii_name]}\")\n",
    "\n",
    "    if plot_sig_flag:\n",
    "        plot_rec_pred(train_EMG_dict, train_preds, EMG_name, train_VAFs, title_append = 'training set')\n",
    "        plot_rec_pred(test_EMG_dict, test_preds, EMG_name, test_VAFs, title_append = 'testing set')\n",
    "\n",
    "    if plot_VAF_flag:\n",
    "        plot_VAFs(train_VAFs, test_VAFs, EMG_name, sup_title=f'REx Weighted, Beta = {beta}')\n",
    "\n",
    "    if return_VAF_flag:\n",
    "        return train_VAFs, test_VAFs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare different combinations of train/test sets\n",
    "\n",
    "So that we can quickly run through all of the iterations\n",
    "\n",
    "Set the nonlinearity type, to compare across iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonlinear_type = 'poly'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "First train wrist movement, test wrist movement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_timestamps, train_firing, train_EMG, train_force, train_kin = load_josh_mat(data['WmTrain'])\n",
    "test_timestamps, test_firing, test_EMG, test_force, test_kin = load_josh_mat(data['WmTest'])\n",
    "# using the training set twice as the \"refit\" gain -- for sanity's sake\n",
    "mov_mov_linVAF = basic_decoder_comparison(train_firing, train_EMG, train_firing, train_EMG, test_firing, test_EMG, test_timestamps, nonlinear_type)\n",
    "mov_mov_LSTMVAF = LSTM_comparisons(train_firing, train_EMG, test_firing, test_EMG, test_timestamps)\n",
    "\n",
    "print(f\"Mean Linear {np.mean(mov_mov_linVAF)}\")\n",
    "print(f\"Mean LSTM {np.mean(mov_mov_LSTMVAF)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train wrist movement, test iso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_timestamps, train_firing, train_EMG, train_force, train_kin = load_josh_mat(data['WmTrain'])\n",
    "_, retrain_firing, retrain_EMG, _, _, = load_josh_mat(data['IsoTrain'])\n",
    "test_timestamps, test_firing, test_EMG, test_force, test_kin = load_josh_mat(data['IsoTest'])\n",
    "mov_iso_linVAF = basic_decoder_comparison(train_firing, train_EMG, retrain_firing, retrain_EMG, test_firing, test_EMG, test_timestamps, nonlinear_type)\n",
    "mov_iso_LSTMVAF = LSTM_comparisons(train_firing, train_EMG, test_firing, test_EMG, test_timestamps)\n",
    "\n",
    "print(f\"Mean Linear {np.mean(mov_iso_linVAF)}\")\n",
    "print(f\"Mean LSTM {np.mean(mov_iso_LSTMVAF)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train WM, test spring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_timestamps, train_firing, train_EMG, train_force, train_kin = load_josh_mat(data['WmTrain'])\n",
    "_, retrain_firing, retrain_EMG, _, _, = load_josh_mat(data['SprTrain'])\n",
    "test_timestamps, test_firing, test_EMG, test_force, test_kin = load_josh_mat(data['SprTest'])\n",
    "mov_spr_linVAF = basic_decoder_comparison(train_firing, train_EMG, retrain_firing, retrain_EMG, test_firing, test_EMG, test_timestamps, nonlinear_type)\n",
    "mov_spr_LSTMVAF = LSTM_comparisons(train_firing, train_EMG, test_firing, test_EMG, test_timestamps)\n",
    "\n",
    "print(f\"Mean Linear {np.mean(mov_spr_linVAF)}\")\n",
    "print(f\"Mean LSTM {np.mean(mov_spr_LSTMVAF)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Iso, test Iso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_timestamps, train_firing, train_EMG, train_force, train_kin = load_josh_mat(data['IsoTrain'])\n",
    "test_timestamps, test_firing, test_EMG, test_force, test_kin = load_josh_mat(data['IsoTest'])\n",
    "iso_iso_linVAF = basic_decoder_comparison(train_firing, train_EMG, train_firing, train_EMG, test_firing, test_EMG, test_timestamps, nonlinear_type)\n",
    "iso_iso_LSTMVAF = LSTM_comparisons(train_firing, train_EMG, test_firing, test_EMG, test_timestamps)\n",
    "\n",
    "print(f\"Mean Linear {np.mean(iso_iso_linVAF)}\")\n",
    "print(f\"Mean LSTM {np.mean(iso_iso_LSTMVAF)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Iso, test WM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_timestamps, train_firing, train_EMG, train_force, train_kin = load_josh_mat(data['IsoTrain'])\n",
    "_, retrain_firing, retrain_EMG, _, _, = load_josh_mat(data['WmTrain'])\n",
    "test_timestamps, test_firing, test_EMG, test_force, test_kin = load_josh_mat(data['WmTest'])\n",
    "iso_mov_linVAF = basic_decoder_comparison(train_firing, train_EMG, retrain_firing, retrain_EMG, test_firing, test_EMG, test_timestamps, nonlinear_type)\n",
    "iso_mov_LSTMVAF = LSTM_comparisons(train_firing, train_EMG, test_firing, test_EMG, test_timestamps)\n",
    "\n",
    "print(f\"Mean Linear {np.mean(iso_mov_linVAF)}\")\n",
    "print(f\"Mean LSTM {np.mean(iso_mov_linVAF)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Iso, Test Spring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_timestamps, train_firing, train_EMG, train_force, train_kin = load_josh_mat(data['IsoTrain'])\n",
    "_, retrain_firing, retrain_EMG, _, _, = load_josh_mat(data['SprTrain'])\n",
    "test_timestamps, test_firing, test_EMG, test_force, test_kin = load_josh_mat(data['SprTest'])\n",
    "iso_spr_linVAF = basic_decoder_comparison(train_firing, train_EMG, retrain_firing, retrain_EMG, test_firing, test_EMG, test_timestamps, nonlinear_type)\n",
    "iso_spr_LSTMVAF = LSTM_comparisons(train_firing, train_EMG, test_firing, test_EMG, test_timestamps)\n",
    "\n",
    "print(f\"Mean Linear {np.mean(iso_spr_linVAF)}\")\n",
    "print(f\"Mean LSTM {np.mean(iso_spr_linVAF)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Spring, test each of the three"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_timestamps, train_firing, train_EMG, train_force, train_kin = load_josh_mat(data['SprTrain'])\n",
    "\n",
    "print('Test Spring')\n",
    "_, retrain_firing, retrain_EMG, _, _, = load_josh_mat(data['SprTrain'])\n",
    "test_timestamps, test_firing, test_EMG, test_force, test_kin = load_josh_mat(data['SprTest'])\n",
    "spr_spr_linVAF = basic_decoder_comparison(train_firing, train_EMG, retrain_firing, retrain_EMG, test_firing, test_EMG, test_timestamps, nonlinear_type)\n",
    "spr_spr_LSTMVAF = LSTM_comparisons(train_firing, train_EMG, test_firing, test_EMG, test_timestamps)\n",
    "\n",
    "print('Test Iso')\n",
    "_, retrain_firing, retrain_EMG, _, _, = load_josh_mat(data['IsoTrain'])\n",
    "test_timestamps, test_firing, test_EMG, test_force, test_kin = load_josh_mat(data['IsoTest'])\n",
    "spr_iso_linVAF = basic_decoder_comparison(train_firing, train_EMG, retrain_firing, retrain_EMG, test_firing, test_EMG, test_timestamps, nonlinear_type)\n",
    "spr_iso_LSTMVAF = LSTM_comparisons(train_firing, train_EMG, test_firing, test_EMG, test_timestamps)\n",
    "\n",
    "print('Test Movement')\n",
    "_, retrain_firing, retrain_EMG, _, _, = load_josh_mat(data['WmTrain'])\n",
    "test_timestamps, test_firing, test_EMG, test_force, test_kin = load_josh_mat(data['WmTest'])\n",
    "spr_mov_linVAF = basic_decoder_comparison(train_firing, train_EMG, retrain_firing, retrain_EMG, test_firing, test_EMG, test_timestamps, nonlinear_type)\n",
    "spr_mov_LSTMVAF = LSTM_comparisons(train_firing, train_EMG, test_firing, test_EMG, test_timestamps)\n",
    "\n",
    "dntxt.send('Spring Linear and non weighted done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train on hybrid, test on each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Hybrid 3 -- this should be a blend of all three, I think for training\n",
    "train_timestamps, train_firing, train_EMG, train_force, train_kin = load_josh_mat(data['Hybrid3'])\n",
    "\n",
    "print(\"test on movement\")\n",
    "_, retrain_firing, retrain_EMG, _, _, = load_josh_mat(data['WmTrain'])\n",
    "test_timestamps, test_firing, test_EMG, test_force, test_kin = load_josh_mat(data['WmTest'])\n",
    "basic_decoder_comparison(train_firing, train_EMG, retrain_firing, retrain_EMG, test_firing, test_EMG, test_timestamps, nonlinear_type)\n",
    "LSTM_comparisons(train_firing, train_EMG, test_firing, test_EMG, test_timestamps)\n",
    "\n",
    "print(\"\\n\\ntest on Iso\")\n",
    "_, retrain_firing, retrain_EMG, _, _, = load_josh_mat(data['IsoTrain'])\n",
    "test_timestamps, test_firing, test_EMG, test_force, test_kin = load_josh_mat(data['IsoTest'])\n",
    "basic_decoder_comparison(train_firing, train_EMG, retrain_firing, retrain_EMG, test_firing, test_EMG, test_timestamps, nonlinear_type)\n",
    "LSTM_comparisons(train_firing, train_EMG, test_firing, test_EMG, test_timestamps)\n",
    "\n",
    "\n",
    "print(\"\\n\\ntest on Spring\")\n",
    "_, retrain_firing, retrain_EMG, _, _, = load_josh_mat(data['SprTrain'])\n",
    "test_timestamps, test_firing, test_EMG, test_force, test_kin = load_josh_mat(data['SprTest'])\n",
    "basic_decoder_comparison(train_firing, train_EMG, retrain_firing, retrain_EMG, test_firing, test_EMG, test_timestamps, nonlinear_type)\n",
    "LSTM_comparisons(train_firing, train_EMG, test_firing, test_EMG, test_timestamps)\n",
    "\n",
    "dntxt.send('Hybrid basic testing complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Hybrid 3 -- this should be a blend of all three, I think for training\n",
    "train_timestamps, train_firing, train_EMG, train_force, train_kin = load_josh_mat(data['Hybrid3'])\n",
    "_, retrain_firing, retrain_EMG, _, _, = load_josh_mat(data['IsoTrain'])\n",
    "test_timestamps, test_firing, test_EMG, test_force, test_kin = load_josh_mat(data['IsoTest'])\n",
    "basic_decoder_comparison(train_firing, train_EMG, retrain_firing, retrain_EMG, test_firing, test_EMG, test_timestamps, nonlinear_type)\n",
    "LSTM_comparisons(train_firing, train_EMG, test_firing, test_EMG, test_timestamps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Different NN Loss functions\n",
    "\n",
    "Comparing each type of NN defined above:\n",
    "1. Vanilla LSTM\n",
    "1. Vanilla LSTM with \"weighting\"\n",
    "1. LSTM with REx\n",
    "1. LSTM with REx and \"weighting\"\n",
    "\n",
    "Here we're defining weighting as the inverse of a muscle's variance for that condition. That means that the squared error for each muscle for each condition is multiplied by that value before the losses are summed etc. This is meant to account for different EMG magnitudes so that we are training to all conditions and muscles\n",
    "\n",
    "\n",
    "First we'll test and train on iso, and set the Beta value for the Risk Extrapolation conditions to zero. This should make the plain REx equal to the vanilla LSTM, and the weighting REx equal to the vanilla weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_firing = {'Iso': Iso_train_firing}\n",
    "test_firing = {'Iso': Iso_test_firing}\n",
    "train_EMG = {'Iso': Iso_train_EMG}\n",
    "test_EMG = {'Iso': Iso_test_EMG}\n",
    "\n",
    "ret_vals = LSTM_preprocess(train_firing, train_EMG, test_firing, test_EMG)\n",
    "\n",
    "train_firing_dict = ret_vals[0]\n",
    "train_EMG_dict = ret_vals[1]\n",
    "train_oh_dict = ret_vals[2]\n",
    "train_var_dict = ret_vals[3]\n",
    "test_firing_dict = ret_vals[4]\n",
    "test_EMG_dict = ret_vals[5]\n",
    "test_oh_dict = ret_vals[6]\n",
    "test_var_dict = ret_vals[7]\n",
    "\n",
    "\n",
    "print('Vanilla LSTM')\n",
    "LSTM_comparisons(train_firing_dict, train_EMG_dict, test_firing_dict, test_EMG_dict, EMG_name)\n",
    "\n",
    "print('LSTM w/ REx, Beta=0')\n",
    "LSTM_rex(train_firing_dict=train_firing_dict, train_EMG_orig=train_EMG_dict,\n",
    "    train_oh_dict=train_oh_dict, test_firing_dict=test_firing_dict, \n",
    "    test_EMG_dict=test_EMG_dict, beta=0, EMG_name=EMG_name)\n",
    "\n",
    "print('LSTM Weighted')\n",
    "LSTM_across_weighted(train_firing_dict=train_firing_dict, train_EMG_orig=train_EMG_dict,\n",
    "    train_var_dict=train_var_dict, test_firing_dict=test_firing_dict, \n",
    "    test_EMG_dict=test_EMG_dict, EMG_name=EMG_name)\n",
    "\n",
    "print('LSTM w/ REx Weighted, Beta=0')\n",
    "LSTM_rex_weighted(train_firing_dict = train_firing_dict, train_EMG_orig = train_EMG_dict, \n",
    "    train_oh_dict = train_oh_dict, train_var_dict = train_var_dict, \n",
    "    test_firing_dict=test_firing_dict, test_EMG_dict = test_EMG_dict, \n",
    "    beta=0, EMG_name=EMG_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train on Movement and Spring, test on everything"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train on Movement and Isometric, test on everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vanilla LSTM\n",
      "375/375 [==============================] - 1s 3ms/step\n",
      "375/375 [==============================] - 1s 3ms/step\n",
      "750/750 [==============================] - 2s 3ms/step\n",
      "188/188 [==============================] - 1s 3ms/step\n",
      "188/188 [==============================] - 1s 3ms/step\n",
      "188/188 [==============================] - 1s 3ms/step\n",
      "----------------------------------------\n",
      "FCU\n",
      "\tTrain VAF for Iso: 0.3581315603559527\n",
      "\tTrain VAF for Mov: 0.09237315300793958\n",
      "\tTrain VAF for Combined: 0.283359373442327\n",
      "\tTest VAF for Iso: 0.4697589093487502\n",
      "\tTest VAF for Mov: 0.059000975268873934\n",
      "\tTest VAF for Spr: 0.03662578941965533\n",
      "FCR\n",
      "\tTrain VAF for Iso: 0.5536212714209918\n",
      "\tTrain VAF for Mov: 0.32768083335832665\n",
      "\tTrain VAF for Combined: 0.4858813856799582\n",
      "\tTest VAF for Iso: 0.433069300995648\n",
      "\tTest VAF for Mov: 0.25898034533994296\n",
      "\tTest VAF for Spr: 0.032542391448421304\n",
      "ECU\n",
      "\tTrain VAF for Iso: 0.7201128852954463\n",
      "\tTrain VAF for Mov: 0.5782898266820464\n",
      "\tTrain VAF for Combined: 0.6753721678560471\n",
      "\tTest VAF for Iso: 0.5186255685572244\n",
      "\tTest VAF for Mov: 0.352722416123483\n",
      "\tTest VAF for Spr: 0.17201690928123792\n",
      "ECR\n",
      "\tTrain VAF for Iso: 0.9171733616240882\n",
      "\tTrain VAF for Mov: 0.5837243419808518\n",
      "\tTrain VAF for Combined: 0.9051488333546314\n",
      "\tTest VAF for Iso: 0.8368720212856132\n",
      "\tTest VAF for Mov: 0.4906064971888001\n",
      "\tTest VAF for Spr: 0.2740849588331655\n",
      "LSTM Weighted\n",
      "375/375 [==============================] - 2s 3ms/step\n",
      "375/375 [==============================] - 1s 3ms/step\n",
      "750/750 [==============================] - 2s 3ms/step\n",
      "188/188 [==============================] - 1s 3ms/step\n",
      "188/188 [==============================] - 1s 3ms/step\n",
      "188/188 [==============================] - 1s 3ms/step\n",
      "----------------------------------------\n",
      "FCU\n",
      "\tTrain VAF for Iso: 0.296435412785615\n",
      "\tTrain VAF for Mov: 0.18434453126329475\n",
      "\tTrain VAF for Combined: 0.26492250421180363\n",
      "\tTest VAF for Iso: 0.30110381848500933\n",
      "\tTest VAF for Mov: 0.10479517532866445\n",
      "\tTest VAF for Spr: 0.16049931730086353\n",
      "FCR\n",
      "\tTrain VAF for Iso: 0.5442442623636556\n",
      "\tTrain VAF for Mov: 0.30979235836121166\n",
      "\tTrain VAF for Combined: 0.4738350348563607\n",
      "\tTest VAF for Iso: 0.39134149739224744\n",
      "\tTest VAF for Mov: 0.2499523900880195\n",
      "\tTest VAF for Spr: 0.04746435403541638\n",
      "ECU\n",
      "\tTrain VAF for Iso: 0.811770633228968\n",
      "\tTrain VAF for Mov: 0.610677686793083\n",
      "\tTrain VAF for Combined: 0.7106046381161677\n",
      "\tTest VAF for Iso: 0.61011557254313\n",
      "\tTest VAF for Mov: 0.3841898642720547\n",
      "\tTest VAF for Spr: 0.16874609971268273\n",
      "ECR\n",
      "\tTrain VAF for Iso: 0.8806987736940443\n",
      "\tTrain VAF for Mov: 0.6628550120704734\n",
      "\tTrain VAF for Combined: 0.8795904036743487\n",
      "\tTest VAF for Iso: 0.8212048874671873\n",
      "\tTest VAF for Mov: 0.5637681726187592\n",
      "\tTest VAF for Spr: 0.2868861748622673\n",
      "LSTM w/ REx, Beta=1.023292992280754\n",
      "375/375 [==============================] - 2s 3ms/step\n",
      "375/375 [==============================] - 1s 3ms/step\n",
      "750/750 [==============================] - 2s 3ms/step\n",
      "188/188 [==============================] - 1s 3ms/step\n",
      "188/188 [==============================] - 1s 3ms/step\n",
      "188/188 [==============================] - 1s 3ms/step\n",
      "----------------------------------------\n",
      "FCU\n",
      "\tTrain VAF for Iso: 0.36413619030298394\n",
      "\tTrain VAF for Mov: 0.07055329421467449\n",
      "\tTrain VAF for Combined: 0.2815313613936017\n",
      "\tTest VAF for Iso: 0.5044166030968354\n",
      "\tTest VAF for Mov: 0.031922720184644926\n",
      "\tTest VAF for Spr: 0.09043709583600401\n",
      "FCR\n",
      "\tTrain VAF for Iso: 0.5840954029490474\n",
      "\tTrain VAF for Mov: 0.3069598370893035\n",
      "\tTrain VAF for Combined: 0.4989276507740612\n",
      "\tTest VAF for Iso: 0.4452238734665871\n",
      "\tTest VAF for Mov: 0.2087722061818552\n",
      "\tTest VAF for Spr: 0.13857125862072184\n",
      "ECU\n",
      "\tTrain VAF for Iso: 0.7484916427312704\n",
      "\tTrain VAF for Mov: 0.6086239960369928\n",
      "\tTrain VAF for Combined: 0.6999337061103656\n",
      "\tTest VAF for Iso: 0.5786346123078308\n",
      "\tTest VAF for Mov: 0.37613621364751315\n",
      "\tTest VAF for Spr: 0.18880664748213172\n",
      "ECR\n",
      "\tTrain VAF for Iso: 0.9136362685470891\n",
      "\tTrain VAF for Mov: 0.618876389361317\n",
      "\tTrain VAF for Combined: 0.9043676753153808\n",
      "\tTest VAF for Iso: 0.8296885780966851\n",
      "\tTest VAF for Mov: 0.5454695727552887\n",
      "\tTest VAF for Spr: 0.3549269979251918\n",
      "LSTM w/ REx Weighted, Beta=1.023292992280754\n",
      "375/375 [==============================] - 1s 3ms/step\n",
      "375/375 [==============================] - 1s 3ms/step\n",
      "750/750 [==============================] - 2s 3ms/step\n",
      "188/188 [==============================] - 1s 3ms/step\n",
      "188/188 [==============================] - 1s 3ms/step\n",
      "188/188 [==============================] - 1s 3ms/step\n",
      "----------------------------------------\n",
      "FCU\n",
      "\tTrain VAF for Iso: 0.19667767055075502\n",
      "\tTrain VAF for Mov: -0.5082093035531914\n",
      "\tTrain VAF for Combined: -0.001695583087000685\n",
      "\tTest VAF for Iso: -0.11332167566176077\n",
      "\tTest VAF for Mov: -0.8463687464937206\n",
      "\tTest VAF for Spr: 0.20318152296684155\n",
      "FCR\n",
      "\tTrain VAF for Iso: 0.5445490170930642\n",
      "\tTrain VAF for Mov: 0.3140544425972529\n",
      "\tTrain VAF for Combined: 0.4754449247448218\n",
      "\tTest VAF for Iso: 0.4503998357852479\n",
      "\tTest VAF for Mov: 0.22875024925618315\n",
      "\tTest VAF for Spr: 0.09483125212776788\n",
      "ECU\n",
      "\tTrain VAF for Iso: 0.7615342786546956\n",
      "\tTrain VAF for Mov: 0.5947840574970877\n",
      "\tTrain VAF for Combined: 0.6925432380546671\n",
      "\tTest VAF for Iso: 0.5562599152255472\n",
      "\tTest VAF for Mov: 0.3746959572541547\n",
      "\tTest VAF for Spr: 0.17946208896581972\n",
      "ECR\n",
      "\tTrain VAF for Iso: 0.8592973518961404\n",
      "\tTrain VAF for Mov: 0.6319071154301859\n",
      "\tTrain VAF for Combined: 0.8598143808118539\n",
      "\tTest VAF for Iso: 0.790659842474704\n",
      "\tTest VAF for Mov: 0.5518811306209062\n",
      "\tTest VAF for Spr: 0.2965027495140484\n",
      "LSTM w/ REx, Beta=112.36013307668443\n",
      "375/375 [==============================] - 1s 3ms/step\n",
      "375/375 [==============================] - 1s 3ms/step\n",
      "750/750 [==============================] - 2s 3ms/step\n",
      "188/188 [==============================] - 1s 3ms/step\n",
      "188/188 [==============================] - 1s 3ms/step\n",
      "188/188 [==============================] - 1s 3ms/step\n",
      "----------------------------------------\n",
      "FCU\n",
      "\tTrain VAF for Iso: 0.37308972294080756\n",
      "\tTrain VAF for Mov: -0.04723875043259773\n",
      "\tTrain VAF for Combined: 0.25480682672587396\n",
      "\tTest VAF for Iso: 0.5135281978111885\n",
      "\tTest VAF for Mov: -0.07122735756008436\n",
      "\tTest VAF for Spr: 0.030641092207924325\n",
      "FCR\n",
      "\tTrain VAF for Iso: 0.5766920317498794\n",
      "\tTrain VAF for Mov: 0.28652310932648506\n",
      "\tTrain VAF for Combined: 0.48732693535123983\n",
      "\tTest VAF for Iso: 0.45712623539576114\n",
      "\tTest VAF for Mov: 0.1946065990125999\n",
      "\tTest VAF for Spr: 0.14258065590159907\n",
      "ECU\n",
      "\tTrain VAF for Iso: 0.7271373476886622\n",
      "\tTrain VAF for Mov: 0.5865409116298751\n",
      "\tTrain VAF for Combined: 0.6819510647243356\n",
      "\tTest VAF for Iso: 0.5490612354286261\n",
      "\tTest VAF for Mov: 0.3941166691777054\n",
      "\tTest VAF for Spr: 0.17541406702395346\n",
      "ECR\n",
      "\tTrain VAF for Iso: 0.9101974684956733\n",
      "\tTrain VAF for Mov: 0.5973975824472466\n",
      "\tTrain VAF for Combined: 0.9001704611636199\n",
      "\tTest VAF for Iso: 0.8429370820270763\n",
      "\tTest VAF for Mov: 0.5236290983648908\n",
      "\tTest VAF for Spr: 0.3473105555139816\n",
      "LSTM w/ REx Weighted, Beta=112.36013307668443\n",
      "375/375 [==============================] - 1s 2ms/step\n",
      "375/375 [==============================] - 1s 2ms/step\n",
      "750/750 [==============================] - 2s 2ms/step\n",
      "188/188 [==============================] - 1s 2ms/step\n",
      "188/188 [==============================] - 0s 2ms/step\n",
      "188/188 [==============================] - 0s 2ms/step\n",
      "----------------------------------------\n",
      "FCU\n",
      "\tTrain VAF for Iso: -1.2326743649544345\n",
      "\tTrain VAF for Mov: -2.533893018107745\n",
      "\tTrain VAF for Combined: -1.5988285264737172\n",
      "\tTest VAF for Iso: -2.81732556491883\n",
      "\tTest VAF for Mov: -3.7479123367275475\n",
      "\tTest VAF for Spr: -0.12960875878139033\n",
      "FCR\n",
      "\tTrain VAF for Iso: -0.10476499410425855\n",
      "\tTrain VAF for Mov: -0.7363946250687308\n",
      "\tTrain VAF for Combined: -0.29639624735487247\n",
      "\tTest VAF for Iso: 0.04436212512614923\n",
      "\tTest VAF for Mov: -0.8984115063412366\n",
      "\tTest VAF for Spr: 0.05201314830470272\n",
      "ECU\n",
      "\tTrain VAF for Iso: -2.0576815576641385\n",
      "\tTrain VAF for Mov: 0.16310231048826207\n",
      "\tTrain VAF for Combined: -0.011593604170826888\n",
      "\tTest VAF for Iso: -1.3132196391858195\n",
      "\tTest VAF for Mov: 0.14695093349123456\n",
      "\tTest VAF for Spr: 0.10993220389880742\n",
      "ECR\n",
      "\tTrain VAF for Iso: -0.16401245313495205\n",
      "\tTrain VAF for Mov: 0.10824348968922437\n",
      "\tTrain VAF for Combined: -0.026717647437587644\n",
      "\tTest VAF for Iso: -0.09147394433123912\n",
      "\tTest VAF for Mov: 0.07530398889015788\n",
      "\tTest VAF for Spr: 0.18134710402930054\n",
      "LSTM w/ REx, Beta=12337.423983400502\n",
      "375/375 [==============================] - 1s 2ms/step\n",
      "375/375 [==============================] - 1s 3ms/step\n",
      "750/750 [==============================] - 2s 2ms/step\n",
      "188/188 [==============================] - 1s 2ms/step\n",
      "188/188 [==============================] - 0s 2ms/step\n",
      "188/188 [==============================] - 0s 2ms/step\n",
      "----------------------------------------\n",
      "FCU\n",
      "\tTrain VAF for Iso: -9.10222955158331\n",
      "\tTrain VAF for Mov: -22.520364063509568\n",
      "\tTrain VAF for Combined: -12.87872782072648\n",
      "\tTest VAF for Iso: -20.997279344298644\n",
      "\tTest VAF for Mov: -33.29442372102678\n",
      "\tTest VAF for Spr: -5.102423622898913\n",
      "FCR\n",
      "\tTrain VAF for Iso: -0.07892229120901995\n",
      "\tTrain VAF for Mov: -0.8967944065417164\n",
      "\tTrain VAF for Combined: -0.3326114131944564\n",
      "\tTest VAF for Iso: 0.09989050719969417\n",
      "\tTest VAF for Mov: -0.7460621847093396\n",
      "\tTest VAF for Spr: 0.16156039078995865\n",
      "ECU\n",
      "\tTrain VAF for Iso: -8.489886249288057\n",
      "\tTrain VAF for Mov: -0.923408067022073\n",
      "\tTrain VAF for Combined: -1.6864357870549367\n",
      "\tTest VAF for Iso: -5.968804081920426\n",
      "\tTest VAF for Mov: -0.7097365530537039\n",
      "\tTest VAF for Spr: 0.2044604465589791\n",
      "ECR\n",
      "\tTrain VAF for Iso: 0.7384104051389264\n",
      "\tTrain VAF for Mov: -3.1318265926185855\n",
      "\tTrain VAF for Combined: 0.5264197760215337\n",
      "\tTest VAF for Iso: 0.6345211927040326\n",
      "\tTest VAF for Mov: -2.3712483842935916\n",
      "\tTest VAF for Spr: 0.3856921539863952\n",
      "LSTM w/ REx Weighted, Beta=12337.423983400502\n",
      "375/375 [==============================] - 1s 2ms/step\n",
      "375/375 [==============================] - 1s 2ms/step\n",
      "750/750 [==============================] - 2s 2ms/step\n",
      "188/188 [==============================] - 1s 2ms/step\n",
      "188/188 [==============================] - 0s 2ms/step\n",
      "188/188 [==============================] - 0s 2ms/step\n",
      "----------------------------------------\n",
      "FCU\n",
      "\tTrain VAF for Iso: -2.629934238896322\n",
      "\tTrain VAF for Mov: -6.4028470940861695\n",
      "\tTrain VAF for Combined: -3.6917661960066406\n",
      "\tTest VAF for Iso: -5.827788472424351\n",
      "\tTest VAF for Mov: -9.674957290644151\n",
      "\tTest VAF for Spr: -0.8972045109925249\n",
      "FCR\n",
      "\tTrain VAF for Iso: -0.4361187091025509\n",
      "\tTrain VAF for Mov: -1.6405350199205966\n",
      "\tTrain VAF for Combined: -0.812119144742119\n",
      "\tTest VAF for Iso: -0.14742883405851082\n",
      "\tTest VAF for Mov: -1.8694065587986453\n",
      "\tTest VAF for Spr: -0.01794379341459096\n",
      "ECU\n",
      "\tTrain VAF for Iso: -5.391892646609211\n",
      "\tTrain VAF for Mov: -0.1283153768426304\n",
      "\tTrain VAF for Combined: -0.6970314845314971\n",
      "\tTest VAF for Iso: -3.502975171028962\n",
      "\tTest VAF for Mov: -0.09340001101383266\n",
      "\tTest VAF for Spr: -0.02096213015799986\n",
      "ECR\n",
      "\tTrain VAF for Iso: -0.1325446250358695\n",
      "\tTrain VAF for Mov: -0.2893715422565404\n",
      "\tTrain VAF for Combined: -0.025011369497137448\n",
      "\tTest VAF for Iso: -0.08822171708843074\n",
      "\tTest VAF for Mov: -0.30303852975219425\n",
      "\tTest VAF for Spr: -0.005097917213727543\n",
      "LSTM w/ REx, Beta=1354680.0486815288\n",
      "375/375 [==============================] - 1s 2ms/step\n",
      "375/375 [==============================] - 1s 2ms/step\n",
      "750/750 [==============================] - 2s 2ms/step\n",
      "188/188 [==============================] - 1s 2ms/step\n",
      "188/188 [==============================] - 0s 2ms/step\n",
      "188/188 [==============================] - 0s 2ms/step\n",
      "----------------------------------------\n",
      "FCU\n",
      "\tTrain VAF for Iso: -14.511272385659558\n",
      "\tTrain VAF for Mov: -42.08400245520225\n",
      "\tTrain VAF for Combined: -22.271838626953922\n",
      "\tTest VAF for Iso: -31.62068320823508\n",
      "\tTest VAF for Mov: -62.626005045581955\n",
      "\tTest VAF for Spr: -9.140928827339115\n",
      "FCR\n",
      "\tTrain VAF for Iso: -0.04089621584312497\n",
      "\tTrain VAF for Mov: -1.1423411642599528\n",
      "\tTrain VAF for Combined: -0.389053776135476\n",
      "\tTest VAF for Iso: 0.14927052636145466\n",
      "\tTest VAF for Mov: -1.2962648276121267\n",
      "\tTest VAF for Spr: 0.17857545477479975\n",
      "ECU\n",
      "\tTrain VAF for Iso: -10.34183637113621\n",
      "\tTrain VAF for Mov: -1.5960295117161496\n",
      "\tTrain VAF for Combined: -2.4105620341881884\n",
      "\tTest VAF for Iso: -7.107320079843733\n",
      "\tTest VAF for Mov: -1.3860629204234778\n",
      "\tTest VAF for Spr: 0.054616135678488664\n",
      "ECR\n",
      "\tTrain VAF for Iso: 0.7863244489240129\n",
      "\tTrain VAF for Mov: -3.4073196710352347\n",
      "\tTrain VAF for Combined: 0.549397675884444\n",
      "\tTest VAF for Iso: 0.6580736358577464\n",
      "\tTest VAF for Mov: -3.345488879985215\n",
      "\tTest VAF for Spr: 0.07696422942562287\n",
      "LSTM w/ REx Weighted, Beta=1354680.0486815288\n",
      "375/375 [==============================] - 1s 2ms/step\n",
      "375/375 [==============================] - 1s 2ms/step\n",
      "750/750 [==============================] - 2s 2ms/step\n",
      "188/188 [==============================] - 1s 2ms/step\n",
      "188/188 [==============================] - 0s 2ms/step\n",
      "188/188 [==============================] - 0s 2ms/step\n",
      "----------------------------------------\n",
      "FCU\n",
      "\tTrain VAF for Iso: -2.4411552036866313\n",
      "\tTrain VAF for Mov: -6.15411994486466\n",
      "\tTrain VAF for Combined: -3.4861229904713813\n",
      "\tTest VAF for Iso: -5.47835563889661\n",
      "\tTest VAF for Mov: -9.387998124620418\n",
      "\tTest VAF for Spr: -0.8460887443678617\n",
      "FCR\n",
      "\tTrain VAF for Iso: -0.6230309762538317\n",
      "\tTrain VAF for Mov: -2.0981690819919137\n",
      "\tTrain VAF for Combined: -1.085693020645456\n",
      "\tTest VAF for Iso: -0.26725098899251165\n",
      "\tTest VAF for Mov: -2.3427448155428485\n",
      "\tTest VAF for Spr: -0.05187175144874945\n",
      "ECU\n",
      "\tTrain VAF for Iso: -6.052772492468568\n",
      "\tTrain VAF for Mov: -0.17713786430059697\n",
      "\tTrain VAF for Combined: -0.826882571257141\n",
      "\tTest VAF for Iso: -3.950432167968822\n",
      "\tTest VAF for Mov: -0.13756350217547908\n",
      "\tTest VAF for Spr: -0.018647911750943935\n",
      "ECR\n",
      "\tTrain VAF for Iso: -0.08428099074330175\n",
      "\tTrain VAF for Mov: -0.5692190997709767\n",
      "\tTrain VAF for Combined: -0.0020106341242822623\n",
      "\tTest VAF for Iso: -0.045403049329090006\n",
      "\tTest VAF for Mov: -0.607210730779516\n",
      "\tTest VAF for Spr: -0.019728905381611206\n",
      "LSTM w/ REx, Beta=148747261.72699577\n",
      "375/375 [==============================] - 1s 2ms/step\n",
      "375/375 [==============================] - 1s 2ms/step\n",
      "750/750 [==============================] - 2s 2ms/step\n",
      "188/188 [==============================] - 1s 2ms/step\n",
      "188/188 [==============================] - 0s 2ms/step\n",
      "188/188 [==============================] - 0s 2ms/step\n",
      "----------------------------------------\n",
      "FCU\n",
      "\tTrain VAF for Iso: -22.369547855733686\n",
      "\tTrain VAF for Mov: -56.93030291382661\n",
      "\tTrain VAF for Combined: -32.09672929191435\n",
      "\tTest VAF for Iso: -48.03185977813087\n",
      "\tTest VAF for Mov: -84.9396970811461\n",
      "\tTest VAF for Spr: -11.22234179400711\n",
      "FCR\n",
      "\tTrain VAF for Iso: -0.30093649657565424\n",
      "\tTrain VAF for Mov: -1.4925666282136354\n",
      "\tTrain VAF for Combined: -0.6748396743309706\n",
      "\tTest VAF for Iso: 0.018961024819479477\n",
      "\tTest VAF for Mov: -1.7281907970311634\n",
      "\tTest VAF for Spr: 0.11421531959627074\n",
      "ECU\n",
      "\tTrain VAF for Iso: -17.76420404171713\n",
      "\tTrain VAF for Mov: -3.1784504117098153\n",
      "\tTrain VAF for Combined: -4.564197891011523\n",
      "\tTest VAF for Iso: -13.008369959595761\n",
      "\tTest VAF for Mov: -2.5666338220406075\n",
      "\tTest VAF for Spr: -0.047820388197380215\n",
      "ECR\n",
      "\tTrain VAF for Iso: 0.6390461144966506\n",
      "\tTrain VAF for Mov: -5.4418957418504155\n",
      "\tTrain VAF for Combined: 0.3007840061337729\n",
      "\tTest VAF for Iso: 0.5136700607286746\n",
      "\tTest VAF for Mov: -5.056315872388127\n",
      "\tTest VAF for Spr: -0.269136721840068\n",
      "LSTM w/ REx Weighted, Beta=148747261.72699577\n",
      "375/375 [==============================] - 1s 2ms/step\n",
      "375/375 [==============================] - 1s 2ms/step\n",
      "750/750 [==============================] - 2s 2ms/step\n",
      "188/188 [==============================] - 1s 2ms/step\n",
      "188/188 [==============================] - 0s 2ms/step\n",
      "188/188 [==============================] - 0s 2ms/step\n",
      "----------------------------------------\n",
      "FCU\n",
      "\tTrain VAF for Iso: -1.599027161311278\n",
      "\tTrain VAF for Mov: -4.0307889542129995\n",
      "\tTrain VAF for Combined: -2.2833969086990327\n",
      "\tTest VAF for Iso: -3.6395720079388045\n",
      "\tTest VAF for Mov: -6.1080560644452175\n",
      "\tTest VAF for Spr: -0.4798556231159994\n",
      "FCR\n",
      "\tTrain VAF for Iso: -0.7393058457770141\n",
      "\tTrain VAF for Mov: -2.26636775935256\n",
      "\tTrain VAF for Combined: -1.2173190634290267\n",
      "\tTest VAF for Iso: -0.33685811611390015\n",
      "\tTest VAF for Mov: -2.5220908320646016\n",
      "\tTest VAF for Spr: -0.06671978902333087\n",
      "ECU\n",
      "\tTrain VAF for Iso: -4.494522358773303\n",
      "\tTrain VAF for Mov: -0.07083604677706501\n",
      "\tTrain VAF for Combined: -0.5266402678034747\n",
      "\tTest VAF for Iso: -2.912166104433397\n",
      "\tTest VAF for Mov: -0.056651713147941596\n",
      "\tTest VAF for Spr: -0.0353345078296845\n",
      "ECR\n",
      "\tTrain VAF for Iso: -0.10039852700191432\n",
      "\tTrain VAF for Mov: -0.4748026756640331\n",
      "\tTrain VAF for Combined: -0.00963226077621493\n",
      "\tTest VAF for Iso: -0.05906035951605171\n",
      "\tTest VAF for Mov: -0.5175865720280346\n",
      "\tTest VAF for Spr: -0.025142062791868813\n",
      "LSTM w/ REx, Beta=16332821829.636995\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\17204\\Documents\\git\\proc-kevin\\LSTM\\LSTM_exploration.ipynb Cell 49\u001b[0m in \u001b[0;36m<cell line: 32>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/17204/Documents/git/proc-kevin/LSTM/LSTM_exploration.ipynb#X66sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39mfor\u001b[39;00m beta \u001b[39min\u001b[39;00m np\u001b[39m.\u001b[39mlogspace(\u001b[39m.01\u001b[39m, \u001b[39m100\u001b[39m):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/17204/Documents/git/proc-kevin/LSTM/LSTM_exploration.ipynb#X66sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mLSTM w/ REx, Beta=\u001b[39m\u001b[39m{\u001b[39;00mbeta\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/17204/Documents/git/proc-kevin/LSTM/LSTM_exploration.ipynb#X66sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m     rex_train_VAF[beta], rex_test_VAF[beta] \u001b[39m=\u001b[39m LSTM_rex(train_firing_dict\u001b[39m=\u001b[39;49mtrain_firing_dict, train_EMG_orig\u001b[39m=\u001b[39;49mtrain_EMG_dict,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/17204/Documents/git/proc-kevin/LSTM/LSTM_exploration.ipynb#X66sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m         train_oh_dict\u001b[39m=\u001b[39;49mtrain_oh_dict, test_firing_dict\u001b[39m=\u001b[39;49mtest_firing_dict, \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/17204/Documents/git/proc-kevin/LSTM/LSTM_exploration.ipynb#X66sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m         test_EMG_dict\u001b[39m=\u001b[39;49mtest_EMG_dict, beta\u001b[39m=\u001b[39;49mbeta, EMG_name\u001b[39m=\u001b[39;49mEMG_name, return_VAF_flag\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, plot_VAF_flag\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/17204/Documents/git/proc-kevin/LSTM/LSTM_exploration.ipynb#X66sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mLSTM w/ REx Weighted, Beta=\u001b[39m\u001b[39m{\u001b[39;00mbeta\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/17204/Documents/git/proc-kevin/LSTM/LSTM_exploration.ipynb#X66sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m     wrex_train_VAF[beta], wrex_test_VAF[beta] \u001b[39m=\u001b[39m LSTM_rex_weighted(train_firing_dict \u001b[39m=\u001b[39m train_firing_dict, train_EMG_orig \u001b[39m=\u001b[39m train_EMG_dict, \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/17204/Documents/git/proc-kevin/LSTM/LSTM_exploration.ipynb#X66sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m         train_oh_dict \u001b[39m=\u001b[39m train_oh_dict, train_var_dict \u001b[39m=\u001b[39m train_var_dict, \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/17204/Documents/git/proc-kevin/LSTM/LSTM_exploration.ipynb#X66sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m         test_firing_dict\u001b[39m=\u001b[39mtest_firing_dict, test_EMG_dict \u001b[39m=\u001b[39m test_EMG_dict, \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/17204/Documents/git/proc-kevin/LSTM/LSTM_exploration.ipynb#X66sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m         beta\u001b[39m=\u001b[39mbeta, EMG_name\u001b[39m=\u001b[39mEMG_name, return_VAF_flag\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, plot_VAF_flag\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[1;32mc:\\Users\\17204\\Documents\\git\\proc-kevin\\LSTM\\LSTM_exploration.ipynb Cell 49\u001b[0m in \u001b[0;36mLSTM_rex\u001b[1;34m(train_firing_dict, train_EMG_orig, train_oh_dict, test_firing_dict, test_EMG_dict, EMG_name, beta, plot_sig_flag, plot_VAF_flag, return_VAF_flag)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/17204/Documents/git/proc-kevin/LSTM/LSTM_exploration.ipynb#X66sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m mdl\u001b[39m.\u001b[39madd(tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mDense(train_o\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/17204/Documents/git/proc-kevin/LSTM/LSTM_exploration.ipynb#X66sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m mdl\u001b[39m.\u001b[39mcompile(loss\u001b[39m=\u001b[39mvrex_loss, optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrmsprop\u001b[39m\u001b[39m'\u001b[39m, metrics\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmse\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/17204/Documents/git/proc-kevin/LSTM/LSTM_exploration.ipynb#X66sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m mdl\u001b[39m.\u001b[39;49mfit(train_i, train_o, epochs\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m, verbose\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/17204/Documents/git/proc-kevin/LSTM/LSTM_exploration.ipynb#X66sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m \u001b[39m# Get the predictions\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/17204/Documents/git/proc-kevin/LSTM/LSTM_exploration.ipynb#X66sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m train_preds \u001b[39m=\u001b[39m {}\n",
      "File \u001b[1;32mc:\\Users\\17204\\miniconda3\\envs\\MSDS\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\17204\\miniconda3\\envs\\MSDS\\lib\\site-packages\\keras\\engine\\training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1402\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1403\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   1404\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   1405\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[0;32m   1406\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m   1407\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m   1408\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1409\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1410\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1411\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\17204\\miniconda3\\envs\\MSDS\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\17204\\miniconda3\\envs\\MSDS\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\17204\\miniconda3\\envs\\MSDS\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\17204\\miniconda3\\envs\\MSDS\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2450\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2451\u001b[0m   (graph_function,\n\u001b[0;32m   2452\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2453\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2454\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\17204\\miniconda3\\envs\\MSDS\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1856\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1857\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1858\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1859\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1860\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1861\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1862\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1863\u001b[0m     args,\n\u001b[0;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1865\u001b[0m     executing_eagerly)\n\u001b[0;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\17204\\miniconda3\\envs\\MSDS\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    496\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 497\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    498\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    499\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    500\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    501\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    502\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    503\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    504\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    505\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    506\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    509\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    510\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\17204\\miniconda3\\envs\\MSDS\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_firing = {'Iso': Iso_train_firing, 'Mov': Mov_train_firing}\n",
    "test_firing = {'Iso': Iso_test_firing, 'Mov': Mov_test_firing, 'Spr': Spr_test_firing}\n",
    "train_EMG = {'Iso': Iso_train_EMG, 'Mov': Mov_train_EMG}\n",
    "test_EMG = {'Iso': Iso_test_EMG, 'Mov':Mov_test_EMG, 'Spr':Spr_test_EMG}\n",
    "\n",
    "ret_vals = LSTM_preprocess(train_firing, train_EMG, test_firing, test_EMG)\n",
    "\n",
    "train_firing_dict = ret_vals[0]\n",
    "train_EMG_dict = ret_vals[1]\n",
    "train_oh_dict = ret_vals[2]\n",
    "train_var_dict = ret_vals[3]\n",
    "test_firing_dict = ret_vals[4]\n",
    "test_EMG_dict = ret_vals[5]\n",
    "test_oh_dict = ret_vals[6]\n",
    "test_var_dict = ret_vals[7]\n",
    "\n",
    "\n",
    "print('Vanilla LSTM')\n",
    "van_train_VAF, van_test_VAF = LSTM_comparisons(train_firing_dict, train_EMG_dict,\n",
    "        test_firing_dict, test_EMG_dict, \n",
    "        EMG_name, return_VAF_flag=True, plot_VAF_flag=False)\n",
    "\n",
    "print('LSTM Weighted')\n",
    "weight_train_VAF, weight_test_VAF = LSTM_across_weighted(train_firing_dict=train_firing_dict, train_EMG_orig=train_EMG_dict,\n",
    "    train_var_dict=train_var_dict, test_firing_dict=test_firing_dict, \n",
    "    test_EMG_dict=test_EMG_dict, EMG_name=EMG_name, return_VAF_flag=True, plot_VAF_flag=False)\n",
    "\n",
    "rex_train_VAF = {}\n",
    "rex_test_VAF = {}\n",
    "wrex_train_VAF = {}\n",
    "wrex_test_VAF = {}\n",
    "for beta in np.logspace(0, 1000) - 1:\n",
    "    print(f'LSTM w/ REx, Beta={beta}')\n",
    "    rex_train_VAF[beta], rex_test_VAF[beta] = LSTM_rex(train_firing_dict=train_firing_dict, train_EMG_orig=train_EMG_dict,\n",
    "        train_oh_dict=train_oh_dict, test_firing_dict=test_firing_dict, \n",
    "        test_EMG_dict=test_EMG_dict, beta=beta, EMG_name=EMG_name, return_VAF_flag=True, plot_VAF_flag=False)\n",
    "\n",
    "\n",
    "    print(f'LSTM w/ REx Weighted, Beta={beta}')\n",
    "    wrex_train_VAF[beta], wrex_test_VAF[beta] = LSTM_rex_weighted(train_firing_dict = train_firing_dict, train_EMG_orig = train_EMG_dict, \n",
    "        train_oh_dict = train_oh_dict, train_var_dict = train_var_dict, \n",
    "        test_firing_dict=test_firing_dict, test_EMG_dict = test_EMG_dict, \n",
    "        beta=beta, EMG_name=EMG_name, return_VAF_flag=True, plot_VAF_flag=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train on everything, test on each"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM grid search\n",
    "\n",
    "Time to look at some non-linearities!\n",
    "\n",
    "Let's run through the grid search on hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, firing, EMG, _, _ = load_josh_mat(data['WmTrain'])\n",
    "\n",
    "log = LSTM_grid_search(firing, EMG, n_iter = 30, n_fold = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM with REx\n",
    "\n",
    "Run through the options, see what comes out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scratch Space\n",
    "Sometimes the variable viewer isn't very goood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting bits of code to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs/LSTM_exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorboard\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'file' is an invalid keyword argument for dumps()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\17204\\Documents\\git\\proc-kevin\\LSTM\\LSTM_exploration.ipynb Cell 59\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/17204/Documents/git/proc-kevin/LSTM/LSTM_exploration.ipynb#Y131sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m exportname \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mBetaComparisons.pkl\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/17204/Documents/git/proc-kevin/LSTM/LSTM_exploration.ipynb#Y131sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(exportname, \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m fid:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/17204/Documents/git/proc-kevin/LSTM/LSTM_exploration.ipynb#Y131sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     pickle\u001b[39m.\u001b[39;49mdumps([rex_train_VAF, rex_test_VAF, wrex_train_VAF, wrex_train_VAF], file\u001b[39m=\u001b[39;49mexportname)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'file' is an invalid keyword argument for dumps()"
     ]
    }
   ],
   "source": [
    "exportname = 'BetaComparisons.pkl'\n",
    "\n",
    "with open(exportname, 'w') as fid:\n",
    "    pickle.dump([rex_train_VAF, rex_test_VAF, wrex_train_VAF, wrex_train_VAF], )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('MSDS')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "e6f5ab44297089514ffa059ea0d83d6392bebfea7e191fb6b7f26c8412c9553b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
