{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM decoding exploration\n",
    "\n",
    "Going to be looking at using LSTMs (with potentially some changes to the cost function) to decode EMGs from cortical data. This is all based off work from Steph and Josh.\n",
    "\n",
    "\n",
    "Going to start with the old Jango data, then update from there as necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import loadmat\n",
    "from scipy.optimize import least_squares\n",
    "from matplotlib import pyplot as plt\n",
    "# import ipympl\n",
    "\n",
    "# we'll use ridge regression as a comparisson\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn import metrics\n",
    "\n",
    "from tkinter import Tk\n",
    "from tkinter import filedialog as fd # just so I don't have to repeatedly manually enter filenames\n",
    "\n",
    "# and tf stuff\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import backend as K # this was in Josh's version. Not sure why can't use numpy\n",
    "\n",
    "# datetime stuff for logs\n",
    "from datetime import datetime as dt\n",
    "\n",
    "\n",
    "# utility functions that I moved to the LSTM_utils.py file\n",
    "from LSTM_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# import ipympl\n",
    "%matplotlib qt5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# request the filename\n",
    "root = Tk()\n",
    "mat_fn = fd.askopenfilename(master=root,filetypes=[('matlab data','*.mat')])\n",
    "root.destroy()\n",
    "\n",
    "data = loadmat(mat_fn)\n",
    "\n",
    "# Training\n",
    "Iso_train_timestamps, Iso_train_firing, Iso_train_EMG, _, _, = load_josh_mat(data['IsoTrain'])\n",
    "Spr_train_timestamps, Spr_train_firing, Spr_train_EMG, _, _, = load_josh_mat(data['SprTrain'])\n",
    "Mov_train_timestamps, Mov_train_firing, Mov_train_EMG, _, _, = load_josh_mat(data['WmTrain'])\n",
    "\n",
    "# Testing\n",
    "Iso_test_timestamps, Iso_test_firing, Iso_test_EMG, _, _, = load_josh_mat(data['IsoTest'])\n",
    "Spr_test_timestamps, Spr_test_firing, Spr_test_EMG, _, _, = load_josh_mat(data['SprTest'])\n",
    "Mov_test_timestamps, Mov_test_firing, Mov_test_EMG, _, _, = load_josh_mat(data['WmTest'])\n",
    "\n",
    "\n",
    "# EMG names -- makes things easier later on\n",
    "EMG_name = Iso_test_EMG.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize the data\n",
    "\n",
    "Plot out some good information on the max and variances of each muscle. Should also look at something for the cortex, maybe depth of modulation or avg firing rates?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bar plots of representative values (max and 95th pctl) of different EMG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------\n",
    "# Max EMG values bar plot\n",
    "\n",
    "fig_emg_max, ax_emg_max = plt.subplots()\n",
    "i_muscles = np.arange(Mov_train_EMG.shape[1]) # indexing on the x axis\n",
    "bar_width = .25\n",
    "\n",
    "\n",
    "ax_emg_max.bar(i_muscles, np.max(Mov_train_EMG,axis=0), width = bar_width, label='Movement')\n",
    "ax_emg_max.bar(i_muscles+bar_width, np.max(Iso_train_EMG, axis=0), width = bar_width, label='Isometric')\n",
    "ax_emg_max.bar(i_muscles+bar_width*2, np.max(Spr_train_EMG, axis=0), width = bar_width, label='Spring')\n",
    "\n",
    "ax_emg_max.set_xticks(i_muscles+bar_width)\n",
    "ax_emg_max.set_xticklabels(Mov_train_EMG.columns)\n",
    "\n",
    "fig_emg_max.show()\n",
    "_ = ax_emg_max.legend()\n",
    "\n",
    "ax_emg_max.set_xlabel('Muscle')\n",
    "ax_emg_max.set_ylabel('Max Value')\n",
    "\n",
    "# For each bar in the chart, add a text label.\n",
    "for bar in ax_emg_max.patches:\n",
    "    # The text annotation for each bar should be its height.\n",
    "    bar_value = bar.get_height()\n",
    "    # Format the text with commas to separate thousands. You can do\n",
    "    # any type of formatting here though.\n",
    "    text = f'{bar_value:.02f}'\n",
    "    # This will give the middle of each bar on the x-axis.\n",
    "    text_x = bar.get_x() + bar.get_width() / 2\n",
    "    # get_y() is where the bar starts so we add the height to it.\n",
    "    text_y = np.max([bar.get_y() + bar_value, 0.01]) # keep it from going too far below zero, and disappearing\n",
    "    # If we want the text to be the same color as the bar, we can\n",
    "    # get the color like so:\n",
    "    bar_color = bar.get_facecolor()\n",
    "    # If you want a consistent color, you can just set it as a constant, e.g. #222222\n",
    "    ax_emg_max.text(text_x, text_y, text, ha='center', va='bottom', color=bar_color,\n",
    "            size=12)\n",
    "    \n",
    "for spine in ['right','top','bottom','left']:\n",
    "    ax_emg_max.spines[spine].set_visible(False)\n",
    "\n",
    "ax_emg_max.set_title('Maximum EMG Value')\n",
    "\n",
    "# --------------------------------------------\n",
    "# 95th percentile\n",
    "fig_emg_95, ax_emg_95 = plt.subplots()\n",
    "i_muscles = np.arange(Mov_train_EMG.shape[1]) # indexing on the x axis\n",
    "bar_width = .25\n",
    "\n",
    "\n",
    "ax_emg_95.bar(i_muscles, np.percentile(Mov_train_EMG, 95,axis=0), width = bar_width, label='Movement')\n",
    "ax_emg_95.bar(i_muscles+bar_width, np.percentile(Iso_train_EMG, 95, axis=0), width = bar_width, label='Isometric')\n",
    "ax_emg_95.bar(i_muscles+2*bar_width, np.percentile(Spr_train_EMG, 95, axis=0), width = bar_width, label='Spring')\n",
    "\n",
    "ax_emg_95.set_xticks(i_muscles+bar_width)\n",
    "ax_emg_95.set_xticklabels(Mov_train_EMG.columns)\n",
    "\n",
    "# fig_emg_95.show()\n",
    "_ = ax_emg_95.legend()\n",
    "\n",
    "ax_emg_95.set_xlabel('Muscle')\n",
    "ax_emg_95.set_ylabel('95th Percentile')\n",
    "\n",
    "# For each bar in the chart, add a text label.\n",
    "for bar in ax_emg_95.patches:\n",
    "    # The text annotation for each bar should be its height.\n",
    "    bar_value = bar.get_height()\n",
    "    # Format the text with commas to separate thousands. You can do\n",
    "    # any type of formatting here though.\n",
    "    text = f'{bar_value:.02f}'\n",
    "    # This will give the middle of each bar on the x-axis.\n",
    "    text_x = bar.get_x() + bar.get_width() / 2\n",
    "    # get_y() is where the bar starts so we add the height to it.\n",
    "    text_y = np.max([bar.get_y() + bar_value, 0.01]) # keep it from going too far below zero, and disappearing\n",
    "    # If we want the text to be the same color as the bar, we can\n",
    "    # get the color like so:\n",
    "    bar_color = bar.get_facecolor()\n",
    "    # If you want a consistent color, you can just set it as a constant, e.g. #222222\n",
    "    ax_emg_95.text(text_x, text_y, text, ha='center', va='bottom', color=bar_color,\n",
    "            size=12)\n",
    "\n",
    "\n",
    "for spine in ['right','top','bottom','left']:\n",
    "    ax_emg_95.spines[spine].set_visible(False)\n",
    "\n",
    "ax_emg_95.set_title('95th Percentile of EMG')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing mean firing rates of different conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_cort, ax_cort = plt.subplots(ncols=3)\n",
    "\n",
    "Wm_means = np.mean(Mov_train_firing, axis=0)\n",
    "Iso_means = np.mean(Iso_train_firing, axis=0)\n",
    "Spr_means = np.mean(Spr_train_firing, axis=0)\n",
    "\n",
    "\n",
    "\n",
    "# scatters between mean firing rates\n",
    "ax_cort[0].scatter(Wm_means, Iso_means, s=2)\n",
    "ax_cort[0].plot([0,40],[0,40],c='k', alpha=.3)\n",
    "ax_cort[1].scatter(Wm_means, Spr_means, s=2)\n",
    "ax_cort[1].plot([0,40],[0,40],c='k', alpha=.3)\n",
    "ax_cort[2].scatter(Iso_means, Spr_means, s=2)\n",
    "ax_cort[2].plot([0,40],[0,40],c='k', alpha=.3)\n",
    "\n",
    "\n",
    "# x and y labels\n",
    "ax_cort[0].set_xlabel('Movement')\n",
    "ax_cort[0].set_ylabel('Isometric')\n",
    "ax_cort[1].set_xlabel('Movement')\n",
    "ax_cort[1].set_ylabel('Spring')\n",
    "ax_cort[2].set_xlabel('Isometric')\n",
    "ax_cort[2].set_ylabel('Spring')\n",
    "\n",
    "# making the axes square and removing the spines\n",
    "for axis in ax_cort:\n",
    "    axis.set_aspect('equal',adjustable='box')\n",
    "    for spine in ['right','top','bottom','left']:\n",
    "        ax_emg_95.spines[spine].set_visible(False)\n",
    "    axis.set_title('Mean Firing Rates')\n",
    "\n",
    "\n",
    "fig_cort.set_label('Compared Mean Firing Rates across conditions')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same with the variance of the firing rates (thinking depth of modulation sort of thing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_cort, ax_cort = plt.subplots(ncols=3)\n",
    "\n",
    "Wm_vars = np.var(Mov_train_firing, axis=0)\n",
    "Iso_vars = np.var(Iso_train_firing, axis=0)\n",
    "Spr_vars = np.var(Spr_train_firing, axis=0)\n",
    "\n",
    "\n",
    "\n",
    "# scatters between var firing rates\n",
    "ax_cort[0].scatter(Wm_vars, Iso_vars, s=2)\n",
    "ax_cort[1].scatter(Wm_vars, Spr_vars, s=2)\n",
    "ax_cort[2].scatter(Iso_vars, Spr_vars, s=2)\n",
    "\n",
    "\n",
    "# x and y labels\n",
    "ax_cort[0].set_xlabel('Movement')\n",
    "ax_cort[0].set_ylabel('Isometric')\n",
    "ax_cort[1].set_xlabel('Movement')\n",
    "ax_cort[1].set_ylabel('Spring')\n",
    "ax_cort[2].set_xlabel('Isometric')\n",
    "ax_cort[2].set_ylabel('Spring')\n",
    "\n",
    "# making the axes square and removing the spines\n",
    "for axis in ax_cort:\n",
    "    axis.set_aspect('equal',adjustable='box')\n",
    "    max_lim = np.max([axis.get_xlim()[1],axis.get_ylim()[1]])\n",
    "    min_lim = np.min([axis.get_xlim()[0],axis.get_ylim()[1]])\n",
    "    axis.set_xlim([min_lim, max_lim])\n",
    "    axis.set_ylim([min_lim, max_lim])\n",
    "    for spine in ['right','top','bottom','left']:\n",
    "        axis.spines[spine].set_visible(False)\n",
    "    axis.set_title('Variance of Firing Rates')\n",
    "    axis.plot([min_lim, max_lim],[min_lim, max_lim],c='k', alpha=.3)\n",
    "\n",
    "fig_cort.set_label('Compared var Firing Rates across conditions')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model building \n",
    "Look through a couple of different model types, look to see how they are trained\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear with Static Non-linearity\n",
    "\n",
    "Using the lab default -- build a wiener filter, fit it, then fit with a static polynomial on top of the form\n",
    "\n",
    "$Ax^2 + Bx + C$\n",
    "\n",
    "Where $x$ is the original EMG prediction, and the output is the new EMG prediction\n",
    "\n",
    "Alternatively, I have also allowed to predict using an exponential activation \n",
    "\n",
    "$Ae^{Bx} + C$\n",
    "\n",
    "Also giving the options for a sigmoid\n",
    "\n",
    "\n",
    "**Starting with defining our nonlinearity methods**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using scipy's least_squares:\n",
    "def non_linearity(p, y_pred, nonlinear_type):\n",
    "    if nonlinear_type == 'poly':\n",
    "        return p[0] + p[1]*y_pred + p[2]*y_pred**2\n",
    "    elif nonlinear_type == 'exponential':\n",
    "        return p[0]*np.exp(p[1]*y_pred) + p[2]\n",
    "    elif nonlinear_type == 'sigmoid':\n",
    "        return p[1] * 1/(1 + np.exp(-10*(y_pred-p[0])))\n",
    "\n",
    "def non_linearity_residuals(p, y_pred, y_act, nonlinear_type):\n",
    "    if nonlinear_type == 'poly':\n",
    "        return y_act - (p[0] + p[1]*y_pred + p[2]*y_pred**2)\n",
    "    elif nonlinear_type == 'exponential':\n",
    "        return y_act - (p[0]*np.exp(p[1]*y_pred) + p[2])\n",
    "    elif nonlinear_type == 'sigmoid':\n",
    "        return y_act - (p[1] * 1/(1 + np.exp(-10*(y_pred-p[0]))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next a function that compares Wiener filter models with Wiener cascades, reports the VAF (Cooefficient of Determination) and gives plots for the validation predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a function that we can just call multiple times, so then we can just quickly run through all of the different combinations\n",
    "\n",
    "\n",
    "def basic_decoder_comparison(train_firing, train_EMG, retrain_firing, retrain_EMG, test_firing, test_EMG, test_timestamps, nonlinear_type, save_plot=True):\n",
    "    wiener_input = pd.DataFrame() # empty dataframe\n",
    "    n_lags = 10 # number of lags\n",
    "    for ii in np.arange(n_lags): # create the lagged dataframe\n",
    "        col_dict = dict(zip(train_firing.columns, train_firing.columns+f\"_lag{ii}\"))\n",
    "        wiener_input = wiener_input.join(train_firing.shift(-ii, fill_value=0).rename(columns=col_dict), how='outer')\n",
    "\n",
    "    wiener_test = pd.DataFrame() # empty dataframe\n",
    "    for ii in np.arange(n_lags): # create the lagged dataframe\n",
    "        col_dict = dict(zip(test_firing.columns, test_firing.columns+f\"_lag{ii}\"))\n",
    "        wiener_test = wiener_test.join(test_firing.shift(-ii, fill_value=0).rename(columns=col_dict), how='outer')\n",
    "        \n",
    "    wiener_retrain = pd.DataFrame() # empty dataframe\n",
    "    for ii in np.arange(n_lags): # create the lagged dataframe\n",
    "        col_dict = dict(zip(retrain_firing.columns, retrain_firing.columns+f\"_lag{ii}\"))\n",
    "        wiener_retrain = wiener_retrain.join(retrain_firing.shift(-ii, fill_value=0).rename(columns=col_dict), how='outer')\n",
    "\n",
    "\n",
    "\n",
    "    if nonlinear_type == 'poly':\n",
    "        init_pred = [.1, .1, .1]\n",
    "    elif nonlinear_type == 'exponential':\n",
    "        init_pred = [1, .1, .2]\n",
    "    elif nonlinear_type == 'sigmoid':\n",
    "        init_pred = [.1, .5]\n",
    "\n",
    "    mdl_A = linear_model.LinearRegression(fit_intercept=True)\n",
    "    mdl_B = {} # a dictionary of numpy polynomials. Probably a better way to do this, maybe Xuan's method... oh well\n",
    "\n",
    "    mdl_A.fit(wiener_input, train_EMG)# fit the first model\n",
    "    prefit_EMG = mdl_A.predict(wiener_input) # get the initially predicted EMGs\n",
    "    retrain_pred = mdl_A.predict(wiener_retrain) # from a training set on a separate condition -- to properly hold out test data\n",
    "    prefit_VAF = metrics.explained_variance_score(train_EMG, prefit_EMG, multioutput='raw_values')\n",
    "    nonlin_EMG = np.zeros(prefit_EMG.shape)\n",
    "\n",
    "    print('Training Results\\n')\n",
    "\n",
    "    for ii in np.arange(len(train_EMG.columns)):\n",
    "        muscle = train_EMG.columns[ii]\n",
    "        mdl_B[muscle] = least_squares(non_linearity_residuals, init_pred, args=(prefit_EMG[:,ii], train_EMG.iloc[:,ii].to_numpy(), nonlinear_type)).x\n",
    "        # print('--------------------------------------------------------')\n",
    "        print(muscle)\n",
    "        print(f\"\\tLinear VAF: {prefit_VAF[ii]:.03f}\")\n",
    "        nonlin_EMG[:,ii] = non_linearity(mdl_B[muscle],(prefit_EMG[:,ii]), nonlinear_type)\n",
    "        print(f\"\\tNonLinear VAF: {metrics.explained_variance_score(train_EMG.iloc[:,ii],nonlin_EMG[:,ii]):.03f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # predicting the test set\n",
    "    prefit_test = mdl_A.predict(wiener_test)\n",
    "    prefit_test_VAF = metrics.explained_variance_score(test_EMG, prefit_test, multioutput='raw_values')\n",
    "    nonlin_test = np.zeros(prefit_test.shape)\n",
    "    nonlin_within_test = np.zeros(prefit_test.shape)\n",
    "    nonlin_VAF = np.zeros(prefit_test_VAF.shape)\n",
    "    nonlin_within_VAF = np.zeros(prefit_test_VAF.shape)\n",
    "    mdl_C = {} # for a separate non-linearity, built for the second condition.\n",
    "\n",
    "    print('\\n------------------------------------------------------------\\n')\n",
    "    print('Testing Results\\n')\n",
    "    for ii in np.arange(len(train_EMG.columns)):\n",
    "        muscle = test_EMG.columns[ii]\n",
    "        mdl_C[muscle] = least_squares(non_linearity_residuals, init_pred, args=(retrain_pred[:,ii], retrain_EMG.iloc[:,ii].to_numpy(), nonlinear_type)).x\n",
    "        # print('--------------------------------------------------------')\n",
    "        print(muscle)\n",
    "        print(f\"\\tLinear VAF: {prefit_test_VAF[ii]:.03f}\")\n",
    "        nonlin_test[:,ii] = non_linearity(mdl_B[muscle],(prefit_test[:,ii]), nonlinear_type)\n",
    "        nonlin_within_test[:,ii] = non_linearity(mdl_C[muscle],(prefit_test[:,ii]), nonlinear_type)\n",
    "        nonlin_VAF[ii] = metrics.explained_variance_score(test_EMG.iloc[:,ii],nonlin_test[:,ii])\n",
    "        nonlin_within_VAF[ii] = metrics.explained_variance_score(test_EMG.iloc[:,ii],nonlin_within_test[:,ii])\n",
    "        print(f\"\\tPre-built Nonlinearity VAF: {nonlin_VAF[ii]:.03f}\")\n",
    "        print(f\"\\tRe-built Nonlinearity VAF: {nonlin_within_VAF[ii]:.03f}\")\n",
    "\n",
    "    # Plotting the test data -- so that we can see how  the non-linearities act between types\n",
    "    n_rows = int(np.ceil(np.sqrt(len(train_EMG.columns))))\n",
    "    fig_nl_test, ax_nl_test = plt.subplots(nrows=n_rows, ncols=n_rows, sharex=True, constrained_layout=True)\n",
    "\n",
    "    for muscle_ii in np.arange(len(train_EMG.columns)):\n",
    "        row_i = int(muscle_ii//n_rows)\n",
    "        col_i = int(muscle_ii%n_rows)\n",
    "        ax_nl_test[row_i,col_i].plot(test_timestamps, test_EMG.iloc[:,muscle_ii], label='Recorded')\n",
    "        ax_nl_test[row_i,col_i].plot(test_timestamps,prefit_test[:,muscle_ii], label=f'Linear VAF: {prefit_test_VAF[muscle_ii]:.03f}')\n",
    "        ax_nl_test[row_i,col_i].plot(test_timestamps,nonlin_test[:,muscle_ii], label=f'NonLin VAF: {nonlin_VAF[muscle_ii]:.03f}')\n",
    "        ax_nl_test[row_i,col_i].plot(test_timestamps,nonlin_within_test[:,muscle_ii], label=f'Rebuilt NonLin VAF: {nonlin_within_VAF[muscle_ii]:.03f}')\n",
    "        ax_nl_test[row_i,col_i].set_title(f\"{test_EMG.columns[muscle_ii]}\")\n",
    "        ax_nl_test[row_i,col_i].set_xlabel(f\"Time (s)\")\n",
    "        ax_nl_test[row_i,col_i].set_ylabel(\"EMG envelope\")\n",
    "        \n",
    "        _ = ax_nl_test[row_i,col_i].legend()\n",
    "\n",
    "        # turn off the spines\n",
    "        for spine in ['right','top','bottom','left']:\n",
    "            ax_nl_test[row_i,col_i].spines[spine].set_visible(False)\n",
    "            \n",
    "    if save_plot:\n",
    "        fig_nl_test.savefig('Wiener_Cascade_Comparison.svg')\n",
    "\n",
    "    # let's also plot the VAFs in a clean manner so that it's easy to compare\n",
    "    fig_vaf, ax_vaf = plt.subplots()\n",
    "    i_muscles = np.arange(len(test_EMG.columns)) # indexing on the x axis\n",
    "    bar_width = .25\n",
    "\n",
    "    ax_vaf.bar(i_muscles, prefit_test_VAF, width = bar_width, label='Linear')\n",
    "    ax_vaf.bar(i_muscles + bar_width, nonlin_VAF, width = bar_width, label='Nonlinear')\n",
    "    ax_vaf.bar(i_muscles + 2*bar_width, nonlin_within_VAF, width = bar_width, label='Rebuilt Nonlinear')\n",
    "\n",
    "    ax_vaf.set_xticks(i_muscles + 1*bar_width)\n",
    "    ax_vaf.set_xticklabels(test_EMG.columns)\n",
    "\n",
    "    ax_vaf.set_ylim([-.05, 1.05])\n",
    "    ax_vaf.set_xlabel('Muscle')\n",
    "    ax_vaf.set_ylabel('Coefficient of Determination')\n",
    "\n",
    "    ax_vaf.legend()\n",
    "\n",
    "    # For each bar in the chart, add a text label.\n",
    "    for bar in ax_vaf.patches:\n",
    "        # The text annotation for each bar should be its height.\n",
    "        bar_value = bar.get_height()\n",
    "        # Format the text with commas to separate thousands. You can do\n",
    "        # any type of formatting here though.\n",
    "        text = f'{bar_value:.02f}'\n",
    "        # This will give the middle of each bar on the x-axis.\n",
    "        text_x = bar.get_x() + bar.get_width() / 2\n",
    "        # get_y() is where the bar starts so we add the height to it.\n",
    "        text_y = np.max([bar.get_y() + bar_value, 0.01]) # keep it from going too far below zero, and disappearing\n",
    "        # If we want the text to be the same color as the bar, we can\n",
    "        # get the color like so:\n",
    "        bar_color = bar.get_facecolor()\n",
    "        # If you want a consistent color, you can just set it as a constant, e.g. #222222\n",
    "        ax_vaf.text(text_x, text_y, text, ha='center', va='bottom', color=bar_color,\n",
    "                size=12)\n",
    "\n",
    "    # turn off the spines\n",
    "    for spine in ['right','top','bottom','left']:\n",
    "        ax_vaf.spines[spine].set_visible(False)\n",
    "\n",
    "\n",
    "    if save_plot:\n",
    "        fig_vaf.savefig('Wiener_VAF.svg')\n",
    "\n",
    "    return nonlin_EMG\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_comparisons(train_firing_dict:dict, train_EMG_dict:dict, test_firing_dict:dict, test_EMG_dict:dict, EMG_name):\n",
    "    # hyper params\n",
    "    layer_0_units = 300\n",
    "    drop_in = .25     # input dropout percentage for LSTM layer\n",
    "    drop_rec = 0    # recurrent dropout for LSTM\n",
    "    drop_lay = .15    # dropout layer?\n",
    "\n",
    "\n",
    "    # append the variance to the EMG values\n",
    "    n_EMGs = len(EMG_name)\n",
    "    seq_len = train_firing_dict['Combined'].shape[1] # num of lags\n",
    "    n_neurons = train_firing_dict['Combined'].shape[2]\n",
    "\n",
    "    # pull out the \"Combined\" conditions for training\n",
    "    train_i = train_firing_dict['Combined']\n",
    "    train_o = train_EMG_dict['Combined']\n",
    "\n",
    "        # Set up the LSTMs\n",
    "    mdl = tf.keras.models.Sequential()\n",
    "\n",
    "    mdl.add(tf.keras.layers.LSTM(layer_0_units, input_shape = (seq_len,n_neurons), dropout=drop_in, recurrent_dropout=drop_rec))\n",
    "    if drop_lay:\n",
    "        mdl.add(tf.keras.layers.Dropout(drop_lay)) # dropout layer if wanted\n",
    "    mdl.add(tf.keras.layers.Dense(n_EMGs)) # try with linear -- how does it compare?\n",
    "    mdl.compile(loss='mse', optimizer='rmsprop', metrics=['MeanAbsoluteError'])\n",
    "\n",
    "    mdl.fit(train_i, train_o, epochs=50, verbose=False)\n",
    "\n",
    "    train_preds = {}\n",
    "    train_VAFs = {}\n",
    "    test_preds = {}\n",
    "    test_VAFs = {}\n",
    "\n",
    "    for cond in train_firing_dict.keys():\n",
    "        train_preds[cond] = mdl.predict(train_firing_dict[cond])\n",
    "        train_VAFs[cond] = metrics.r2_score(train_EMG_dict[cond][:,:n_EMGs], train_preds[cond][:,:n_EMGs], multioutput='raw_values')\n",
    "\n",
    "        if cond != 'Combined': # don't really care about the \"combined\" test case\n",
    "            test_preds[cond] = mdl.predict(test_firing_dict[cond])\n",
    "            test_VAFs[cond] = metrics.r2_score(test_EMG_dict[cond][:,:n_EMGs], test_preds[cond][:,:n_EMGs], multioutput='raw_values')\n",
    "\n",
    "\n",
    "    print('----------------------------------------')\n",
    "    for ii_name, name in enumerate(EMG_name):\n",
    "        print(name)\n",
    "        for in_name, in_vaf in train_VAFs.items():\n",
    "            print(f\"\\tTrain VAF for {in_name}: {in_vaf[ii_name]}\")\n",
    "        for out_name,out_vaf in test_VAFs.items():\n",
    "            print(f\"\\tTest VAF for {out_name}: {out_vaf[ii_name]}\")\n",
    "\n",
    "\n",
    "    plot_rec_pred(train_EMG_dict, train_preds, EMG_name, train_VAFs, title_append = 'training set')\n",
    "    plot_rec_pred(test_EMG_dict, test_preds, EMG_name, test_VAFs, title_append = 'testing set')\n",
    "\n",
    "    plot_VAFs(train_VAFs, test_VAFs, EMG_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Custom Loss functions\n",
    "\n",
    "First the weighted loss function. This one calculates the MSE, but weights the value for each point in time by the variance of that particular task. This balances the training so that the model is able to train for conditions with different EMG ranges (the whole idea behind our system...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weight the losses by the std of that particular range in time and muscle.\n",
    "# for hybrid decoders\n",
    "def hybrid_weight_loss(target, pred):\n",
    "    # inputs: \n",
    "    #         target is the recorded data, plus the weights since this needs to be callable by tf\n",
    "    #                First half of the columns of the data will be EMG, second half will be the weights\n",
    "    #         pred   is the current prediction values\n",
    "    num_targets = K.shape(target)[1]//2 # number of cols / 2\n",
    "    err = (target[:, :num_targets] - pred[:,:num_targets]) # subtract the values\n",
    "    se = tf.divide(K.square(err), target[:,num_targets:]) # multiply the square error by the gains\n",
    "    mse = K.mean(se, axis=-1)\n",
    "#     tf.print(f\"Error Shape: {mse.shape}\")\n",
    "    \n",
    "    return mse\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next is the variance Risk Extrapolation (V-REx) from Krueger et al 2021. The purpose of this is to maximize the out-of-distribution generalization. This places a penalty on the variance of the risk (MSE as defined...)\n",
    "\n",
    "$ R_{V-REx}(\\theta) = \\beta * \\sigma^2(R_1(\\theta)....R_m(\\theta)) + \\sum_{e=1}^{m}R_e(\\theta) $\n",
    "\n",
    "Where risk is defined as \n",
    " $ R^2 = \\sum_{i=0}^{I}\\frac{(\\hat{y_i}-y_i)^2}{I} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vREx loss function\n",
    "def vrex_loss(target, pred):\n",
    "    # from the Risk Extrapolation paper\n",
    "    B = 0 #\n",
    "    # B = .5 #\n",
    "    # B = 1 #\n",
    "#     B = 5 #\n",
    "    # B = 10 #\n",
    "    # B = 50 #\n",
    "    # B = 100 #\n",
    "    \n",
    "    err = target[:,:-1] - pred[:,:-1] # without the condition flag\n",
    "    se_musc = K.square(err) # squared error\n",
    "    mse_musc = tf.expand_dims(K.mean(se_musc, axis=-1),-1) # mean squared error for each sample\n",
    "    \n",
    "    # now create a one-hot matrix for timestamps with a one for the appropriate condition\n",
    "    conditions = target[:,-1] # condition flag\n",
    "    u_conds,i_conds = tf.unique(conditions)\n",
    "    cond_oh = tf.transpose(tf.one_hot(i_conds, len(u_conds))) # create a mask the same size as the risk\n",
    "    \n",
    "    # split up the risks (MSE for right now) per condition\n",
    "    sum_risks = tf.matmul(cond_oh,mse_musc) # this gives us the per-condition sum of MSEs\n",
    "    risks = tf.math.divide(sum_risks, K.sum(cond_oh, axis=1)) # and this should average them\n",
    "\n",
    "    \n",
    "    rex = B*K.var(risks) + K.sum(risks) # and now to run the risk extrapolation step\n",
    "\n",
    "    return rex\n",
    "    # return mse_musc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vrex_weighted(target, pred):\n",
    "    # weighting the risks based on the var of the EMG\n",
    "    # For this, we will bring in an array of Tx(2*M+1) \n",
    "    # where M is the number of muscles and the extra column is for a flag\n",
    "\n",
    "    # define the balance of mean and variance of risk\n",
    "    B = 0 #\n",
    "#     B = .5 #\n",
    "#     B = 1 #\n",
    "#     B = 5 #\n",
    "#     B = 10 #\n",
    "#     B = 50 #\n",
    "#     B = 100 #\n",
    "    \n",
    "    # number of muscles\n",
    "    muscles = target.shape[1]//2 # find that value of M\n",
    "    \n",
    "    \n",
    "    err = target[:,:muscles] - pred[:,:muscles] # find the error\n",
    "    se_musc = K.square(err) # square error per muscle per timepoint\n",
    "    se = tf.expand_dims(K.sum(tf.multiply(err, target[:,muscles:-1]),axis=1),axis=-1) # take a weighted sum  of muscles per ts\n",
    "#     tf.print(f\"se shape:{se.shape}\")\n",
    "    \n",
    "    \n",
    "    # separate the conditions based on the flag\n",
    "    flag = target[:,-1] # last column\n",
    "#     risks = [K.mean(se[flag==C]) for C,_ in tf.unique(flag)]\n",
    "    u_flag,i_flag = tf.unique(flag) # for another one-hot matrix\n",
    "    flag_mask = tf.one_hot(i_flag, len(u_flag), axis=0) # mask for each condition -- CxT\n",
    "#     tf.print(f\"flag_mask shape: {flag_mask.shape}\")\n",
    "\n",
    "    split_se = tf.matmul(flag_mask, se) # this should give us a Cx1 array\n",
    "    # need to get the mean per condition, and samples/condition changes\n",
    "    # depending on the batch. the flag mask has already counted for us :)\n",
    "    risks = tf.math.divide(split_se, K.sum(flag_mask, axis=0))\n",
    "#     split_risk = tf.matmul(var_oh, mse_musc)\n",
    "#     weighted_risk = tf.multiply(tf.expand_dims(u_var, axis=-1), split_risk)\n",
    "#     risks = tf.math.divide(weighted_risk, K.sum(var_oh, axis=1)) # get the mean\n",
    "\n",
    "    rex = B*K.var(risks) + K.sum(risks)\n",
    "\n",
    "#     return rex\n",
    "    return K.mean(se_musc, axis=-1)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_across_weighted(train_firing_dict: dict, train_EMG_orig: dict, train_var_dict: dict, test_firing_dict: dict, test_EMG_dict: dict, EMG_name):\n",
    "    # hyper params\n",
    "    layer_0_units = 300\n",
    "    drop_in = .25     # input dropout percentage for LSTM layer\n",
    "    drop_rec = 0    # recurrent dropout for LSTM\n",
    "    drop_lay = .15    # dropout layer?\n",
    "\n",
    "\n",
    "    # append the variance to the EMG values\n",
    "    n_EMGs = len(EMG_name)\n",
    "    seq_len = train_firing_dict['Combined'].shape[1] # num of lags\n",
    "    n_neurons = train_firing_dict['Combined'].shape[2]\n",
    "    train_EMG_dict = {}\n",
    "    for ii_cond, cond in enumerate(train_EMG_orig.keys()):\n",
    "        train_EMG_dict[cond] = train_EMG_orig[cond].copy()\n",
    "        train_EMG_dict[cond] = np.append(train_EMG_dict[cond], train_var_dict[cond], axis=1)\n",
    "\n",
    "    # pull out the \"Combined\" conditions for training\n",
    "    train_i = train_firing_dict['Combined']\n",
    "    train_o = train_EMG_dict['Combined']\n",
    "\n",
    "        # Set up the LSTMs\n",
    "    mdl = tf.keras.models.Sequential()\n",
    "\n",
    "    mdl.add(tf.keras.layers.LSTM(layer_0_units, input_shape = (seq_len,n_neurons), dropout=drop_in, recurrent_dropout=drop_rec))\n",
    "    if drop_lay:\n",
    "        mdl.add(tf.keras.layers.Dropout(drop_lay)) # dropout layer if wanted\n",
    "    mdl.add(tf.keras.layers.Dense(n_EMGs*2)) # try with linear -- how does it compare?\n",
    "    mdl.compile(loss=hybrid_weight_loss, optimizer='rmsprop', metrics=['MeanAbsoluteError'])\n",
    "\n",
    "    mdl.fit(train_i, train_o, epochs=50, verbose=False)\n",
    "\n",
    "    train_preds = {}\n",
    "    train_VAFs = {}\n",
    "    test_preds = {}\n",
    "    test_VAFs = {}\n",
    "\n",
    "    for cond in train_firing_dict.keys():\n",
    "        train_preds[cond] = mdl.predict(train_firing_dict[cond])\n",
    "        train_VAFs[cond] = metrics.r2_score(train_EMG_dict[cond][:,:n_EMGs], train_preds[cond][:,:n_EMGs], multioutput='raw_values')\n",
    "\n",
    "        if cond != 'Combined': # don't really care about the \"combined\" test case\n",
    "            test_preds[cond] = mdl.predict(test_firing_dict[cond])\n",
    "            test_VAFs[cond] = metrics.r2_score(test_EMG_dict[cond][:,:n_EMGs], test_preds[cond][:,:n_EMGs], multioutput='raw_values')\n",
    "\n",
    "\n",
    "    print('----------------------------------------')\n",
    "    for ii_name, name in enumerate(EMG_name):\n",
    "        print(name)\n",
    "        for in_name, in_vaf in train_VAFs.items():\n",
    "            print(f\"\\tTrain VAF for {in_name}: {in_vaf[ii_name]}\")\n",
    "        for out_name,out_vaf in test_VAFs.items():\n",
    "            print(f\"\\tTest VAF for {out_name}: {out_vaf[ii_name]}\")\n",
    "\n",
    "\n",
    "    plot_rec_pred(train_EMG_dict, train_preds, EMG_name, train_VAFs, title_append = 'training set')\n",
    "    plot_rec_pred(test_EMG_dict, test_preds, EMG_name, test_VAFs, title_append = 'testing set')\n",
    "\n",
    "    plot_VAFs(train_VAFs, test_VAFs, EMG_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_grid_search(firing, EMG, n_iter = 150, n_fold = 10, n_epochs = 20, unit_range = [100, 400], drop_in_range = [0,.5], drop_rec_range = [0,.5], drop_lay_range = [0,.5], seq_range=[5,20], plot=True):\n",
    "    # Runs a monte-carlo style grid search on hyper parameters\n",
    "    # It will run mfxval, so there is no need for a separate training group\n",
    "    #\n",
    "    #  This will allow me to compare the number of lstm units, drop percentages,\n",
    "    #  batch and sequence sizes, etc.\n",
    "    \n",
    "    EMG_names = EMG.columns\n",
    "    cols = [f\"{name}_train_VAF\" for name in EMG_names]\n",
    "    cols += [f'{name}_test_VAF' for name in EMG_names]\n",
    "    cols += ['n_units','drop_in','drop_rec','drop_lay','seq_len']\n",
    "    log = pd.DataFrame(columns=cols)\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir='./logs/LSTM_exploration', histogram_freq=1)\n",
    "\n",
    "    \n",
    "    n_neurons = firing.shape[1] # number of neurons\n",
    "    n_EMGs = EMG.shape[1]\n",
    "    \n",
    "    # get the indices of the folds\n",
    "    kf = KFold(n_splits=n_fold, random_state=None, shuffle=False) # working in chunks, not random indices\n",
    "#     train_idx,test_idx = kf.split(firing) # get the indices. Won't split until later, since we will need to set up the sequences each round\n",
    "    \n",
    "    # intiialize the random number generator for the monte carlo\n",
    "    rng = np.random.default_rng()\n",
    "    \n",
    "    for iter in np.arange(n_iter):\n",
    "        layer_0_units = rng.integers(unit_range[0],unit_range[1])\n",
    "        drop_in = rng.uniform(drop_in_range[0], drop_in_range[1])\n",
    "        drop_rec = rng.uniform(drop_rec_range[0], drop_rec_range[1])\n",
    "        drop_lay = rng.uniform(drop_lay_range[0], drop_lay_range[1])\n",
    "        seq_len = rng.integers(seq_range[0], seq_range[1])\n",
    "        \n",
    "        rnn_i = np.ndarray((firing.shape[0], seq_len, firing.shape[1]))\n",
    "        for ii in np.arange(seq_len):\n",
    "            rnn_i[:,ii,:] = firing.shift(-ii, fill_value=0).to_numpy()\n",
    "        \n",
    "        \n",
    "        train_VAFs = np.zeros((n_fold, n_EMGs))\n",
    "        test_VAFs = np.zeros((n_fold, n_EMGs))\n",
    "        \n",
    "        log_entry = {'n_units':layer_0_units, 'drop_in':drop_in, 'drop_rec':drop_rec,\\\n",
    "                        'drop_lay':drop_lay, 'seq_len':seq_len}\n",
    "        \n",
    "        fold_idx = 0\n",
    "        for train_idx,test_idx in kf.split(firing):\n",
    "\n",
    "            rnn_train_i = np.zeros((len(train_idx),seq_len, firing.shape[1]))\n",
    "            rnn_test_i = np.zeros((len(test_idx),seq_len, firing.shape[1]))\n",
    "            rnn_train_o = EMG.iloc[train_idx,:].to_numpy()\n",
    "            rnn_test_o = EMG.iloc[test_idx,:].to_numpy()\n",
    "            \n",
    "            # split training and testing inputs\n",
    "            rnn_train_i = rnn_i[train_idx,:,:]\n",
    "            rnn_test_i = rnn_i[test_idx,:,:]\n",
    "\n",
    "\n",
    "            # normalize the EMGs\n",
    "            EMG_std = np.std(rnn_train_o, axis=0)\n",
    "            for ii in np.arange(rnn_train_o.shape[1]):\n",
    "                rnn_train_o[:,ii] = rnn_train_o[:,ii]/EMG_std[ii]\n",
    "                rnn_test_o[:,ii] = rnn_test_o[:,ii]/EMG_std[ii]\n",
    "\n",
    "            # Set up the LSTMs\n",
    "            mdl = tf.keras.models.Sequential()\n",
    "\n",
    "\n",
    "            mdl.add(tf.keras.layers.LSTM(layer_0_units, input_shape = (seq_len,n_neurons), dropout=drop_in, recurrent_dropout=drop_rec))\n",
    "            if drop_lay:\n",
    "                mdl.add(tf.keras.layers.Dropout(drop_lay)) # dropout layer if wanted\n",
    "        #     mdl.add(tf.keras.layers.Dense(n_EMGs, activation='relu')) # dense combination layer\n",
    "            mdl.add(tf.keras.layers.Dense(n_EMGs)) # dense combination layer\n",
    "            mdl.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "            mdl.fit(rnn_train_i, rnn_train_o, epochs=n_epochs, verbose=False, callbacks=[tensorboard_callback])\n",
    "\n",
    "\n",
    "            train_pred = mdl.predict(rnn_train_i, verbose=False)\n",
    "            test_pred = mdl.predict(rnn_test_i, verbose=False)\n",
    "            train_VAFs[fold_idx,:] = metrics.explained_variance_score(rnn_train_o, train_pred, multioutput='raw_values')\n",
    "            test_VAFs[fold_idx,:] = metrics.explained_variance_score(rnn_test_o, test_pred, multioutput='raw_values')\n",
    "            \n",
    "            fold_idx += 1\n",
    "            \n",
    "        # store the VAFs in the log entry\n",
    "        for emg_iter,emg_name in enumerate(EMG_names):\n",
    "            log_entry[f\"{emg_name}_train_VAF\"] = np.mean(train_VAFs[:,emg_iter])\n",
    "            log_entry[f\"{emg_name}_test_VAF\"] = np.mean(test_VAFs[:,emg_iter])\n",
    "        \n",
    "        \n",
    "#         return log_entry\n",
    "#         print(pd.DataFrame.from_records([log_entry]))\n",
    "        log = pd.concat([log,pd.DataFrame.from_records([log_entry])], ignore_index=True)\n",
    "        print(f\"Looped iteration {iter} of {n_iter}\")\n",
    "        \n",
    "    return log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_rex(train_firing_dict: dict, train_EMG_orig: dict, train_oh_dict:dict, test_firing_dict: dict, test_EMG_dict: dict, EMG_name, beta=5):\n",
    "\n",
    "    # hyper params\n",
    "    layer_0_units = 300\n",
    "    drop_in = .25     # input dropout percentage for LSTM layer\n",
    "    drop_rec = 0    # recurrent dropout for LSTM\n",
    "    drop_lay = .15    # dropout layer?\n",
    "\n",
    "    # append the variance to the EMG values\n",
    "    n_EMGs = len(EMG_name)\n",
    "    seq_len = train_firing_dict['Combined'].shape[1] # num of lags\n",
    "    n_neurons = train_firing_dict['Combined'].shape[2]\n",
    "    train_EMG_dict = {}\n",
    "    for ii_cond, cond in enumerate(train_EMG_orig.keys()):\n",
    "        train_EMG_dict[cond] = train_EMG_orig[cond]\n",
    "        train_EMG_dict[cond] = np.append(train_EMG_dict[cond], train_oh_dict[cond], axis=1)\n",
    "\n",
    "    # pull out the \"Combined\" conditions for training\n",
    "    train_i = train_firing_dict['Combined'] \n",
    "    train_o = train_EMG_dict['Combined']\n",
    "\n",
    "    # define the vrex loss function -- so that we can dynamically change the Beta value etc\n",
    "    def vrex_loss(target, pred):\n",
    "        # from the Risk Extrapolation paper\n",
    "        B = beta #\n",
    "\n",
    "        n_target = n_EMGs\n",
    "        err = target[:,:n_target] - pred[:,:n_target] # without the condition flag\n",
    "        se = K.square(err) # squared error -- TxM\n",
    "        mse = K.mean(se, axis=-1) # mean squared error for each sample -- Tx1\n",
    "\n",
    "        # now pull in the one-hot matrix for flagging\n",
    "        cond_oh = tf.transpose(target[:,n_target:]) # transpose it so that we can add everything later CxT\n",
    "\n",
    "        # risk for each condition -- ie MSE for each condition\n",
    "        risk = tf.matmul(cond_oh,se) # Cx1\n",
    "        risk = tf.divide(risk, tf.reduce_sum(cond_oh, 1, keepdims=1)) # mean to account for differen num samples\n",
    "\n",
    "        rex = B*K.var(risk) + K.sum(risk)\n",
    "\n",
    "        return rex\n",
    "\n",
    "    # create the model\n",
    "    mdl = tf.keras.models.Sequential()\n",
    "    # add the LSTM layer\n",
    "    mdl.add(tf.keras.layers.LSTM(layer_0_units, input_shape = (seq_len,n_neurons), dropout=drop_in, recurrent_dropout=drop_rec))\n",
    "    mdl.add(tf.keras.layers.Dropout(drop_lay))\n",
    "    mdl.add(tf.keras.layers.Dense(train_o.shape[1]))\n",
    "\n",
    "    mdl.compile(loss=vrex_loss, optimizer='rmsprop', metrics='mse')\n",
    "    mdl.fit(train_i, train_o, epochs=50, verbose=0)\n",
    "\n",
    "    # Get the predictions\n",
    "    train_preds = {}\n",
    "    train_VAFs = {}\n",
    "    test_preds = {}\n",
    "    test_VAFs = {}\n",
    "\n",
    "    for cond in train_firing_dict.keys():\n",
    "        train_preds[cond] = mdl.predict(train_firing_dict[cond])\n",
    "        train_VAFs[cond] = metrics.r2_score(train_EMG_dict[cond][:,:n_EMGs], train_preds[cond][:,:n_EMGs], multioutput='raw_values')\n",
    "\n",
    "        if cond != 'Combined': # don't really care about the \"combined\" test case\n",
    "            test_preds[cond] = mdl.predict(test_firing_dict[cond])\n",
    "            test_VAFs[cond] = metrics.r2_score(test_EMG_dict[cond][:,:n_EMGs], test_preds[cond][:,:n_EMGs], multioutput='raw_values')\n",
    "\n",
    "\n",
    "    print('----------------------------------------')\n",
    "    for ii_name, name in enumerate(EMG_name):\n",
    "        print(name)\n",
    "        for in_name, in_vaf in train_VAFs.items():\n",
    "            print(f\"\\tTrain VAF for {in_name}: {in_vaf[ii_name]}\")\n",
    "        for out_name,out_vaf in test_VAFs.items():\n",
    "            print(f\"\\tTest VAF for {out_name}: {out_vaf[ii_name]}\")\n",
    "\n",
    "\n",
    "    plot_rec_pred(train_EMG_dict, train_preds, EMG_name, train_VAFs, title_append = 'training set')\n",
    "    plot_rec_pred(test_EMG_dict, test_preds, EMG_name, test_VAFs, title_append = 'testing set')\n",
    "\n",
    "    plot_VAFs(train_VAFs, test_VAFs, EMG_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_rex_weighted(train_firing_dict: dict, train_EMG_orig: dict, train_var_dict:dict, train_oh_dict:dict, test_firing_dict: dict, test_EMG_dict: dict, EMG_name, beta=3):\n",
    "    # hyper params\n",
    "    layer_0_units = 300\n",
    "    drop_in = .25     # input dropout percentage for LSTM layer\n",
    "    drop_rec = 0    # recurrent dropout for LSTM\n",
    "    drop_lay = .15    # dropout layer?\n",
    "\n",
    "    # append the variance to the EMG values\n",
    "    n_EMGs = len(EMG_name)\n",
    "    seq_len = train_firing_dict['Combined'].shape[1] # num of lags\n",
    "    n_neurons = train_firing_dict['Combined'].shape[2]\n",
    "    n_cond = len(list(train_firing_dict.keys()))-1 # to avoid counting \"Combined\"\n",
    "    train_EMG_dict = {}\n",
    "    for ii_cond, cond in enumerate(train_EMG_orig.keys()):\n",
    "        train_EMG_dict[cond] = train_EMG_orig[cond].copy()\n",
    "        train_EMG_dict[cond] = np.append(train_EMG_dict[cond], train_var_dict[cond], axis=1)\n",
    "        train_EMG_dict[cond] = np.append(train_EMG_dict[cond], train_oh_dict[cond], axis=1)\n",
    "\n",
    "    # pull out the \"Combined\" conditions for training\n",
    "    train_i = train_firing_dict['Combined'] \n",
    "    train_o = train_EMG_dict['Combined']\n",
    "\n",
    "    # define the loss function -- allows us to change beta etc dynamically\n",
    "    def vrex_weighted(target, pred):\n",
    "        B = beta \n",
    "\n",
    "        n_target = n_EMGs\n",
    "        n_conds = n_cond\n",
    "\n",
    "        err = target[:,:n_target] - pred[:,:n_target] # find the error\n",
    "        se_musc = K.square(err) # square error per muscle per timepoint\n",
    "        # pull out the variances and divide, then take the mean. Tx1\n",
    "        se = K.mean(tf.divide(se_musc, target[:,n_target:2*n_target]), axis=1, keepdims=True) \n",
    "\n",
    "        # pull out the one-hot matrix for flagging\n",
    "        cond_oh = tf.transpose(target[:,-n_conds:]) # transpose -- CxT\n",
    "\n",
    "        risk = tf.matmul(cond_oh, se) # this should give us a Cx1 array\n",
    "        risks = tf.divide(risk, tf.reduce_sum(cond_oh, 1, keepdims=1))\n",
    "\n",
    "        rex = B*K.var(risks) + K.sum(risks)\n",
    "        return rex\n",
    "\n",
    "\n",
    "    # create the model\n",
    "    mdl = tf.keras.models.Sequential()\n",
    "\n",
    "    # add the LSTM layer\n",
    "    mdl.add(tf.keras.layers.LSTM(layer_0_units, input_shape = (seq_len,n_neurons), dropout=drop_in, recurrent_dropout=drop_rec))\n",
    "    mdl.add(tf.keras.layers.Dropout(drop_lay))\n",
    "    mdl.add(tf.keras.layers.Dense(train_o.shape[1]))\n",
    "\n",
    "    mdl.compile(loss=vrex_weighted, optimizer='rmsprop', metrics='mse')\n",
    "\n",
    "    mdl.fit(train_i, train_o, epochs=50, verbose=0)\n",
    "\n",
    "\n",
    "\n",
    "    train_preds = {}\n",
    "    train_VAFs = {}\n",
    "    test_preds = {}\n",
    "    test_VAFs = {}\n",
    "\n",
    "    for cond in train_firing_dict.keys():\n",
    "        train_preds[cond] = mdl.predict(train_firing_dict[cond])\n",
    "        train_VAFs[cond] = metrics.r2_score(train_EMG_dict[cond][:,:n_EMGs], train_preds[cond][:,:n_EMGs], multioutput='raw_values')\n",
    "\n",
    "        if cond != 'Combined': # don't really care about the \"combined\" test case\n",
    "            test_preds[cond] = mdl.predict(test_firing_dict[cond])\n",
    "            test_VAFs[cond] = metrics.r2_score(test_EMG_dict[cond][:,:n_EMGs], test_preds[cond][:,:n_EMGs], multioutput='raw_values')\n",
    "\n",
    "\n",
    "    print('----------------------------------------')\n",
    "    for ii_name, name in enumerate(EMG_name):\n",
    "        print(name)\n",
    "        for in_name, in_vaf in train_VAFs.items():\n",
    "            print(f\"\\tTrain VAF for {in_name}: {in_vaf[ii_name]}\")\n",
    "        for out_name,out_vaf in test_VAFs.items():\n",
    "            print(f\"\\tTest VAF for {out_name}: {out_vaf[ii_name]}\")\n",
    "\n",
    "\n",
    "    plot_rec_pred(train_EMG_dict, train_preds, EMG_name, train_VAFs, title_append = 'training set')\n",
    "    plot_rec_pred(test_EMG_dict, test_preds, EMG_name, test_VAFs, title_append = 'testing set')\n",
    "\n",
    "    plot_VAFs(train_VAFs, test_VAFs, EMG_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare different combinations of train/test sets\n",
    "\n",
    "So that we can quickly run through all of the iterations\n",
    "\n",
    "Set the nonlinearity type, to compare across iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonlinear_type = 'poly'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "First train wrist movement, test wrist movement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_timestamps, train_firing, train_EMG, train_force, train_kin = load_josh_mat(data['WmTrain'])\n",
    "test_timestamps, test_firing, test_EMG, test_force, test_kin = load_josh_mat(data['WmTest'])\n",
    "# using the training set twice as the \"refit\" gain -- for sanity's sake\n",
    "mov_mov_linVAF = basic_decoder_comparison(train_firing, train_EMG, train_firing, train_EMG, test_firing, test_EMG, test_timestamps, nonlinear_type)\n",
    "mov_mov_LSTMVAF = LSTM_comparisons(train_firing, train_EMG, test_firing, test_EMG, test_timestamps)\n",
    "\n",
    "print(f\"Mean Linear {np.mean(mov_mov_linVAF)}\")\n",
    "print(f\"Mean LSTM {np.mean(mov_mov_LSTMVAF)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train wrist movement, test iso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_timestamps, train_firing, train_EMG, train_force, train_kin = load_josh_mat(data['WmTrain'])\n",
    "_, retrain_firing, retrain_EMG, _, _, = load_josh_mat(data['IsoTrain'])\n",
    "test_timestamps, test_firing, test_EMG, test_force, test_kin = load_josh_mat(data['IsoTest'])\n",
    "mov_iso_linVAF = basic_decoder_comparison(train_firing, train_EMG, retrain_firing, retrain_EMG, test_firing, test_EMG, test_timestamps, nonlinear_type)\n",
    "mov_iso_LSTMVAF = LSTM_comparisons(train_firing, train_EMG, test_firing, test_EMG, test_timestamps)\n",
    "\n",
    "print(f\"Mean Linear {np.mean(mov_iso_linVAF)}\")\n",
    "print(f\"Mean LSTM {np.mean(mov_iso_LSTMVAF)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train WM, test spring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_timestamps, train_firing, train_EMG, train_force, train_kin = load_josh_mat(data['WmTrain'])\n",
    "_, retrain_firing, retrain_EMG, _, _, = load_josh_mat(data['SprTrain'])\n",
    "test_timestamps, test_firing, test_EMG, test_force, test_kin = load_josh_mat(data['SprTest'])\n",
    "mov_spr_linVAF = basic_decoder_comparison(train_firing, train_EMG, retrain_firing, retrain_EMG, test_firing, test_EMG, test_timestamps, nonlinear_type)\n",
    "mov_spr_LSTMVAF = LSTM_comparisons(train_firing, train_EMG, test_firing, test_EMG, test_timestamps)\n",
    "\n",
    "print(f\"Mean Linear {np.mean(mov_spr_linVAF)}\")\n",
    "print(f\"Mean LSTM {np.mean(mov_spr_LSTMVAF)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Iso, test Iso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_timestamps, train_firing, train_EMG, train_force, train_kin = load_josh_mat(data['IsoTrain'])\n",
    "test_timestamps, test_firing, test_EMG, test_force, test_kin = load_josh_mat(data['IsoTest'])\n",
    "iso_iso_linVAF = basic_decoder_comparison(train_firing, train_EMG, train_firing, train_EMG, test_firing, test_EMG, test_timestamps, nonlinear_type)\n",
    "iso_iso_LSTMVAF = LSTM_comparisons(train_firing, train_EMG, test_firing, test_EMG, test_timestamps)\n",
    "\n",
    "print(f\"Mean Linear {np.mean(iso_iso_linVAF)}\")\n",
    "print(f\"Mean LSTM {np.mean(iso_iso_LSTMVAF)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Iso, test WM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_timestamps, train_firing, train_EMG, train_force, train_kin = load_josh_mat(data['IsoTrain'])\n",
    "_, retrain_firing, retrain_EMG, _, _, = load_josh_mat(data['WmTrain'])\n",
    "test_timestamps, test_firing, test_EMG, test_force, test_kin = load_josh_mat(data['WmTest'])\n",
    "iso_mov_linVAF = basic_decoder_comparison(train_firing, train_EMG, retrain_firing, retrain_EMG, test_firing, test_EMG, test_timestamps, nonlinear_type)\n",
    "iso_mov_LSTMVAF = LSTM_comparisons(train_firing, train_EMG, test_firing, test_EMG, test_timestamps)\n",
    "\n",
    "print(f\"Mean Linear {np.mean(iso_mov_linVAF)}\")\n",
    "print(f\"Mean LSTM {np.mean(iso_mov_linVAF)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Iso, Test Spring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_timestamps, train_firing, train_EMG, train_force, train_kin = load_josh_mat(data['IsoTrain'])\n",
    "_, retrain_firing, retrain_EMG, _, _, = load_josh_mat(data['SprTrain'])\n",
    "test_timestamps, test_firing, test_EMG, test_force, test_kin = load_josh_mat(data['SprTest'])\n",
    "iso_spr_linVAF = basic_decoder_comparison(train_firing, train_EMG, retrain_firing, retrain_EMG, test_firing, test_EMG, test_timestamps, nonlinear_type)\n",
    "iso_spr_LSTMVAF = LSTM_comparisons(train_firing, train_EMG, test_firing, test_EMG, test_timestamps)\n",
    "\n",
    "print(f\"Mean Linear {np.mean(iso_spr_linVAF)}\")\n",
    "print(f\"Mean LSTM {np.mean(iso_spr_linVAF)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Spring, test each of the three"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_timestamps, train_firing, train_EMG, train_force, train_kin = load_josh_mat(data['SprTrain'])\n",
    "\n",
    "print('Test Spring')\n",
    "_, retrain_firing, retrain_EMG, _, _, = load_josh_mat(data['SprTrain'])\n",
    "test_timestamps, test_firing, test_EMG, test_force, test_kin = load_josh_mat(data['SprTest'])\n",
    "spr_spr_linVAF = basic_decoder_comparison(train_firing, train_EMG, retrain_firing, retrain_EMG, test_firing, test_EMG, test_timestamps, nonlinear_type)\n",
    "spr_spr_LSTMVAF = LSTM_comparisons(train_firing, train_EMG, test_firing, test_EMG, test_timestamps)\n",
    "\n",
    "print('Test Iso')\n",
    "_, retrain_firing, retrain_EMG, _, _, = load_josh_mat(data['IsoTrain'])\n",
    "test_timestamps, test_firing, test_EMG, test_force, test_kin = load_josh_mat(data['IsoTest'])\n",
    "spr_iso_linVAF = basic_decoder_comparison(train_firing, train_EMG, retrain_firing, retrain_EMG, test_firing, test_EMG, test_timestamps, nonlinear_type)\n",
    "spr_iso_LSTMVAF = LSTM_comparisons(train_firing, train_EMG, test_firing, test_EMG, test_timestamps)\n",
    "\n",
    "print('Test Movement')\n",
    "_, retrain_firing, retrain_EMG, _, _, = load_josh_mat(data['WmTrain'])\n",
    "test_timestamps, test_firing, test_EMG, test_force, test_kin = load_josh_mat(data['WmTest'])\n",
    "spr_mov_linVAF = basic_decoder_comparison(train_firing, train_EMG, retrain_firing, retrain_EMG, test_firing, test_EMG, test_timestamps, nonlinear_type)\n",
    "spr_mov_LSTMVAF = LSTM_comparisons(train_firing, train_EMG, test_firing, test_EMG, test_timestamps)\n",
    "\n",
    "dntxt.send('Spring Linear and non weighted done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train on hybrid, test on each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Hybrid 3 -- this should be a blend of all three, I think for training\n",
    "train_timestamps, train_firing, train_EMG, train_force, train_kin = load_josh_mat(data['Hybrid3'])\n",
    "\n",
    "print(\"test on movement\")\n",
    "_, retrain_firing, retrain_EMG, _, _, = load_josh_mat(data['WmTrain'])\n",
    "test_timestamps, test_firing, test_EMG, test_force, test_kin = load_josh_mat(data['WmTest'])\n",
    "basic_decoder_comparison(train_firing, train_EMG, retrain_firing, retrain_EMG, test_firing, test_EMG, test_timestamps, nonlinear_type)\n",
    "LSTM_comparisons(train_firing, train_EMG, test_firing, test_EMG, test_timestamps)\n",
    "\n",
    "print(\"\\n\\ntest on Iso\")\n",
    "_, retrain_firing, retrain_EMG, _, _, = load_josh_mat(data['IsoTrain'])\n",
    "test_timestamps, test_firing, test_EMG, test_force, test_kin = load_josh_mat(data['IsoTest'])\n",
    "basic_decoder_comparison(train_firing, train_EMG, retrain_firing, retrain_EMG, test_firing, test_EMG, test_timestamps, nonlinear_type)\n",
    "LSTM_comparisons(train_firing, train_EMG, test_firing, test_EMG, test_timestamps)\n",
    "\n",
    "\n",
    "print(\"\\n\\ntest on Spring\")\n",
    "_, retrain_firing, retrain_EMG, _, _, = load_josh_mat(data['SprTrain'])\n",
    "test_timestamps, test_firing, test_EMG, test_force, test_kin = load_josh_mat(data['SprTest'])\n",
    "basic_decoder_comparison(train_firing, train_EMG, retrain_firing, retrain_EMG, test_firing, test_EMG, test_timestamps, nonlinear_type)\n",
    "LSTM_comparisons(train_firing, train_EMG, test_firing, test_EMG, test_timestamps)\n",
    "\n",
    "dntxt.send('Hybrid basic testing complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Hybrid 3 -- this should be a blend of all three, I think for training\n",
    "train_timestamps, train_firing, train_EMG, train_force, train_kin = load_josh_mat(data['Hybrid3'])\n",
    "_, retrain_firing, retrain_EMG, _, _, = load_josh_mat(data['IsoTrain'])\n",
    "test_timestamps, test_firing, test_EMG, test_force, test_kin = load_josh_mat(data['IsoTest'])\n",
    "basic_decoder_comparison(train_firing, train_EMG, retrain_firing, retrain_EMG, test_firing, test_EMG, test_timestamps, nonlinear_type)\n",
    "LSTM_comparisons(train_firing, train_EMG, test_firing, test_EMG, test_timestamps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hybrid LSTMs with weighted loss functions\n",
    "\n",
    "This works a little different from Josh's -- I'm not basing it off of times; instead, I'm manually compiling the train sets I want to use\n",
    "\n",
    "\n",
    "Train on Iso and Movement, test on each of the three"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_firing = {'Iso': Iso_train_firing}\n",
    "test_firing = {'Iso': Iso_test_firing}\n",
    "train_EMG = {'Iso': Iso_train_EMG}\n",
    "test_EMG = {'Iso': Iso_test_EMG}\n",
    "\n",
    "ret_vals = LSTM_preprocess(train_firing, train_EMG, test_firing, test_EMG)\n",
    "\n",
    "train_firing_dict = ret_vals[0]\n",
    "train_EMG_dict = ret_vals[1]\n",
    "train_oh_dict = ret_vals[2]\n",
    "train_var_dict = ret_vals[3]\n",
    "test_firing_dict = ret_vals[4]\n",
    "test_EMG_dict = ret_vals[5]\n",
    "test_oh_dict = ret_vals[6]\n",
    "test_var_dict = ret_vals[7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train on Movement and Spring, test on everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, train_firing_0, train_EMG_0, _, _ = load_josh_mat(data['SprTrain'])\n",
    "_, train_firing_1, train_EMG_1, _, _ = load_josh_mat(data['WmTrain'])\n",
    "\n",
    "print(f\"Test on Spring\")\n",
    "test_timestamps, test_firing, test_EMG, _, _ = load_josh_mat(data['SprTest'])\n",
    "LSTM_across_weighted([train_firing_0, train_firing_1], [train_EMG_0, train_EMG_1], test_firing, test_EMG, test_timestamps, plot=False)\n",
    "\n",
    "print(f\"Test on Movement\")\n",
    "test_timestamps, test_firing, test_EMG, _, _ = load_josh_mat(data['WmTest'])\n",
    "LSTM_across_weighted([train_firing_0, train_firing_1], [train_EMG_0, train_EMG_1], test_firing, test_EMG, test_timestamps, plot=False)\n",
    "\n",
    "print(f\"Test on Iso\")\n",
    "test_timestamps, test_firing, test_EMG, _, _ = load_josh_mat(data['IsoTest'])\n",
    "LSTM_across_weighted([train_firing_0, train_firing_1], [train_EMG_0, train_EMG_1], test_firing, test_EMG, test_timestamps, plot=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train on Spring and Iso, test on everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_, train_firing_0, train_EMG_0, _, _ = load_josh_mat(data['SprTrain'])\n",
    "_, train_firing_1, train_EMG_1, _, _ = load_josh_mat(data['IsoTrain'])\n",
    "\n",
    "print(f\"Test on Spring\")\n",
    "test_timestamps, test_firing, test_EMG, _, _ = load_josh_mat(data['SprTest'])\n",
    "LSTM_across_weighted([train_firing_0, train_firing_1], [train_EMG_0, train_EMG_1], test_firing, test_EMG, test_timestamps)\n",
    "\n",
    "print(f\"Test on Movement\")\n",
    "test_timestamps, test_firing, test_EMG, _, _ = load_josh_mat(data['WmTest'])\n",
    "LSTM_across_weighted([train_firing_0, train_firing_1], [train_EMG_0, train_EMG_1], test_firing, test_EMG, test_timestamps)\n",
    "\n",
    "print(f\"Test on Iso\")\n",
    "test_timestamps, test_firing, test_EMG, _, _ = load_josh_mat(data['IsoTest'])\n",
    "LSTM_across_weighted([train_firing_0, train_firing_1], [train_EMG_0, train_EMG_1], test_firing, test_EMG, test_timestamps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train on everything, test on each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, train_firing_0, train_EMG_0, _, _ = load_josh_mat(data['SprTrain'])\n",
    "_, train_firing_1, train_EMG_1, _, _ = load_josh_mat(data['IsoTrain'])\n",
    "_, train_firing_2, train_EMG_2, _, _ = load_josh_mat(data['IsoTrain'])\n",
    "\n",
    "print(f\"Test on Spring\")\n",
    "test_timestamps, test_firing, test_EMG, _, _ = load_josh_mat(data['SprTest'])\n",
    "LSTM_across_weighted([train_firing_0, train_firing_1, train_firing_2], [train_EMG_0, train_EMG_1, train_EMG_2], test_firing, test_EMG, test_timestamps, plot=False)\n",
    "\n",
    "print(f\"Test on Movement\")\n",
    "test_timestamps, test_firing, test_EMG, _, _ = load_josh_mat(data['WmTest'])\n",
    "LSTM_across_weighted([train_firing_0, train_firing_1, train_firing_2], [train_EMG_0, train_EMG_1, train_EMG_2], test_firing, test_EMG, test_timestamps, plot=False)\n",
    "\n",
    "print(f\"Test on Iso\")\n",
    "test_timestamps, test_firing, test_EMG, _, _ = load_josh_mat(data['IsoTest'])\n",
    "LSTM_across_weighted([train_firing_0, train_firing_1, train_firing_2], [train_EMG_0, train_EMG_1, train_EMG_2], test_firing, test_EMG, test_timestamps, plot=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM grid search\n",
    "\n",
    "Time to look at some non-linearities!\n",
    "\n",
    "Let's run through the grid search on hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, firing, EMG, _, _ = load_josh_mat(data['WmTrain'])\n",
    "\n",
    "log = LSTM_grid_search(firing, EMG, n_iter = 30, n_fold = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM with REx\n",
    "\n",
    "Run through the options, see what comes out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('Training on Movement')\n",
    "\n",
    "_, train_firing_1, train_EMG_1, _, _ = load_josh_mat(data['WmTrain'])\n",
    "\n",
    "train_firing = {'Move': train_firing_1}\n",
    "train_EMG = {'Move': train_EMG_1}\n",
    "\n",
    "# testing dictionaries\n",
    "test_firing = {}\n",
    "test_EMG = {}\n",
    "test_timestamps = {}\n",
    "# movement\n",
    "test_timestamps['Move'], test_firing['Move'], test_EMG['Move'], _, _ = load_josh_mat(data['WmTest'])\n",
    "test_timestamps['Iso'], test_firing['Iso'], test_EMG['Iso'], _, _ = load_josh_mat(data['IsoTest'])\n",
    "test_timestamps['Spr'], test_firing['Spr'], test_EMG['Spr'], _, _ = load_josh_mat(data['SprTest'])\n",
    "\n",
    "# Send it\n",
    "LSTM_rex(train_firing, train_EMG, test_firing, test_EMG, test_timestamps)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('Training on isometric and movement')\n",
    "\n",
    "_, train_firing_0, train_EMG_0, _, _ = load_josh_mat(data['IsoTrain'])\n",
    "_, train_firing_1, train_EMG_1, _, _ = load_josh_mat(data['WmTrain'])\n",
    "\n",
    "train_firing = {'Iso': train_firing_0, 'Move': train_firing_1}\n",
    "train_EMG = {'Iso': train_EMG_0, 'Move': train_EMG_1}\n",
    "\n",
    "# testing dictionaries\n",
    "test_firing = {}\n",
    "test_EMG = {}\n",
    "test_timestamps = {}\n",
    "\n",
    "# populate dictionaries\n",
    "test_timestamps['Iso'], test_firing['Iso'], test_EMG['Iso'], _, _ = load_josh_mat(data['IsoTest'])\n",
    "test_timestamps['Move'], test_firing['Move'], test_EMG['Move'], _, _ = load_josh_mat(data['WmTest'])\n",
    "test_timestamps['Spr'], test_firing['Spr'], test_EMG['Spr'], _, _ = load_josh_mat(data['SprTest'])\n",
    "\n",
    "# Send it\n",
    "LSTM_rex(train_firing, train_EMG, test_firing, test_EMG, test_timestamps)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# doneTone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('movement and spring')\n",
    "\n",
    "\n",
    "_, train_firing_0, train_EMG_0, _, _ = load_josh_mat(data['SprTrain'])\n",
    "_, train_firing_1, train_EMG_1, _, _ = load_josh_mat(data['WmTrain'])\n",
    "\n",
    "print('\\nmovement test')\n",
    "test_timestamps, test_firing, test_EMG, test_force, test_kin = load_josh_mat(data['WmTest'])\n",
    "LSTM_rex([train_firing_0, train_firing_1], [train_EMG_0, train_EMG_1], test_firing, test_EMG, test_timestamps)\n",
    "print('\\niso test')\n",
    "test_timestamps, test_firing, test_EMG, test_force, test_kin = load_josh_mat(data['IsoTest'])\n",
    "LSTM_rex([train_firing_0, train_firing_1], [train_EMG_0, train_EMG_1], test_firing, test_EMG, test_timestamps)\n",
    "print('\\nspring test')\n",
    "test_timestamps, test_firing, test_EMG, test_force, test_kin = load_josh_mat(data['SprTest'])\n",
    "LSTM_rex([train_firing_0, train_firing_1], [train_EMG_0, train_EMG_1], test_firing, test_EMG, test_timestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('iso and spring')\n",
    "\n",
    "\n",
    "_, train_firing_0, train_EMG_0, _, _ = load_josh_mat(data['IsoTrain'])\n",
    "_, train_firing_1, train_EMG_1, _, _ = load_josh_mat(data['SprTrain'])\n",
    "\n",
    "print('\\nmovement test')\n",
    "test_timestamps, test_firing, test_EMG, test_force, test_kin = load_josh_mat(data['WmTest'])\n",
    "LSTM_rex([train_firing_0, train_firing_1], [train_EMG_0, train_EMG_1], test_firing, test_EMG, test_timestamps)\n",
    "print('\\niso test')\n",
    "test_timestamps, test_firing, test_EMG, test_force, test_kin = load_josh_mat(data['IsoTest'])\n",
    "LSTM_rex([train_firing_0, train_firing_1], [train_EMG_0, train_EMG_1], test_firing, test_EMG, test_timestamps)\n",
    "print('\\nspring test')\n",
    "test_timestamps, test_firing, test_EMG, test_force, test_kin = load_josh_mat(data['SprTest'])\n",
    "LSTM_rex([train_firing_0, train_firing_1], [train_EMG_0, train_EMG_1], test_firing, test_EMG, test_timestamps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, train_firing_0, train_EMG_0, _, _ = load_josh_mat(data['IsoTrain'])\n",
    "_, train_firing_1, train_EMG_1, _, _ = load_josh_mat(data['WmTrain'])\n",
    "_, train_firing_2, train_EMG_2, _, _ = load_josh_mat(data['SprTrain'])\n",
    "test_timestamps, test_firing, test_EMG, test_force, test_kin = load_josh_mat(data['SprTest'])\n",
    "\n",
    "\n",
    "print('\\nmovement test')\n",
    "test_timestamps, test_firing, test_EMG, test_force, test_kin = load_josh_mat(data['WmTest'])\n",
    "LSTM_rex([train_firing_0, train_firing_1, train_firing_2], [train_EMG_0, train_EMG_1, train_EMG_2], test_firing, test_EMG, test_timestamps)\n",
    "print('\\niso test')\n",
    "test_timestamps, test_firing, test_EMG, test_force, test_kin = load_josh_mat(data['IsoTest'])\n",
    "LSTM_rex([train_firing_0, train_firing_1, train_firing_2], [train_EMG_0, train_EMG_1, train_EMG_2], test_firing, test_EMG, test_timestamps)\n",
    "print('\\nspring test')\n",
    "test_timestamps, test_firing, test_EMG, test_force, test_kin = load_josh_mat(data['SprTest'])\n",
    "LSTM_rex([train_firing_0, train_firing_1, train_firing_2], [train_EMG_0, train_EMG_1, train_EMG_2], test_firing, test_EMG, test_timestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, train_firing_0, train_EMG_0, _, _ = load_josh_mat(data['IsoTrain'])\n",
    "_, train_firing_1, train_EMG_1, _, _ = load_josh_mat(data['WmTrain'])\n",
    "test_timestamps, test_firing, test_EMG, test_force, test_kin = load_josh_mat(data['IsoTest'])\n",
    "\n",
    "\n",
    "LSTM_rex([train_firing_0, train_firing_1], [train_EMG_0, train_EMG_1], test_firing, test_EMG, test_timestamps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the weighted version of the REx (doesn't change the function, just what's fed into the One Hot matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('iso and spring')\n",
    "\n",
    "\n",
    "_, train_firing_0, train_EMG_0, _, _ = load_josh_mat(data['IsoTrain'])\n",
    "_, train_firing_1, train_EMG_1, _, _ = load_josh_mat(data['SprTrain'])\n",
    "\n",
    "print('\\nmovement test')\n",
    "test_timestamps, test_firing, test_EMG, test_force, test_kin = load_josh_mat(data['WmTest'])\n",
    "LSTM_rex([train_firing_0, train_firing_1], [train_EMG_0, train_EMG_1], test_firing, test_EMG, test_timestamps, weighted=True)\n",
    "print('\\niso test')\n",
    "test_timestamps, test_firing, test_EMG, test_force, test_kin = load_josh_mat(data['IsoTest'])\n",
    "LSTM_rex([train_firing_0, train_firing_1], [train_EMG_0, train_EMG_1], test_firing, test_EMG, test_timestamps, weighted=True)\n",
    "print('\\nspring test')\n",
    "test_timestamps, test_firing, test_EMG, test_force, test_kin = load_josh_mat(data['SprTest'])\n",
    "LSTM_rex([train_firing_0, train_firing_1], [train_EMG_0, train_EMG_1], test_firing, test_EMG, test_timestamps, weighted=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('iso and movement')\n",
    "\n",
    "_, train_firing_0, train_EMG_0, _, _ = load_josh_mat(data['IsoTrain'])\n",
    "_, train_firing_1, train_EMG_1, _, _ = load_josh_mat(data['WmTrain'])\n",
    "\n",
    "print('\\nmovement test')\n",
    "test_timestamps, test_firing, test_EMG, test_force, test_kin = load_josh_mat(data['WmTest'])\n",
    "LSTM_rex([train_firing_0, train_firing_1], [train_EMG_0, train_EMG_1], test_firing, test_EMG, test_timestamps, weighted=True)\n",
    "print('\\niso test')\n",
    "test_timestamps, test_firing, test_EMG, test_force, test_kin = load_josh_mat(data['IsoTest'])\n",
    "LSTM_rex([train_firing_0, train_firing_1], [train_EMG_0, train_EMG_1], test_firing, test_EMG, test_timestamps, weighted=True)\n",
    "print('\\nspring test')\n",
    "test_timestamps, test_firing, test_EMG, test_force, test_kin = load_josh_mat(data['SprTest'])\n",
    "LSTM_rex([train_firing_0, train_firing_1], [train_EMG_0, train_EMG_1], test_firing, test_EMG, test_timestamps, weighted=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VRex with weightings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vrex_weighted(target, pred):\n",
    "    # weighting the risks based on the var of the EMG\n",
    "    # For this, we will bring in an array of Tx(2*M+1) \n",
    "    # where M is the number of muscles and the extra column is for a flag\n",
    "\n",
    "    # define the balance of mean and variance of risk\n",
    "    B = 0 #\n",
    "#     B = .5 #\n",
    "#     B = 1 #\n",
    "#     B = 5 #\n",
    "#     B = 10 #\n",
    "#     B = 50 #\n",
    "#     B = 100 #\n",
    "\n",
    "#     num_targets = K.shape(target)[1]//2 # number of cols / 2\n",
    "#     err = (target[:, 0:num_targets] - pred[:,0:num_targets]) # subtract the values\n",
    "#     se = K.square(err) * target[:,num_targets:-1] # multiply the square error by the gains\n",
    "#     mse = K.mean(se, axis=-1)\n",
    "\n",
    "    # number of muscles\n",
    "    muscles = target.shape[1]//2 # find that value of M\n",
    "    err = target[:,:muscles] - pred[:,:muscles] # find the error\n",
    "    se_musc = K.square(err) * target[:,num_targets:-1] # square error per muscle per timepoint\n",
    "    mse = tf.expand_dims(K.mean(se_musc,axis=-1),axis=-1) # take a weighted sum  of muscles per ts\n",
    "#     tf.print(f\"se shape:{se.shape}\")\n",
    "    \n",
    "    \n",
    "    # separate the conditions based on the flag\n",
    "    flag = target[:,-1] # last column\n",
    "#     risks = [K.mean(se[flag==C]) for C,_ in tf.unique(flag)]\n",
    "    u_flag,i_flag = tf.unique(flag) # for another one-hot matrix\n",
    "    flag_mask = tf.one_hot(i_flag, len(u_flag), axis=0) # mask for each condition -- CxT\n",
    "#     tf.print(f\"flag_mask shape: {flag_mask.shape}\")\n",
    "\n",
    "    split_se = tf.matmul(flag_mask, se) # this should give us a Cx1 array\n",
    "    # need to get the mean per condition, and samples/condition changes\n",
    "    # depending on the batch. the flag mask has already counted for us :)\n",
    "    risks = tf.math.divide(split_se, K.sum(flag_mask, axis=0))\n",
    "#     split_risk = tf.matmul(var_oh, mse_musc)\n",
    "#     weighted_risk = tf.multiply(tf.expand_dims(u_var, axis=-1), split_risk)\n",
    "#     risks = tf.math.divide(weighted_risk, K.sum(var_oh, axis=1)) # get the mean\n",
    "\n",
    "    rex = B*K.var(risks) + K.sum(risks)\n",
    "\n",
    "#     return rex\n",
    "    return mse\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('Training on isometric and movement')\n",
    "\n",
    "_, train_firing_0, train_EMG_0, _, _ = load_josh_mat(data['IsoTrain'])\n",
    "_, train_firing_1, train_EMG_1, _, _ = load_josh_mat(data['WmTrain'])\n",
    "\n",
    "train_firing = {'Iso': train_firing_0, 'Move': train_firing_1}\n",
    "train_EMG = {'Iso': train_EMG_1, 'Move': train_EMG_1}\n",
    "\n",
    "# testing dictionaries\n",
    "test_firing = {}\n",
    "test_EMG = {}\n",
    "test_timestamps = {}\n",
    "# movement\n",
    "test_timestamps['Move'], test_firing['Move'], test_EMG['Move'], _, _ = load_josh_mat(data['WmTest'])\n",
    "test_timestamps['Iso'], test_firing['Iso'], test_EMG['Iso'], _, _ = load_josh_mat(data['IsoTest'])\n",
    "test_timestamps['Spr'], test_firing['Spr'], test_EMG['Spr'], _, _ = load_josh_mat(data['SprTest'])\n",
    "\n",
    "# Send it\n",
    "LSTM_rex_weighted(train_firing, train_EMG, test_firing, test_EMG, test_timestamps)\n",
    "\n",
    "# print('\\nmovement test')\n",
    "# test_timestamps, test_firing, test_EMG, test_force, test_kin = load_josh_mat(data['WmTest'])\n",
    "# LSTM_rex_weighted([train_firing_0, train_firing_1], [train_EMG_0, train_EMG_1], test_firing, test_EMG, test_timestamps)\n",
    "# print('\\niso test')\n",
    "# test_timestamps, test_firing, test_EMG, test_force, test_kin = load_josh_mat(data['IsoTest'])\n",
    "# LSTM_rex_weighted([train_firing_0, train_firing_1], [train_EMG_0, train_EMG_1], test_firing, test_EMG, test_timestamps)\n",
    "# print('\\nspring test')\n",
    "# test_timestamps, test_firing, test_EMG, test_force, test_kin = load_josh_mat(data['SprTest'])\n",
    "# LSTM_rex_weighted([train_firing_0, train_firing_1], [train_EMG_0, train_EMG_1], test_firing, test_EMG, test_timestamps)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scratch Space\n",
    "Sometimes the variable viewer isn't very goood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting bits of code to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs/LSTM_exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorboard\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_firing = {'Iso': Iso_train_firing}\n",
    "test_firing = {'Iso': Iso_test_firing}\n",
    "train_EMG = {'Iso': Iso_train_EMG}\n",
    "test_EMG = {'Iso': Iso_test_EMG}\n",
    "\n",
    "ret_vals = LSTM_preprocess(train_firing, train_EMG, test_firing, test_EMG)\n",
    "\n",
    "train_firing_dict = ret_vals[0]\n",
    "train_EMG_dict = ret_vals[1]\n",
    "train_oh_dict = ret_vals[2]\n",
    "train_var_dict = ret_vals[3]\n",
    "test_firing_dict = ret_vals[4]\n",
    "test_EMG_dict = ret_vals[5]\n",
    "test_oh_dict = ret_vals[6]\n",
    "test_var_dict = ret_vals[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted LSTM, no REx\n",
      "375/375 [==============================] - 1s 1ms/step\n",
      "188/188 [==============================] - 0s 1ms/step\n",
      "375/375 [==============================] - 0s 1ms/step\n",
      "----------------------------------------\n",
      "FCU\n",
      "\tTrain VAF for Iso: 0.43102945869807874\n",
      "\tTrain VAF for Combined: 0.43102945869807874\n",
      "\tTest VAF for Iso: 0.573556247813646\n",
      "FCR\n",
      "\tTrain VAF for Iso: 0.6335307882931892\n",
      "\tTrain VAF for Combined: 0.6335307882931892\n",
      "\tTest VAF for Iso: 0.45857098829213383\n",
      "ECU\n",
      "\tTrain VAF for Iso: 0.8427253985463115\n",
      "\tTrain VAF for Combined: 0.8427253985463115\n",
      "\tTest VAF for Iso: 0.6305773491271108\n",
      "ECR\n",
      "\tTrain VAF for Iso: 0.9007870709207919\n",
      "\tTrain VAF for Combined: 0.9007870709207919\n",
      "\tTest VAF for Iso: 0.8132055085633186\n"
     ]
    }
   ],
   "source": [
    "# weighted LSTM\n",
    "print ('Weighted LSTM, no REx')\n",
    "LSTM_across_weighted(train_firing_dict, train_EMG_dict, train_var_dict, test_firing_dict, test_EMG_dict, EMG_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted LSTM with REx\n",
      "375/375 [==============================] - 1s 1ms/step\n",
      "188/188 [==============================] - 0s 1ms/step\n",
      "375/375 [==============================] - 0s 1ms/step\n",
      "----------------------------------------\n",
      "FCU\n",
      "\tTrain VAF for Iso: 0.4249044201595742\n",
      "\tTrain VAF for Combined: 0.4249044201595742\n",
      "\tTest VAF for Iso: 0.5237984606777523\n",
      "FCR\n",
      "\tTrain VAF for Iso: 0.6286383020204604\n",
      "\tTrain VAF for Combined: 0.6286383020204604\n",
      "\tTest VAF for Iso: 0.45928190043019834\n",
      "ECU\n",
      "\tTrain VAF for Iso: 0.7319497812605731\n",
      "\tTrain VAF for Combined: 0.7319497812605731\n",
      "\tTest VAF for Iso: 0.6374410967731878\n",
      "ECR\n",
      "\tTrain VAF for Iso: 0.8943658998963767\n",
      "\tTrain VAF for Combined: 0.8943658998963767\n",
      "\tTest VAF for Iso: 0.8063772236113764\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# VREx with beta = 0, should be equivalent to the weighted LSTM\n",
    "print('Weighted LSTM with REx')\n",
    "LSTM_rex_weighted(train_firing_dict, train_EMG_dict, train_var_dict, train_oh_dict, test_firing_dict, test_EMG_dict, EMG_name, beta=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple LSTM -- no weighting, no REx\n",
      "375/375 [==============================] - 1s 1ms/step\n",
      "188/188 [==============================] - 0s 1ms/step\n",
      "375/375 [==============================] - 0s 1ms/step\n",
      "----------------------------------------\n",
      "FCU\n",
      "\tTrain VAF for Iso: 0.30252223604254724\n",
      "\tTrain VAF for Combined: 0.302522236042548\n",
      "\tTest VAF for Iso: 0.32087034410804716\n",
      "FCR\n",
      "\tTrain VAF for Iso: 0.6648555862580818\n",
      "\tTrain VAF for Combined: 0.6648555862580833\n",
      "\tTest VAF for Iso: 0.43872796646223167\n",
      "ECU\n",
      "\tTrain VAF for Iso: 0.4894215702990369\n",
      "\tTrain VAF for Combined: 0.4894215702990393\n",
      "\tTest VAF for Iso: 0.5500406185407676\n",
      "ECR\n",
      "\tTrain VAF for Iso: 0.9213277981975586\n",
      "\tTrain VAF for Combined: 0.9213277981975583\n",
      "\tTest VAF for Iso: 0.8210375571626152\n"
     ]
    }
   ],
   "source": [
    "# Simple LSTM\n",
    "print('Simple LSTM -- no weighting, no REx')\n",
    "LSTM_comparisons(train_firing_dict, train_EMG_dict, test_firing_dict, test_EMG_dict, EMG_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VREx\n",
      "375/375 [==============================] - 1s 1ms/step\n",
      "188/188 [==============================] - 0s 1ms/step\n",
      "375/375 [==============================] - 0s 1ms/step\n",
      "----------------------------------------\n",
      "FCU\n",
      "\tTrain VAF for Iso: 0.36852794274479606\n",
      "\tTrain VAF for Combined: 0.36852794274479683\n",
      "\tTest VAF for Iso: 0.5289112971108405\n",
      "FCR\n",
      "\tTrain VAF for Iso: 0.630109516721883\n",
      "\tTrain VAF for Combined: 0.6301095167218845\n",
      "\tTest VAF for Iso: 0.46310913391266095\n",
      "ECU\n",
      "\tTrain VAF for Iso: 0.5196661193443846\n",
      "\tTrain VAF for Combined: 0.519666119344387\n",
      "\tTest VAF for Iso: 0.5212268749157895\n",
      "ECR\n",
      "\tTrain VAF for Iso: 0.903474690643488\n",
      "\tTrain VAF for Combined: 0.9034746906434875\n",
      "\tTest VAF for Iso: 0.7877116940534179\n"
     ]
    }
   ],
   "source": [
    "# VREx with beta = 0. Should be equivalent to the simple LSTM\n",
    "print('VREx')\n",
    "LSTM_rex(train_firing_dict, train_EMG_dict, test_firing_dict, test_EMG_dict, EMG_name, beta=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(train_firing_dict['Iso'][1:,0,:] - train_firing_dict['Iso'][:-1,1,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vREx loss function\n",
    "def vrex_loss(target, pred):\n",
    "    # from the Risk Extrapolation paper\n",
    "    B = 0 #\n",
    "    \n",
    "    n_EMGs = 4\n",
    "    err = target[:,:n_EMGs] - pred[:,:n_EMGs] # without the condition flag\n",
    "    se = K.square(err) # squared error -- TxM\n",
    "    mse = K.mean(se, axis=-1) # mean squared error for each sample -- Tx1\n",
    "    \n",
    "    # now pull in the one-hot matrix for flagging\n",
    "    cond_oh = tf.transpose(target[:,n_EMGs:]) # transpose it so that we can add everything later CxT\n",
    "    \n",
    "    # risk for each condition -- ie MSE for each condition\n",
    "    risk = tf.matmul(cond_oh,se) # Cx1\n",
    "    risk = tf.divide(risk, tf.reduce_sum(cond_oh, 1, keepdims=1)) # mean to account for differen num samples\n",
    "    \n",
    "    rex = B*K.var(risk) + K.sum(risk)\n",
    "\n",
    "    return rex\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def vrex_weighted(target, pred):\n",
    "    B = 0 \n",
    "    \n",
    "    n_target = 4\n",
    "    n_conds = 1\n",
    "\n",
    "    err = target[:,:n_target] - pred[:,:n_target] # find the error\n",
    "    se_musc = K.square(err) # square error per muscle per timepoint\n",
    "    # pull out the variances and divide, then take the mean. Tx1\n",
    "    se = K.mean(tf.divide(se_musc, target[:,n_target:2*n_target]), axis=1, keepdims=True) \n",
    "    \n",
    "    # pull out the one-hot matrix for flagging\n",
    "    cond_oh = tf.transpose(target[:,-n_conds:]) # transpose -- CxT\n",
    "\n",
    "    risk = tf.matmul(cond_oh, se) # this should give us a Cx1 array\n",
    "    risks = tf.divide(risk, tf.reduce_sum(cond_oh, 1, keepdims=1))\n",
    "\n",
    "    rex = B*K.var(risks) + K.sum(risks)\n",
    "    return rex\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper params\n",
    "layer_0_units = 300\n",
    "drop_in = .25     # input dropout percentage for LSTM layer\n",
    "drop_rec = 0    # recurrent dropout for LSTM\n",
    "drop_lay = .15    # dropout layer?\n",
    "\n",
    "# append the variance to the EMG values\n",
    "n_EMGs = len(EMG_name)\n",
    "seq_len = train_firing_dict['Combined'].shape[1] # num of lags\n",
    "n_neurons = train_firing_dict['Combined'].shape[2]\n",
    "for ii_cond, cond in enumerate(train_EMG_dict.keys()):\n",
    "    train_EMG_dict[cond] = np.append(train_EMG_dict[cond], train_var_dict[cond], axis=1)\n",
    "    train_EMG_dict[cond] = np.append(train_EMG_dict[cond], train_oh_dict[cond], axis=1)\n",
    "\n",
    "# pull out the \"Combined\" conditions for training\n",
    "train_i = train_firing_dict['Combined'] \n",
    "train_o = train_EMG_dict['Combined']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_o[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# create the model\n",
    "mdl = tf.keras.models.Sequential()\n",
    "\n",
    "# add the LSTM layer\n",
    "mdl.add(tf.keras.layers.LSTM(layer_0_units, input_shape = (seq_len,n_neurons), dropout=drop_in, recurrent_dropout=drop_rec))\n",
    "mdl.add(tf.keras.layers.Dropout(drop_lay))\n",
    "mdl.add(tf.keras.layers.Dense(train_o.shape[1]))\n",
    "\n",
    "mdl.compile(loss=vrex_weighted, optimizer='rmsprop', metrics='mse')\n",
    "            \n",
    "mdl.fit(train_i, train_o, epochs=3, verbose=1)\n",
    "\n",
    "\n",
    "\n",
    "train_preds = {}\n",
    "train_VAFs = {}\n",
    "test_preds = {}\n",
    "test_VAFs = {}\n",
    "\n",
    "for cond in train_firing_dict.keys():\n",
    "    train_preds[cond] = mdl.predict(train_firing_dict[cond])\n",
    "    train_VAFs[cond] = metrics.r2_score(train_EMG_dict[cond][:,:n_EMGs], train_preds[cond][:,:n_EMGs], multioutput='raw_values')\n",
    "\n",
    "    if cond != 'Combined': # don't really care about the \"combined\" test case\n",
    "        test_preds[cond] = mdl.predict(test_firing_dict[cond])\n",
    "        test_VAFs[cond] = metrics.r2_score(test_EMG_dict[cond][:,:n_EMGs], test_preds[cond][:,:n_EMGs], multioutput='raw_values')\n",
    "\n",
    "\n",
    "print('----------------------------------------')\n",
    "for ii_name, name in enumerate(EMG_name):\n",
    "    print(name)\n",
    "    for in_name, in_vaf in train_VAFs.items():\n",
    "        print(f\"\\tTrain VAF for {in_name}: {in_vaf[ii_name]}\")\n",
    "    for out_name,out_vaf in test_VAFs.items():\n",
    "        print(f\"\\tTest VAF for {out_name}: {out_vaf[ii_name]}\")\n",
    "\n",
    "\n",
    "plot_rec_pred(train_EMG_dict, train_preds, EMG_name, train_VAFs, title_append = 'training set')\n",
    "plot_rec_pred(test_EMG_dict, test_preds, EMG_name, test_VAFs, title_append = 'testing set')\n",
    "\n",
    "plot_VAFs(train_VAFs, test_VAFs, EMG_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_EMG_dict['Iso'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('MSDS')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "e6f5ab44297089514ffa059ea0d83d6392bebfea7e191fb6b7f26c8412c9553b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
