{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM decoding exploration\n",
    "\n",
    "Going to be looking at using LSTMs (with potentially some changes to the cost function) to decode EMGs from cortical data. This is all based off work from Steph and Josh.\n",
    "\n",
    "\n",
    "Going to start with the old Jango data, then update from there as necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import loadmat\n",
    "from scipy.optimize import least_squares\n",
    "from matplotlib import pyplot as plt\n",
    "# import ipympl\n",
    "\n",
    "# we'll use ridge regression as a comparisson\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn import metrics\n",
    "\n",
    "from tkinter import Tk\n",
    "from tkinter import filedialog as fd # just so I don't have to repeatedly manually enter filenames\n",
    "\n",
    "# and tf stuff\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import backend as K # this was in Josh's version. Not sure why can't use numpy\n",
    "\n",
    "# datetime stuff for logs\n",
    "from datetime import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "# %matplotlib inline\n",
    "# import ipympl\n",
    "%matplotlib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# request the filename\n",
    "root = Tk()\n",
    "mat_fn = fd.askopenfilename(master=root,filetypes=[('matlab data','*.mat')])\n",
    "root.destroy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different loading code if it's data from Josh vs XDS stuff\n",
    "\n",
    "**Josh**\n",
    "It looks like this will input a dictionary containing (among other things) numpy arrays for each of the datasets for the day. We'll pull in each of them, and parse accordingly.\n",
    "\n",
    "In the \"binned\" numpy arrays (two levels down), the organization seems to be:\n",
    "\n",
    "0. timestamps\n",
    "1. metadata\n",
    "2. EMG names\n",
    "3. EMG data\n",
    "4. Force names\n",
    "5. Force data\n",
    "6. electrode and unit number\n",
    "7. channel and unit number\n",
    "8. Firing Rates (in hz)\n",
    "9. Kin (cursor kin?) names\n",
    "10. Kin (cursor kin?) data\n",
    "11. Vel Data\n",
    "12. Vel Names\n",
    "13. Accel Data\n",
    "14. Accel Names\n",
    "15. Digital Words and timestamps\n",
    "16. Targets:\n",
    "\n",
    "    0. corner locations and appearance time \n",
    "    1. rotations and appearance time\n",
    "\n",
    "17. Trial table data\n",
    "18. Trial Table Labels\n",
    "19. \n",
    "20. \n",
    "21. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load it in\n",
    "data = loadmat(mat_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_josh_mat(curr_data):\n",
    "    timestamps = curr_data[0][0][0].reshape(-1)\n",
    "    # create a couple of pandas data frames -- this will make things a bit easier\n",
    "\n",
    "    # EMG\n",
    "    emg_names = [curr_data[0][0][2][ii][0][0] for ii in np.arange(len(curr_data[0][0][2]))]\n",
    "    EMG = pd.DataFrame(curr_data[0][0][3], columns=emg_names, index=timestamps)\n",
    "\n",
    "    # Forces\n",
    "    force_names = [curr_data[0][0][4][ii][0][0] for ii in np.arange(len(curr_data[0][0][4]))]\n",
    "    force = pd.DataFrame(curr_data[0][0][5], columns=force_names, index=timestamps)\n",
    "\n",
    "    # Firing Rates\n",
    "    channel_names = [f\"cc{row[0]:03d}ee{row[1]}\" for row in curr_data[0][0][7]]\n",
    "    firing = pd.DataFrame(curr_data[0][0][8], columns=channel_names, index=timestamps)\n",
    "\n",
    "    # Kin -- not sure if cursor or ang of wrist. Will need to check\n",
    "    kin_names = curr_data[0][0][9]\n",
    "    vel_names = curr_data[0][0][12]\n",
    "    acc_names = curr_data[0][0][14]\n",
    "    kin = pd.DataFrame(curr_data[0][0][10], columns=kin_names, index=timestamps)\n",
    "    try:\n",
    "        kin = kin.join(pd.DataFrame(curr_data[0][0][11], columns=vel_names, index=timestamps))\n",
    "        kin = kin.join(pd.DataFrame(curr_data[0][0][13], columns=acc_names, index=timestamps))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # trial table\n",
    "    trial_names = curr_data[0][0][18]\n",
    "    trial_table = pd.DataFrame(curr_data[0][0][17], columns=trial_names)\n",
    "\n",
    "    return timestamps, firing, EMG, force, kin\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DoneText\n",
    "A quick script that will send me a text message when I ask it to -- so that I can walk away and work on other things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import smtplib\n",
    "import ssl\n",
    "from os import getenv\n",
    "\n",
    "# To send a text when you've finished everything\n",
    "class doneText():\n",
    "    def __init__(self):\n",
    "        self.notif_email = getenv('notif_email') # source for this email\n",
    "        self.notif_pass = getenv('notif_pass')   # pass for the source email\n",
    "        self.notif_target = getenv('notif_target') # target email [phone_num]@[mmsgateway]\n",
    "\n",
    "    def send(self, message):\n",
    "        ssl_context = ssl.create_default_context()\n",
    "        with smtplib.SMTP_SSL('smtp.gmail.com', 465, context=ssl_context) as server:\n",
    "            server.login(self.notif_email, self.notif_pass)\n",
    "            result = server.sendmail(self.notif_email, self.notif_target, f\"Subject:\\n{message}\")\n",
    "\n",
    "            print(f\"Text send result: {result}\")\n",
    "            server.quit()\n",
    "\n",
    "\n",
    "dntxt = doneText() # initialize an instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import winsound\n",
    "\n",
    "def doneTone():\n",
    "    low_A = 440\n",
    "    # C_sharp = int(440* 2**(4/12))\n",
    "    # E = int(440* 2**(7/12))\n",
    "    # hi_A = int(440* 2)\n",
    "\n",
    "    winsound.Beep(low_A, 500)\n",
    "    # winsound.Beep(E, 500)\n",
    "    # winsound.Beep(C_sharp, 500)\n",
    "    # winsound.Beep(hi_A, 1500)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize the data\n",
    "\n",
    "Plot out some good information on the max and variances of each muscle. Should also look at something for the cortex, maybe depth of modulation or avg firing rates?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_names = ['WmTrain','SprTrain','IsoTrain']\n",
    "test_names = ['WmTest','SprTest','IsoTest']\n",
    "\n",
    "_, WmTrain_firing, WmTrain_EMG, _, _ = load_josh_mat(data['WmTrain'])\n",
    "_, WmTest_firing, WmTest_EMG, _, _ = load_josh_mat(data['WmTest'])\n",
    "_, IsoTrain_firing, IsoTrain_EMG, _, _ = load_josh_mat(data['IsoTrain'])\n",
    "_, IsoTest_firing, IsoTest_EMG, _, _ = load_josh_mat(data['IsoTest'])\n",
    "_, SprTrain_firing, SprTrain_EMG, _, _ = load_josh_mat(data['SprTrain'])\n",
    "_, SprTest_firing, SprTest_EMG, _, _ = load_josh_mat(data['SprTest'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bar plots of representative values (max and 95th pctl) of different EMG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------\n",
    "# Max EMG values bar plot\n",
    "\n",
    "fig_emg_max, ax_emg_max = plt.subplots()\n",
    "i_muscles = np.arange(WmTrain_EMG.shape[1]) # indexing on the x axis\n",
    "bar_width = .25\n",
    "\n",
    "\n",
    "ax_emg_max.bar(i_muscles, np.max(WmTrain_EMG,axis=0), width = bar_width, label='Movement')\n",
    "ax_emg_max.bar(i_muscles+bar_width, np.max(IsoTrain_EMG, axis=0), width = bar_width, label='Isometric')\n",
    "ax_emg_max.bar(i_muscles+bar_width*2, np.max(SprTrain_EMG, axis=0), width = bar_width, label='Spring')\n",
    "\n",
    "ax_emg_max.set_xticks(i_muscles+bar_width)\n",
    "ax_emg_max.set_xticklabels(WmTrain_EMG.columns)\n",
    "\n",
    "fig_emg_max.show()\n",
    "_ = ax_emg_max.legend()\n",
    "\n",
    "ax_emg_max.set_xlabel('Muscle')\n",
    "ax_emg_max.set_ylabel('Max Value')\n",
    "\n",
    "# For each bar in the chart, add a text label.\n",
    "for bar in ax_emg_max.patches:\n",
    "    # The text annotation for each bar should be its height.\n",
    "    bar_value = bar.get_height()\n",
    "    # Format the text with commas to separate thousands. You can do\n",
    "    # any type of formatting here though.\n",
    "    text = f'{bar_value:.02f}'\n",
    "    # This will give the middle of each bar on the x-axis.\n",
    "    text_x = bar.get_x() + bar.get_width() / 2\n",
    "    # get_y() is where the bar starts so we add the height to it.\n",
    "    text_y = np.max([bar.get_y() + bar_value, 0.01]) # keep it from going too far below zero, and disappearing\n",
    "    # If we want the text to be the same color as the bar, we can\n",
    "    # get the color like so:\n",
    "    bar_color = bar.get_facecolor()\n",
    "    # If you want a consistent color, you can just set it as a constant, e.g. #222222\n",
    "    ax_emg_max.text(text_x, text_y, text, ha='center', va='bottom', color=bar_color,\n",
    "            size=12)\n",
    "    \n",
    "for spine in ['right','top','bottom','left']:\n",
    "    ax_emg_max.spines[spine].set_visible(False)\n",
    "\n",
    "ax_emg_max.set_title('Maximum EMG Value')\n",
    "\n",
    "# --------------------------------------------\n",
    "# 95th percentile\n",
    "fig_emg_95, ax_emg_95 = plt.subplots()\n",
    "i_muscles = np.arange(WmTrain_EMG.shape[1]) # indexing on the x axis\n",
    "bar_width = .25\n",
    "\n",
    "\n",
    "ax_emg_95.bar(i_muscles, np.percentile(WmTrain_EMG, 95,axis=0), width = bar_width, label='Movement')\n",
    "ax_emg_95.bar(i_muscles+bar_width, np.percentile(IsoTrain_EMG, 95, axis=0), width = bar_width, label='Isometric')\n",
    "ax_emg_95.bar(i_muscles+2*bar_width, np.percentile(SprTrain_EMG, 95, axis=0), width = bar_width, label='Spring')\n",
    "\n",
    "ax_emg_95.set_xticks(i_muscles+bar_width)\n",
    "ax_emg_95.set_xticklabels(WmTrain_EMG.columns)\n",
    "\n",
    "# fig_emg_95.show()\n",
    "_ = ax_emg_95.legend()\n",
    "\n",
    "ax_emg_95.set_xlabel('Muscle')\n",
    "ax_emg_95.set_ylabel('95th Percentile')\n",
    "\n",
    "# For each bar in the chart, add a text label.\n",
    "for bar in ax_emg_95.patches:\n",
    "    # The text annotation for each bar should be its height.\n",
    "    bar_value = bar.get_height()\n",
    "    # Format the text with commas to separate thousands. You can do\n",
    "    # any type of formatting here though.\n",
    "    text = f'{bar_value:.02f}'\n",
    "    # This will give the middle of each bar on the x-axis.\n",
    "    text_x = bar.get_x() + bar.get_width() / 2\n",
    "    # get_y() is where the bar starts so we add the height to it.\n",
    "    text_y = np.max([bar.get_y() + bar_value, 0.01]) # keep it from going too far below zero, and disappearing\n",
    "    # If we want the text to be the same color as the bar, we can\n",
    "    # get the color like so:\n",
    "    bar_color = bar.get_facecolor()\n",
    "    # If you want a consistent color, you can just set it as a constant, e.g. #222222\n",
    "    ax_emg_95.text(text_x, text_y, text, ha='center', va='bottom', color=bar_color,\n",
    "            size=12)\n",
    "\n",
    "\n",
    "for spine in ['right','top','bottom','left']:\n",
    "    ax_emg_95.spines[spine].set_visible(False)\n",
    "\n",
    "ax_emg_95.set_title('95th Percentile of EMG')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing mean firing rates of different conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_cort, ax_cort = plt.subplots(ncols=3)\n",
    "\n",
    "Wm_means = np.mean(WmTrain_firing, axis=0)\n",
    "Iso_means = np.mean(IsoTrain_firing, axis=0)\n",
    "Spr_means = np.mean(SprTrain_firing, axis=0)\n",
    "\n",
    "\n",
    "\n",
    "# scatters between mean firing rates\n",
    "ax_cort[0].scatter(Wm_means, Iso_means, s=2)\n",
    "ax_cort[0].plot([0,40],[0,40],c='k', alpha=.3)\n",
    "ax_cort[1].scatter(Wm_means, Spr_means, s=2)\n",
    "ax_cort[1].plot([0,40],[0,40],c='k', alpha=.3)\n",
    "ax_cort[2].scatter(Iso_means, Spr_means, s=2)\n",
    "ax_cort[2].plot([0,40],[0,40],c='k', alpha=.3)\n",
    "\n",
    "\n",
    "# x and y labels\n",
    "ax_cort[0].set_xlabel('Movement')\n",
    "ax_cort[0].set_ylabel('Isometric')\n",
    "ax_cort[1].set_xlabel('Movement')\n",
    "ax_cort[1].set_ylabel('Spring')\n",
    "ax_cort[2].set_xlabel('Isometric')\n",
    "ax_cort[2].set_ylabel('Spring')\n",
    "\n",
    "# making the axes square and removing the spines\n",
    "for axis in ax_cort:\n",
    "    axis.set_aspect('equal',adjustable='box')\n",
    "    for spine in ['right','top','bottom','left']:\n",
    "        ax_emg_95.spines[spine].set_visible(False)\n",
    "    axis.set_title('Mean Firing Rates')\n",
    "\n",
    "\n",
    "fig_cort.set_label('Compared Mean Firing Rates across conditions')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same with the variance of the firing rates (thinking depth of modulation sort of thing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_cort, ax_cort = plt.subplots(ncols=3)\n",
    "\n",
    "Wm_vars = np.var(WmTrain_firing, axis=0)\n",
    "Iso_vars = np.var(IsoTrain_firing, axis=0)\n",
    "Spr_vars = np.var(SprTrain_firing, axis=0)\n",
    "\n",
    "\n",
    "\n",
    "# scatters between var firing rates\n",
    "ax_cort[0].scatter(Wm_vars, Iso_vars, s=2)\n",
    "ax_cort[1].scatter(Wm_vars, Spr_vars, s=2)\n",
    "ax_cort[2].scatter(Iso_vars, Spr_vars, s=2)\n",
    "\n",
    "\n",
    "# x and y labels\n",
    "ax_cort[0].set_xlabel('Movement')\n",
    "ax_cort[0].set_ylabel('Isometric')\n",
    "ax_cort[1].set_xlabel('Movement')\n",
    "ax_cort[1].set_ylabel('Spring')\n",
    "ax_cort[2].set_xlabel('Isometric')\n",
    "ax_cort[2].set_ylabel('Spring')\n",
    "\n",
    "# making the axes square and removing the spines\n",
    "for axis in ax_cort:\n",
    "    axis.set_aspect('equal',adjustable='box')\n",
    "    max_lim = np.max([axis.get_xlim()[1],axis.get_ylim()[1]])\n",
    "    min_lim = np.min([axis.get_xlim()[0],axis.get_ylim()[1]])\n",
    "    axis.set_xlim([min_lim, max_lim])\n",
    "    axis.set_ylim([min_lim, max_lim])\n",
    "    for spine in ['right','top','bottom','left']:\n",
    "        axis.spines[spine].set_visible(False)\n",
    "    axis.set_title('Variance of Firing Rates')\n",
    "    axis.plot([min_lim, max_lim],[min_lim, max_lim],c='k', alpha=.3)\n",
    "\n",
    "fig_cort.set_label('Compared var Firing Rates across conditions')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model building \n",
    "Look through a couple of different model types, look to see how they are trained\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear with Static Non-linearity\n",
    "\n",
    "Using the lab default -- build a wiener filter, fit it, then fit with a static polynomial on top of the form\n",
    "\n",
    "$Ax^2 + Bx + C$\n",
    "\n",
    "Where $x$ is the original EMG prediction, and the output is the new EMG prediction\n",
    "\n",
    "Alternatively, I have also allowed to predict using an exponential activation \n",
    "\n",
    "$Ae^{Bx} + C$\n",
    "\n",
    "Also giving the options for a sigmoid\n",
    "\n",
    "\n",
    "**Starting with defining our nonlinearity methods**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using scipy's least_squares:\n",
    "def non_linearity(p, y_pred, nonlinear_type):\n",
    "    if nonlinear_type == 'poly':\n",
    "        return p[0] + p[1]*y_pred + p[2]*y_pred**2\n",
    "    elif nonlinear_type == 'exponential':\n",
    "        return p[0]*np.exp(p[1]*y_pred) + p[2]\n",
    "    elif nonlinear_type == 'sigmoid':\n",
    "        return p[1] * 1/(1 + np.exp(-10*(y_pred-p[0])))\n",
    "\n",
    "def non_linearity_residuals(p, y_pred, y_act, nonlinear_type):\n",
    "    if nonlinear_type == 'poly':\n",
    "        return y_act - (p[0] + p[1]*y_pred + p[2]*y_pred**2)\n",
    "    elif nonlinear_type == 'exponential':\n",
    "        return y_act - (p[0]*np.exp(p[1]*y_pred) + p[2])\n",
    "    elif nonlinear_type == 'sigmoid':\n",
    "        return y_act - (p[1] * 1/(1 + np.exp(-10*(y_pred-p[0]))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next a function that compares Wiener filter models with Wiener cascades, reports the VAF (Cooefficient of Determination) and gives plots for the validation predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a function that we can just call multiple times, so then we can just quickly run through all of the different combinations\n",
    "\n",
    "\n",
    "def basic_decoder_comparison(train_firing, train_EMG, retrain_firing, retrain_EMG, test_firing, test_EMG, test_timestamps, nonlinear_type, save_plot=True):\n",
    "    wiener_input = pd.DataFrame() # empty dataframe\n",
    "    n_lags = 10 # number of lags\n",
    "    for ii in np.arange(n_lags): # create the lagged dataframe\n",
    "        col_dict = dict(zip(train_firing.columns, train_firing.columns+f\"_lag{ii}\"))\n",
    "        wiener_input = wiener_input.join(train_firing.shift(-ii, fill_value=0).rename(columns=col_dict), how='outer')\n",
    "\n",
    "    wiener_test = pd.DataFrame() # empty dataframe\n",
    "    for ii in np.arange(n_lags): # create the lagged dataframe\n",
    "        col_dict = dict(zip(test_firing.columns, test_firing.columns+f\"_lag{ii}\"))\n",
    "        wiener_test = wiener_test.join(test_firing.shift(-ii, fill_value=0).rename(columns=col_dict), how='outer')\n",
    "        \n",
    "    wiener_retrain = pd.DataFrame() # empty dataframe\n",
    "    for ii in np.arange(n_lags): # create the lagged dataframe\n",
    "        col_dict = dict(zip(retrain_firing.columns, retrain_firing.columns+f\"_lag{ii}\"))\n",
    "        wiener_retrain = wiener_retrain.join(retrain_firing.shift(-ii, fill_value=0).rename(columns=col_dict), how='outer')\n",
    "\n",
    "\n",
    "\n",
    "    if nonlinear_type == 'poly':\n",
    "        init_pred = [.1, .1, .1]\n",
    "    elif nonlinear_type == 'exponential':\n",
    "        init_pred = [1, .1, .2]\n",
    "    elif nonlinear_type == 'sigmoid':\n",
    "        init_pred = [.1, .5]\n",
    "\n",
    "    mdl_A = linear_model.LinearRegression(fit_intercept=True)\n",
    "    mdl_B = {} # a dictionary of numpy polynomials. Probably a better way to do this, maybe Xuan's method... oh well\n",
    "\n",
    "    mdl_A.fit(wiener_input, train_EMG)# fit the first model\n",
    "    prefit_EMG = mdl_A.predict(wiener_input) # get the initially predicted EMGs\n",
    "    retrain_pred = mdl_A.predict(wiener_retrain) # from a training set on a separate condition -- to properly hold out test data\n",
    "    prefit_VAF = metrics.explained_variance_score(train_EMG, prefit_EMG, multioutput='raw_values')\n",
    "    nonlin_EMG = np.zeros(prefit_EMG.shape)\n",
    "\n",
    "    print('Training Results\\n')\n",
    "\n",
    "    for ii in np.arange(len(train_EMG.columns)):\n",
    "        muscle = train_EMG.columns[ii]\n",
    "        mdl_B[muscle] = least_squares(non_linearity_residuals, init_pred, args=(prefit_EMG[:,ii], train_EMG.iloc[:,ii].to_numpy(), nonlinear_type)).x\n",
    "        # print('--------------------------------------------------------')\n",
    "        print(muscle)\n",
    "        print(f\"\\tLinear VAF: {prefit_VAF[ii]:.03f}\")\n",
    "        nonlin_EMG[:,ii] = non_linearity(mdl_B[muscle],(prefit_EMG[:,ii]), nonlinear_type)\n",
    "        print(f\"\\tNonLinear VAF: {metrics.explained_variance_score(train_EMG.iloc[:,ii],nonlin_EMG[:,ii]):.03f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # predicting the test set\n",
    "    prefit_test = mdl_A.predict(wiener_test)\n",
    "    prefit_test_VAF = metrics.explained_variance_score(test_EMG, prefit_test, multioutput='raw_values')\n",
    "    nonlin_test = np.zeros(prefit_test.shape)\n",
    "    nonlin_within_test = np.zeros(prefit_test.shape)\n",
    "    nonlin_VAF = np.zeros(prefit_test_VAF.shape)\n",
    "    nonlin_within_VAF = np.zeros(prefit_test_VAF.shape)\n",
    "    mdl_C = {} # for a separate non-linearity, built for the second condition.\n",
    "\n",
    "    print('\\n------------------------------------------------------------\\n')\n",
    "    print('Testing Results\\n')\n",
    "    for ii in np.arange(len(train_EMG.columns)):\n",
    "        muscle = test_EMG.columns[ii]\n",
    "        mdl_C[muscle] = least_squares(non_linearity_residuals, init_pred, args=(retrain_pred[:,ii], retrain_EMG.iloc[:,ii].to_numpy(), nonlinear_type)).x\n",
    "        # print('--------------------------------------------------------')\n",
    "        print(muscle)\n",
    "        print(f\"\\tLinear VAF: {prefit_test_VAF[ii]:.03f}\")\n",
    "        nonlin_test[:,ii] = non_linearity(mdl_B[muscle],(prefit_test[:,ii]), nonlinear_type)\n",
    "        nonlin_within_test[:,ii] = non_linearity(mdl_C[muscle],(prefit_test[:,ii]), nonlinear_type)\n",
    "        nonlin_VAF[ii] = metrics.explained_variance_score(test_EMG.iloc[:,ii],nonlin_test[:,ii])\n",
    "        nonlin_within_VAF[ii] = metrics.explained_variance_score(test_EMG.iloc[:,ii],nonlin_within_test[:,ii])\n",
    "        print(f\"\\tPre-built Nonlinearity VAF: {nonlin_VAF[ii]:.03f}\")\n",
    "        print(f\"\\tRe-built Nonlinearity VAF: {nonlin_within_VAF[ii]:.03f}\")\n",
    "\n",
    "    # Plotting the test data -- so that we can see how  the non-linearities act between types\n",
    "    n_rows = int(np.ceil(np.sqrt(len(train_EMG.columns))))\n",
    "    fig_nl_test, ax_nl_test = plt.subplots(nrows=n_rows, ncols=n_rows, sharex=True, constrained_layout=True)\n",
    "\n",
    "    for muscle_ii in np.arange(len(train_EMG.columns)):\n",
    "        row_i = int(muscle_ii//n_rows)\n",
    "        col_i = int(muscle_ii%n_rows)\n",
    "        ax_nl_test[row_i,col_i].plot(test_timestamps, test_EMG.iloc[:,muscle_ii], label='Recorded')\n",
    "        ax_nl_test[row_i,col_i].plot(test_timestamps,prefit_test[:,muscle_ii], label=f'Linear VAF: {prefit_test_VAF[muscle_ii]:.03f}')\n",
    "        ax_nl_test[row_i,col_i].plot(test_timestamps,nonlin_test[:,muscle_ii], label=f'NonLin VAF: {nonlin_VAF[muscle_ii]:.03f}')\n",
    "        ax_nl_test[row_i,col_i].plot(test_timestamps,nonlin_within_test[:,muscle_ii], label=f'Rebuilt NonLin VAF: {nonlin_within_VAF[muscle_ii]:.03f}')\n",
    "        ax_nl_test[row_i,col_i].set_title(f\"{test_EMG.columns[muscle_ii]}\")\n",
    "        ax_nl_test[row_i,col_i].set_xlabel(f\"Time (s)\")\n",
    "        ax_nl_test[row_i,col_i].set_ylabel(\"EMG envelope\")\n",
    "        \n",
    "        _ = ax_nl_test[row_i,col_i].legend()\n",
    "\n",
    "        # turn off the spines\n",
    "        for spine in ['right','top','bottom','left']:\n",
    "            ax_nl_test[row_i,col_i].spines[spine].set_visible(False)\n",
    "            \n",
    "    if save_plot:\n",
    "        fig_nl_test.savefig('Wiener_Cascade_Comparison.svg')\n",
    "\n",
    "    # let's also plot the VAFs in a clean manner so that it's easy to compare\n",
    "    fig_vaf, ax_vaf = plt.subplots()\n",
    "    i_muscles = np.arange(len(test_EMG.columns)) # indexing on the x axis\n",
    "    bar_width = .25\n",
    "\n",
    "    ax_vaf.bar(i_muscles, prefit_test_VAF, width = bar_width, label='Linear')\n",
    "    ax_vaf.bar(i_muscles + bar_width, nonlin_VAF, width = bar_width, label='Nonlinear')\n",
    "    ax_vaf.bar(i_muscles + 2*bar_width, nonlin_within_VAF, width = bar_width, label='Rebuilt Nonlinear')\n",
    "\n",
    "    ax_vaf.set_xticks(i_muscles + 1*bar_width)\n",
    "    ax_vaf.set_xticklabels(test_EMG.columns)\n",
    "\n",
    "    ax_vaf.set_ylim([-.05, 1.05])\n",
    "    ax_vaf.set_xlabel('Muscle')\n",
    "    ax_vaf.set_ylabel('Coefficient of Determination')\n",
    "\n",
    "    ax_vaf.legend()\n",
    "\n",
    "    # For each bar in the chart, add a text label.\n",
    "    for bar in ax_vaf.patches:\n",
    "        # The text annotation for each bar should be its height.\n",
    "        bar_value = bar.get_height()\n",
    "        # Format the text with commas to separate thousands. You can do\n",
    "        # any type of formatting here though.\n",
    "        text = f'{bar_value:.02f}'\n",
    "        # This will give the middle of each bar on the x-axis.\n",
    "        text_x = bar.get_x() + bar.get_width() / 2\n",
    "        # get_y() is where the bar starts so we add the height to it.\n",
    "        text_y = np.max([bar.get_y() + bar_value, 0.01]) # keep it from going too far below zero, and disappearing\n",
    "        # If we want the text to be the same color as the bar, we can\n",
    "        # get the color like so:\n",
    "        bar_color = bar.get_facecolor()\n",
    "        # If you want a consistent color, you can just set it as a constant, e.g. #222222\n",
    "        ax_vaf.text(text_x, text_y, text, ha='center', va='bottom', color=bar_color,\n",
    "                size=12)\n",
    "\n",
    "    # turn off the spines\n",
    "    for spine in ['right','top','bottom','left']:\n",
    "        ax_vaf.spines[spine].set_visible(False)\n",
    "\n",
    "\n",
    "    if save_plot:\n",
    "        fig_vaf.savefig('Wiener_VAF.svg')\n",
    "\n",
    "    return nonlin_EMG\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_comparisons(train_firing, train_EMG, test_firing, test_EMG, test_timestamps, plot=True, save_plot=True):\n",
    "    # hyper params\n",
    "    layer_0_units = 300\n",
    "    drop_in = .25     # input dropout percentage for LSTM layer\n",
    "    drop_rec = 0    # recurrent dropout for LSTM\n",
    "    drop_lay = .15    # dropout layer?\n",
    "\n",
    "    # # input hyper params -- reshape input vector\n",
    "    # batch_size = 64 # why not? will test to see training accuracy after\n",
    "    # seq_len = train_firing.shape[0]//batch_size # splitting out the batches\n",
    "    n_neurons = train_firing.shape[1] # number of neurons\n",
    "    n_EMGs = train_EMG.shape[1]\n",
    "    seq_len = 12\n",
    "    rnn_train_i = np.zeros((train_firing.shape[0],seq_len, train_firing.shape[1]))\n",
    "    rnn_test_i = np.zeros((test_firing.shape[0],seq_len, test_firing.shape[1]))\n",
    "    rnn_train_o = train_EMG.to_numpy()\n",
    "    rnn_test_o = test_EMG.to_numpy()\n",
    "    \n",
    "    # normalize the EMGs\n",
    "    EMG_std = np.std(rnn_train_o, axis=0)\n",
    "    for ii in np.arange(rnn_train_o.shape[1]):\n",
    "        rnn_train_o[:,ii] = rnn_train_o[:,ii]/EMG_std[ii]\n",
    "        rnn_test_o[:,ii] = rnn_test_o[:,ii]/EMG_std[ii]\n",
    "    \n",
    "    # create the sequences\n",
    "    for ii in np.arange(10):\n",
    "        rnn_train_i[:,ii,:] = train_firing.shift(-ii, fill_value=0).to_numpy()\n",
    "        rnn_test_i[:,ii,:] = test_firing.shift(-ii, fill_value=0).to_numpy()\n",
    "\n",
    "    # Set up the LSTMs\n",
    "    mdl = tf.keras.models.Sequential()\n",
    "\n",
    "\n",
    "    mdl.add(tf.keras.layers.LSTM(layer_0_units, input_shape = (seq_len,n_neurons), dropout=drop_in, recurrent_dropout=drop_rec))\n",
    "    if drop_lay:\n",
    "        mdl.add(tf.keras.layers.Dropout(drop_lay)) # dropout layer if wanted\n",
    "#     mdl.add(tf.keras.layers.Dense(train_EMG.shape[1], activation='relu')) # dense combination layer\n",
    "    mdl.add(tf.keras.layers.Dense(train_EMG.shape[1])) # dense combination layer\n",
    "    mdl.compile(loss='mse', optimizer='rmsprop', metrics=['accuracy'])\n",
    "    \n",
    "    mdl.fit(rnn_train_i, rnn_train_o, epochs=20, verbose=False)\n",
    "    \n",
    "    \n",
    "    train_pred = mdl.predict(rnn_train_i)\n",
    "    test_pred = mdl.predict(rnn_test_i)\n",
    "    train_VAFs = metrics.explained_variance_score(rnn_train_o, train_pred, multioutput='raw_values')\n",
    "    test_VAFs = metrics.explained_variance_score(rnn_test_o, test_pred, multioutput='raw_values')\n",
    "    \n",
    "    print('----------------------------------------')\n",
    "    for ii in np.arange(len(train_EMG.columns)):\n",
    "        print(train_EMG.columns[ii])\n",
    "        print(f\"\\tTrain VAF: {train_VAFs[ii]}\")\n",
    "        print(f\"\\tTest VAF: {test_VAFs[ii]}\")\n",
    "    \n",
    "    \n",
    "    # plottin\n",
    "    \n",
    "    if plot:\n",
    "        n_rows = int(np.ceil(np.sqrt(len(train_EMG.columns))))\n",
    "        fig_lstm, ax_lstm = plt.subplots(nrows=n_rows, ncols=n_rows, sharex=True, constrained_layout=True)\n",
    "\n",
    "        for muscle_ii in np.arange(len(train_EMG.columns)):\n",
    "            row_i = int(muscle_ii//n_rows)\n",
    "            col_i = int(muscle_ii%n_rows)\n",
    "            ax_lstm[row_i,col_i].plot(test_timestamps, test_EMG.iloc[:,muscle_ii]*EMG_std[ii], label='Recorded')\n",
    "            ax_lstm[row_i,col_i].plot(test_timestamps,test_pred[:,muscle_ii]*EMG_std[ii], label=f'LSTM VAF: {test_VAFs[muscle_ii]:.03f}')\n",
    "            ax_lstm[row_i,col_i].set_title(f\"{test_EMG.columns[muscle_ii]}\")\n",
    "            _ = ax_lstm[row_i,col_i].legend()\n",
    "\n",
    "            # turn off the spines\n",
    "            for spine in ['right','top','bottom','left']:\n",
    "                ax_lstm[row_i,col_i].spines[spine].set_visible(False)\n",
    "\n",
    "        if save_plot:\n",
    "            fig_lstm.savefig('LSTM_traces.svg')\n",
    "                \n",
    "                \n",
    "        # let's also plot the VAFs in a clean manner so that it's easy to compare\n",
    "        fig_vaf, ax_vaf = plt.subplots()\n",
    "        i_muscles = np.arange(len(test_EMG.columns)) # indexing on the x axis\n",
    "        bar_width = .3\n",
    "\n",
    "        ax_vaf.bar(i_muscles, train_VAFs, width = bar_width, label='Train')\n",
    "        ax_vaf.bar(i_muscles + bar_width, test_VAFs, width = bar_width, label='Test')\n",
    "\n",
    "        ax_vaf.set_xticks(i_muscles + bar_width/2)\n",
    "        ax_vaf.set_xticklabels(test_EMG.columns)\n",
    "\n",
    "        ax_vaf.set_ylim([-.05, 1.05])\n",
    "        ax_vaf.set_xlabel('Muscle')\n",
    "        ax_vaf.set_ylabel('VAF')\n",
    "\n",
    "        ax_vaf.legend()\n",
    "\n",
    "        # For each bar in the chart, add a text label.\n",
    "        for bar in ax_vaf.patches:\n",
    "            # The text annotation for each bar should be its height.\n",
    "            bar_value = bar.get_height()\n",
    "            # Format the text with commas to separate thousands. You can do\n",
    "            # any type of formatting here though.\n",
    "            text = f'{bar_value:.02f}'\n",
    "            # This will give the middle of each bar on the x-axis.\n",
    "            text_x = bar.get_x() + bar.get_width() / 2\n",
    "            # get_y() is where the bar starts so we add the height to it.\n",
    "            text_y = np.max([bar.get_y() + bar_value, 0.01]) # keep it from going too far below zero, and disappearing\n",
    "            # If we want the text to be the same color as the bar, we can\n",
    "            # get the color like so:\n",
    "            bar_color = bar.get_facecolor()\n",
    "            # If you want a consistent color, you can just set it as a constant, e.g. #222222\n",
    "            ax_vaf.text(text_x, text_y, text, ha='center', va='bottom', color=bar_color,\n",
    "                    size=12)\n",
    "\n",
    "        # turn off the spines\n",
    "        for spine in ['right','top','bottom','left']:\n",
    "            ax_vaf.spines[spine].set_visible(False)\n",
    "\n",
    "\n",
    "        if save_plot:\n",
    "            fig_vaf.savefig('LSTM_VAF.svg')\n",
    "\n",
    "\n",
    "    return test_VAFs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Custom Loss functions\n",
    "\n",
    "First the weighted loss function. This one calculates the MSE, but weights the value for each point in time by the variance of that particular task. This balances the training so that the model is able to train for conditions with different EMG ranges (the whole idea behind our system...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weight the losses by the std of that particular range in time and muscle.\n",
    "# for hybrid decoders\n",
    "def hybrid_weight_loss(target, pred):\n",
    "    # inputs: \n",
    "    #         target is the recorded data, plus the weights since this needs to be callable by tf\n",
    "    #                First half of the columns of the data will be EMG, second half will be the weights\n",
    "    #         pred   is the current prediction values\n",
    "    num_targets = K.shape(target)[1]//2 # number of cols / 2\n",
    "    err = (target[:, 0:num_targets] - pred[:,0:num_targets]) # subtract the values\n",
    "    se = K.square(err) * target[:,num_targets:] # multiply the square error by the gains\n",
    "    mse = K.mean(se, axis=-1)\n",
    "    return mse\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next is the variance Risk Extrapolation (V-REx) from Krueger et al 2021. The purpose of this is to maximize the out-of-distribution generalization. This places a penalty on the variance of the risk (MSE as defined...)\n",
    "\n",
    "$ R_{V-REx}(\\theta) = \\beta * \\sigma^2(R_1(\\theta)....R_m(\\theta)) + \\sum_{e=1}^{m}R_e(\\theta) $\n",
    "\n",
    "Where risk is defined as \n",
    " $ R = \\sum_{i=0}^{I}\\frac{\\hat{y_i}-y_i}{I} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vREx loss function\n",
    "def vrex_loss(target, pred):\n",
    "    # from the Risk Extrapolation paper\n",
    "    # B = 0 #\n",
    "    # B = .5 #\n",
    "    # B = 1 #\n",
    "    B = 5 #\n",
    "    # B = 10 #\n",
    "    # B = 50 #\n",
    "    # B = 100 #\n",
    "    \n",
    "    err = target[:,:-1] - pred[:,:-1] # without the condition flag\n",
    "    se_musc = K.square(err) # squared error\n",
    "    mse_musc = tf.expand_dims(K.mean(se_musc, axis=-1),-1) # mean squared error for each sample\n",
    "    \n",
    "    # now create a one-hot matrix for timestamps with a one for the appropriate condition\n",
    "    conditions = target[:,-1] # condition flag\n",
    "    u_conds,i_conds = tf.unique(conditions)\n",
    "    cond_oh = tf.transpose(tf.one_hot(i_conds, len(u_conds))) # create a mask the same size as the risk\n",
    "    \n",
    "    # split up the risks (MSE for right now) per condition\n",
    "    sum_risks = tf.matmul(cond_oh,mse_musc) # this gives us the per-condition sum of MSEs\n",
    "    risks = tf.math.divide(sum_risks, K.sum(cond_oh, axis=1)) # and this should average them\n",
    "\n",
    "    \n",
    "    rex = B*K.var(risks) + K.sum(risks) # and now to run the risk extrapolation step\n",
    "\n",
    "    return rex\n",
    "    # return mse_musc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vrex_weighted(target, pred):\n",
    "    # weighting the risks based on the var of the EMG\n",
    "    # instead of using a one-hot matrix like above to keep track of the conditions,\n",
    "    # we'll just use the passed variance values (since that will be different per-condition)\n",
    "\n",
    "    B = 0 #\n",
    "    # B = .5 #\n",
    "    # B = 1 #\n",
    "    # B = 5 #\n",
    "    # B = 10 #\n",
    "    # B = 50 #\n",
    "    # B = 100 #\n",
    "    \n",
    "    err = target[:,:-1] - pred[:,:-1] # find the error\n",
    "    se_musc = K.square(err) # square it\n",
    "    mse_musc = tf.expand_dims(K.mean(se_musc, axis=-1),-1) # expand dims so that it's (T,1) rather than (T,)\n",
    "    \n",
    "    # separate the conditions based on the passed variances\n",
    "    var = target[:,-1] # last column\n",
    "    u_var,i_var = tf.unique(var) # for another one-hot matrix\n",
    "    var_oh = tf.transpose(tf.one_hot(i_var, len(u_var))) # variances\n",
    "\n",
    "    split_risk = tf.matmul(var_oh, mse_musc)\n",
    "    weighted_risk = tf.multiply(tf.expand_dims(u_var, axis=-1), split_risk)\n",
    "    risks = tf.math.divide(weighted_risk, K.sum(var_oh, axis=1)) # get the mean\n",
    "\n",
    "    rex = B*K.var(risks) + K.sum(risks)\n",
    "\n",
    "    return rex\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_across_weighted(train_firing, train_EMG, test_firing, test_EMG, test_timestamps, plot=True):\n",
    "    if type(train_firing) is not list:\n",
    "        print(f\"training data must be a list, not a {type(train_firing)}\")\n",
    "        return -1\n",
    "    \n",
    "    # hyper params\n",
    "    layer_0_units = 300\n",
    "    drop_in = .25     # input dropout percentage for LSTM layer\n",
    "    drop_rec = 0    # recurrent dropout for LSTM\n",
    "    drop_lay = .15    # dropout layer?\n",
    "    \n",
    "    # size and name of outputs\n",
    "    n_target = train_EMG[0].shape[1] # dimensionality of target (EMGs usually)\n",
    "    col_names = train_EMG[0].columns\n",
    "    \n",
    "    \n",
    "    # put together the training targets \n",
    "    # This means both the EMGs and the variance for that portion of the training set\n",
    "    loss_weights = np.ndarray((0,n_target)) # weights for the training losses\n",
    "    rnn_train_o = np.ndarray((0,n_target*2)) # rnn target for training set. Going to also contain the weights\n",
    "    rnn_test_o = test_EMG.to_numpy() # don't need the weights for the test set\n",
    "    \n",
    "    # initialize the input sequence data\n",
    "    n_neurons = train_firing[0].shape[1] # number of neurons\n",
    "    seq_len = 10\n",
    "    rnn_train_i = np.ndarray((0,seq_len, n_neurons))\n",
    "    rnn_test_i = np.ndarray((test_firing.shape[0], seq_len, n_neurons))\n",
    "    \n",
    "    # training target set\n",
    "    for target in train_EMG:\n",
    "        # put together the weights -- the variances, since we're doing MSE as our training loss\n",
    "        temp_var = np.matmul(np.ones((target.shape[0],1)),np.var(target.to_numpy(), axis=0).reshape(1,-1))\n",
    "#         loss_weights = np.append(loss_weights,temp_var, axis=0)\n",
    "        # append the training targets\n",
    "        temp_train = np.append(target.to_numpy(), 1./temp_var, axis=1)\n",
    "        rnn_train_o = np.append(rnn_train_o, temp_train, axis=0)\n",
    "    \n",
    "    \n",
    "    # testing target set -- have to append the neural firing\n",
    "    for train in train_firing:\n",
    "        temp_train_i = np.ndarray((train.shape[0], seq_len, n_neurons))\n",
    "        for ii in np.arange(seq_len):\n",
    "            temp_train_i[:,ii,:] = train.shift(-ii, fill_value=0).to_numpy()\n",
    "        rnn_train_i = np.append(rnn_train_i, temp_train_i, axis=0)\n",
    "            \n",
    "    for ii in np.arange(seq_len):\n",
    "        rnn_test_i[:,ii,:] = test_firing.shift(-ii, fill_value=0).to_numpy()\n",
    "        \n",
    "    \n",
    "        # Set up the LSTMs\n",
    "    mdl = tf.keras.models.Sequential()\n",
    "\n",
    "\n",
    "    mdl.add(tf.keras.layers.LSTM(layer_0_units, input_shape = (seq_len,n_neurons), dropout=drop_in, recurrent_dropout=drop_rec))\n",
    "    if drop_lay:\n",
    "        mdl.add(tf.keras.layers.Dropout(drop_lay)) # dropout layer if wanted\n",
    "#     mdl.add(tf.keras.layers.Dense(n_target*2, activation='relu')) # dense combination layer -- x2 to account for weights\n",
    "    mdl.add(tf.keras.layers.Dense(n_target*2)) # try with linear -- how does it compare?\n",
    "    mdl.compile(loss=hybrid_weight_loss, optimizer='rmsprop', metrics=['MeanAbsoluteError'])\n",
    "    \n",
    "#     mdl.fit(rnn_train_i, rnn_train_o, epochs=20, batch_size=256, verbose=True)\n",
    "    mdl.fit(rnn_train_i, rnn_train_o, epochs=40, verbose=False)\n",
    "    \n",
    "    \n",
    "    train_pred = mdl.predict(rnn_train_i)[:,:n_target]\n",
    "    test_pred = mdl.predict(rnn_test_i)[:,:n_target]\n",
    "    train_VAFs = metrics.explained_variance_score(rnn_train_o[:,:n_target], train_pred, multioutput='raw_values')\n",
    "    test_VAFs = metrics.explained_variance_score(rnn_test_o, test_pred, multioutput='raw_values')\n",
    "    \n",
    "    print('----------------------------------------')\n",
    "    for ii in np.arange(n_target):\n",
    "        print(col_names[ii])\n",
    "        print(f\"\\tTrain VAF: {train_VAFs[ii]}\")\n",
    "        print(f\"\\tTest VAF: {test_VAFs[ii]}\")\n",
    "    \n",
    "    if plot:\n",
    "        # plottin\n",
    "        n_rows = int(np.ceil(np.sqrt(n_target)))\n",
    "        fig_lstm, ax_lstm = plt.subplots(nrows=n_rows, ncols=n_rows, sharex=True, constrained_layout=True)\n",
    "\n",
    "        for muscle_ii in np.arange(n_target):\n",
    "            row_i = int(muscle_ii//n_rows)\n",
    "            col_i = int(muscle_ii%n_rows)\n",
    "            ax_lstm[row_i,col_i].plot(test_timestamps, rnn_test_o[:,muscle_ii], label='Recorded')\n",
    "            ax_lstm[row_i,col_i].plot(test_timestamps,test_pred[:,muscle_ii], label=f'LSTM VAF: {test_VAFs[muscle_ii]:.03f}')\n",
    "            ax_lstm[row_i,col_i].set_title(f\"{col_names[muscle_ii]}\")\n",
    "            _ = ax_lstm[row_i,col_i].legend()\n",
    "\n",
    "            # turn off the spines\n",
    "            for spine in ['right','top','bottom','left']:\n",
    "                ax_lstm[row_i,col_i].spines[spine].set_visible(False)\n",
    "    \n",
    "    \n",
    "        # let's also plot the VAFs in a clean manner so that it's easy to compare\n",
    "        fig_vaf, ax_vaf = plt.subplots()\n",
    "        i_muscles = np.arange(n_target) # indexing on the x axis\n",
    "        bar_width = .3\n",
    "\n",
    "        ax_vaf.bar(i_muscles, train_VAFs, width = bar_width, label='Train')\n",
    "        ax_vaf.bar(i_muscles + bar_width, test_VAFs, width = bar_width, label='Test')\n",
    "\n",
    "        ax_vaf.set_xticks(i_muscles + bar_width/2)\n",
    "        ax_vaf.set_xticklabels(col_names)\n",
    "\n",
    "        ax_vaf.set_ylim([-.05, 1.05])\n",
    "        ax_vaf.set_xlabel('Muscle')\n",
    "        ax_vaf.set_ylabel('VAF')\n",
    "\n",
    "        ax_vaf.legend()\n",
    "\n",
    "        # For each bar in the chart, add a text label.\n",
    "        for bar in ax_vaf.patches:\n",
    "            # The text annotation for each bar should be its height.\n",
    "            bar_value = bar.get_height()\n",
    "            # Format the text with commas to separate thousands. You can do\n",
    "            # any type of formatting here though.\n",
    "            text = f'{bar_value:.02f}'\n",
    "            # This will give the middle of each bar on the x-axis.\n",
    "            text_x = bar.get_x() + bar.get_width() / 2\n",
    "            # get_y() is where the bar starts so we add the height to it.\n",
    "            text_y = np.max([bar.get_y() + bar_value, 0.01]) # keep it from going too far below zero, and disappearing\n",
    "            # If we want the text to be the same color as the bar, we can\n",
    "            # get the color like so:\n",
    "            bar_color = bar.get_facecolor()\n",
    "            # If you want a consistent color, you can just set it as a constant, e.g. #222222\n",
    "            ax_vaf.text(text_x, text_y, text, ha='center', va='bottom', color=bar_color,\n",
    "                    size=12)\n",
    "\n",
    "        # turn off the spines\n",
    "        for spine in ['right','top','bottom','left']:\n",
    "            ax_vaf.spines[spine].set_visible(False)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load tensorboard so that we can easily explore\n",
    "# %load_ext tensorboard\n",
    "\n",
    "\n",
    "def LSTM_grid_search(firing, EMG, n_iter = 150, n_fold = 10, n_epochs = 20, unit_range = [100, 400], drop_in_range = [0,.5], drop_rec_range = [0,.5], drop_lay_range = [0,.5], seq_range=[5,20], plot=True):\n",
    "    # Runs a monte-carlo style grid search on hyper parameters\n",
    "    # It will run mfxval, so there is no need for a separate training group\n",
    "    #\n",
    "    #  This will allow me to compare the number of lstm units, drop percentages,\n",
    "    #  batch and sequence sizes, etc.\n",
    "    \n",
    "    EMG_names = EMG.columns\n",
    "    cols = [f\"{name}_train_VAF\" for name in EMG_names]\n",
    "    cols += [f'{name}_test_VAF' for name in EMG_names]\n",
    "    cols += ['n_units','drop_in','drop_rec','drop_lay','seq_len']\n",
    "    log = pd.DataFrame(columns=cols)\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir='./logs/LSTM_exploration', histogram_freq=1)\n",
    "\n",
    "    \n",
    "    n_neurons = firing.shape[1] # number of neurons\n",
    "    n_EMGs = EMG.shape[1]\n",
    "    \n",
    "    # get the indices of the folds\n",
    "    kf = KFold(n_splits=n_fold, random_state=None, shuffle=False) # working in chunks, not random indices\n",
    "#     train_idx,test_idx = kf.split(firing) # get the indices. Won't split until later, since we will need to set up the sequences each round\n",
    "    \n",
    "    # intiialize the random number generator for the monte carlo\n",
    "    rng = np.random.default_rng()\n",
    "    \n",
    "    for iter in np.arange(n_iter):\n",
    "        layer_0_units = rng.integers(unit_range[0],unit_range[1])\n",
    "        drop_in = rng.uniform(drop_in_range[0], drop_in_range[1])\n",
    "        drop_rec = rng.uniform(drop_rec_range[0], drop_rec_range[1])\n",
    "        drop_lay = rng.uniform(drop_lay_range[0], drop_lay_range[1])\n",
    "        seq_len = rng.integers(seq_range[0], seq_range[1])\n",
    "        \n",
    "        rnn_i = np.ndarray((firing.shape[0], seq_len, firing.shape[1]))\n",
    "        for ii in np.arange(seq_len):\n",
    "            rnn_i[:,ii,:] = firing.shift(-ii, fill_value=0).to_numpy()\n",
    "        \n",
    "        \n",
    "        train_VAFs = np.zeros((n_fold, n_EMGs))\n",
    "        test_VAFs = np.zeros((n_fold, n_EMGs))\n",
    "        \n",
    "        log_entry = {'n_units':layer_0_units, 'drop_in':drop_in, 'drop_rec':drop_rec,\\\n",
    "                        'drop_lay':drop_lay, 'seq_len':seq_len}\n",
    "        \n",
    "        fold_idx = 0\n",
    "        for train_idx,test_idx in kf.split(firing):\n",
    "\n",
    "            rnn_train_i = np.zeros((len(train_idx),seq_len, firing.shape[1]))\n",
    "            rnn_test_i = np.zeros((len(test_idx),seq_len, firing.shape[1]))\n",
    "            rnn_train_o = EMG.iloc[train_idx,:].to_numpy()\n",
    "            rnn_test_o = EMG.iloc[test_idx,:].to_numpy()\n",
    "            \n",
    "            # split training and testing inputs\n",
    "            rnn_train_i = rnn_i[train_idx,:,:]\n",
    "            rnn_test_i = rnn_i[test_idx,:,:]\n",
    "\n",
    "\n",
    "            # normalize the EMGs\n",
    "            EMG_std = np.std(rnn_train_o, axis=0)\n",
    "            for ii in np.arange(rnn_train_o.shape[1]):\n",
    "                rnn_train_o[:,ii] = rnn_train_o[:,ii]/EMG_std[ii]\n",
    "                rnn_test_o[:,ii] = rnn_test_o[:,ii]/EMG_std[ii]\n",
    "\n",
    "            # Set up the LSTMs\n",
    "            mdl = tf.keras.models.Sequential()\n",
    "\n",
    "\n",
    "            mdl.add(tf.keras.layers.LSTM(layer_0_units, input_shape = (seq_len,n_neurons), dropout=drop_in, recurrent_dropout=drop_rec))\n",
    "            if drop_lay:\n",
    "                mdl.add(tf.keras.layers.Dropout(drop_lay)) # dropout layer if wanted\n",
    "        #     mdl.add(tf.keras.layers.Dense(n_EMGs, activation='relu')) # dense combination layer\n",
    "            mdl.add(tf.keras.layers.Dense(n_EMGs)) # dense combination layer\n",
    "            mdl.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "            mdl.fit(rnn_train_i, rnn_train_o, epochs=n_epochs, verbose=False, callbacks=[tensorboard_callback])\n",
    "\n",
    "\n",
    "            train_pred = mdl.predict(rnn_train_i, verbose=False)\n",
    "            test_pred = mdl.predict(rnn_test_i, verbose=False)\n",
    "            train_VAFs[fold_idx,:] = metrics.explained_variance_score(rnn_train_o, train_pred, multioutput='raw_values')\n",
    "            test_VAFs[fold_idx,:] = metrics.explained_variance_score(rnn_test_o, test_pred, multioutput='raw_values')\n",
    "            \n",
    "            fold_idx += 1\n",
    "            \n",
    "        # store the VAFs in the log entry\n",
    "        for emg_iter,emg_name in enumerate(EMG_names):\n",
    "            log_entry[f\"{emg_name}_train_VAF\"] = np.mean(train_VAFs[:,emg_iter])\n",
    "            log_entry[f\"{emg_name}_test_VAF\"] = np.mean(test_VAFs[:,emg_iter])\n",
    "        \n",
    "        \n",
    "#         return log_entry\n",
    "#         print(pd.DataFrame.from_records([log_entry]))\n",
    "        log = pd.concat([log,pd.DataFrame.from_records([log_entry])], ignore_index=True)\n",
    "        print(f\"Looped iteration {iter} of {n_iter}\")\n",
    "        \n",
    "    return log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_rex(train_firing, train_EMG, test_firing, test_EMG, test_timestamps, plot=True, weighted=False):\n",
    "    if type(train_firing) is not list:\n",
    "        print(f\"train_firing must be a list of Numpy Arrays, not a {type(train_firing)}\")\n",
    "        return -1\n",
    "    \n",
    "    \n",
    "    # hyper params\n",
    "    layer_0_units = 300\n",
    "    drop_in = .25     # input dropout percentage for LSTM layer\n",
    "    drop_rec = 0    # recurrent dropout for LSTM\n",
    "    drop_lay = .15    # dropout layer?\n",
    "    \n",
    "    # size and name of outputs\n",
    "    n_target = train_EMG[0].shape[1] # dimensionality of target (EMGs usually)\n",
    "    col_names = train_EMG[0].columns\n",
    "    \n",
    "\n",
    "    # tensorboard callback\n",
    "    log_dir = f'C:\\\\Users\\\\17204\\\\Documents\\\\Tensorboard_logs\\\\LSTM_logs\\\\{dt.today().strftime(\"%Y%m%d\")}_{\"weighted\" if weighted else \"unweighted\"}'\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir)\n",
    "    \n",
    "\n",
    "    # start by initializing the input sequence data\n",
    "    n_neurons = train_firing[0].shape[1]\n",
    "    seq_len = 10\n",
    "    rnn_train_i = np.ndarray((0,seq_len, n_neurons))\n",
    "    rnn_test_i = np.ndarray((test_firing.shape[0],seq_len, n_neurons))\n",
    "    \n",
    "    # testing target set -- have to append the neural firing\n",
    "    for train in train_firing:\n",
    "        temp_train_i = np.ndarray((train.shape[0], seq_len, n_neurons))\n",
    "        for ii in np.arange(seq_len):\n",
    "            temp_train_i[:,ii,:] = train.shift(-ii, fill_value=0).to_numpy()\n",
    "        rnn_train_i = np.append(rnn_train_i, temp_train_i, axis=0)\n",
    "            \n",
    "    for ii in np.arange(seq_len):\n",
    "        rnn_test_i[:,ii,:] = test_firing.shift(-ii, fill_value=0).to_numpy()\n",
    "        \n",
    "\n",
    "    rnn_test_o = test_EMG.to_numpy() # don't need the categories for the test set\n",
    "    rnn_train_o = np.ndarray((0,n_target+1)) # initialize the training outputs\n",
    "    for ii_EMG, EMG in enumerate(train_EMG): # iterate through list\n",
    "        temp_train = EMG.to_numpy() # add the numpy stuff\n",
    "        if weighted:\n",
    "            temp_train = np.append(temp_train, 1/np.var(EMG.to_numpy()) * np.ones((EMG.shape[0],1)), axis=-1) # append a category flag to the last column\n",
    "        else:\n",
    "            temp_train = np.append(temp_train, ii_EMG+1 * np.ones((EMG.shape[0],1)), axis=-1) # append a category flag to the last column\n",
    "        rnn_train_o = np.append(rnn_train_o, temp_train, axis=0)\n",
    "\n",
    "    # normalize EMGs\n",
    "    # EMG_std = np.std(rnn_train_o, axis=0)\n",
    "    # for ii in np.arange(rnn_train_o.shape[1] - 1):\n",
    "    #     rnn_train_o[:,ii] = rnn_train_o[:,ii]/EMG_std[ii]\n",
    "    #     rnn_test_o[:,ii] = rnn_test_o[:,ii]/EMG_std[ii]\n",
    "\n",
    "\n",
    "    # create the model\n",
    "    mdl = tf.keras.models.Sequential()\n",
    "\n",
    "    # add the LSTM layer\n",
    "    mdl.add(tf.keras.layers.LSTM(layer_0_units, input_shape = (seq_len,n_neurons), dropout=drop_in, recurrent_dropout=drop_rec))\n",
    "    mdl.add(tf.keras.layers.Dropout(drop_lay))\n",
    "    mdl.add(tf.keras.layers.Dense(rnn_train_o.shape[1]))\n",
    "\n",
    "    if weighted:\n",
    "        mdl.compile(loss=vrex_weighted, optimizer='rmsprop', metrics='mse')\n",
    "    else:\n",
    "        mdl.compile(loss=vrex_loss, optimizer='rmsprop', metrics='mse')\n",
    "                \n",
    "    mdl.fit(rnn_train_i, rnn_train_o, epochs=30, batch_size=128, verbose=False, callbacks=tensorboard_callback)\n",
    "    \n",
    "    \n",
    "    train_pred = mdl.predict(rnn_train_i)\n",
    "    test_pred = mdl.predict(rnn_test_i)\n",
    "    \n",
    "    train_VAFs = metrics.r2_score(rnn_train_o[:,:-1], train_pred[:,:-1], multioutput='raw_values')\n",
    "    test_VAFs = metrics.r2_score(rnn_test_o, test_pred[:,:-1], multioutput='raw_values')\n",
    "    \n",
    "    \n",
    "    print('----------------------------------------')\n",
    "    for ii in np.arange(n_target):\n",
    "        print(col_names[ii])\n",
    "        print(f\"\\tTrain VAF: {train_VAFs[ii]}\")\n",
    "        print(f\"\\tTest VAF: {test_VAFs[ii]}\")\n",
    "\n",
    "    print(f\"\\nMean Testing VAF: {np.mean(test_VAFs)}\")\n",
    "    \n",
    "    \n",
    "    # plottin\n",
    "    n_rows = int(np.ceil(np.sqrt(n_target)))\n",
    "    fig_lstm, ax_lstm = plt.subplots(nrows=n_rows, ncols=n_rows, sharex=True, constrained_layout=True)\n",
    "\n",
    "    for muscle_ii in np.arange(n_target):\n",
    "        row_i = int(muscle_ii//n_rows)\n",
    "        col_i = int(muscle_ii%n_rows)\n",
    "        ax_lstm[row_i,col_i].plot(test_timestamps, rnn_test_o[:,muscle_ii], label='Recorded')\n",
    "        ax_lstm[row_i,col_i].plot(test_timestamps,test_pred[:,muscle_ii], label=f'LSTM VAF: {test_VAFs[muscle_ii]:.03f}')\n",
    "        ax_lstm[row_i,col_i].set_title(f\"{col_names[muscle_ii]}\")\n",
    "        _ = ax_lstm[row_i,col_i].legend()\n",
    "\n",
    "        # turn off the spines\n",
    "        for spine in ['right','top','bottom','left']:\n",
    "            ax_lstm[row_i,col_i].spines[spine].set_visible(False)\n",
    "    \n",
    "    \n",
    "    # let's also plot the VAFs in a clean manner so that it's easy to compare\n",
    "    fig_vaf, ax_vaf = plt.subplots()\n",
    "    i_muscles = np.arange(n_target) # indexing on the x axis\n",
    "    bar_width = .3\n",
    "\n",
    "    ax_vaf.bar(i_muscles, train_VAFs, width = bar_width, label='Train')\n",
    "    ax_vaf.bar(i_muscles + bar_width, test_VAFs, width = bar_width, label='Test')\n",
    "\n",
    "    ax_vaf.set_xticks(i_muscles + bar_width/2)\n",
    "    ax_vaf.set_xticklabels(col_names)\n",
    "\n",
    "    ax_vaf.set_ylim([-.05, 1.05])\n",
    "    ax_vaf.set_xlabel('Muscle')\n",
    "    ax_vaf.set_ylabel('VAF')\n",
    "\n",
    "    ax_vaf.legend()\n",
    "\n",
    "    # For each bar in the chart, add a text label.\n",
    "    for bar in ax_vaf.patches:\n",
    "        # The text annotation for each bar should be its height.\n",
    "        bar_value = bar.get_height()\n",
    "        # Format the text with commas to separate thousands. You can do\n",
    "        # any type of formatting here though.\n",
    "        text = f'{bar_value:.02f}'\n",
    "        # This will give the middle of each bar on the x-axis.\n",
    "        text_x = bar.get_x() + bar.get_width() / 2\n",
    "        # get_y() is where the bar starts so we add the height to it.\n",
    "        text_y = np.max([bar.get_y() + bar_value, 0.01]) # keep it from going too far below zero, and disappearing\n",
    "        # If we want the text to be the same color as the bar, we can\n",
    "        # get the color like so:\n",
    "        bar_color = bar.get_facecolor()\n",
    "        # If you want a consistent color, you can just set it as a constant, e.g. #222222\n",
    "        ax_vaf.text(text_x, text_y, text, ha='center', va='bottom', color=bar_color,\n",
    "                size=12)\n",
    "\n",
    "    # turn off the spines\n",
    "    for spine in ['right','top','bottom','left']:\n",
    "        ax_vaf.spines[spine].set_visible(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare different combinations of train/test sets\n",
    "\n",
    "So that we can quickly run through all of the iterations\n",
    "\n",
    "Set the nonlinearity type, to compare across iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonlinear_type = 'poly'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "First train wrist movement, test wrist movement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_timestamps, train_firing, train_EMG, train_force, train_kin = load_josh_mat(data['WmTrain'])\n",
    "test_timestamps, test_firing, test_EMG, test_force, test_kin = load_josh_mat(data['WmTest'])\n",
    "# using the training set twice as the \"refit\" gain -- for sanity's sake\n",
    "mov_mov_linVAF = basic_decoder_comparison(train_firing, train_EMG, train_firing, train_EMG, test_firing, test_EMG, test_timestamps, nonlinear_type)\n",
    "mov_mov_LSTMVAF = LSTM_comparisons(train_firing, train_EMG, test_firing, test_EMG, test_timestamps)\n",
    "\n",
    "print(f\"Mean Linear {np.mean(mov_mov_linVAF)}\")\n",
    "print(f\"Mean LSTM {np.mean(mov_mov_LSTMVAF)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train wrist movement, test iso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_timestamps, train_firing, train_EMG, train_force, train_kin = load_josh_mat(data['WmTrain'])\n",
    "_, retrain_firing, retrain_EMG, _, _, = load_josh_mat(data['IsoTrain'])\n",
    "test_timestamps, test_firing, test_EMG, test_force, test_kin = load_josh_mat(data['IsoTest'])\n",
    "mov_iso_linVAF = basic_decoder_comparison(train_firing, train_EMG, retrain_firing, retrain_EMG, test_firing, test_EMG, test_timestamps, nonlinear_type)\n",
    "mov_iso_LSTMVAF = LSTM_comparisons(train_firing, train_EMG, test_firing, test_EMG, test_timestamps)\n",
    "\n",
    "print(f\"Mean Linear {np.mean(mov_iso_linVAF)}\")\n",
    "print(f\"Mean LSTM {np.mean(mov_iso_LSTMVAF)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train WM, test spring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_timestamps, train_firing, train_EMG, train_force, train_kin = load_josh_mat(data['WmTrain'])\n",
    "_, retrain_firing, retrain_EMG, _, _, = load_josh_mat(data['SprTrain'])\n",
    "test_timestamps, test_firing, test_EMG, test_force, test_kin = load_josh_mat(data['SprTest'])\n",
    "mov_spr_linVAF = basic_decoder_comparison(train_firing, train_EMG, retrain_firing, retrain_EMG, test_firing, test_EMG, test_timestamps, nonlinear_type)\n",
    "mov_spr_LSTMVAF = LSTM_comparisons(train_firing, train_EMG, test_firing, test_EMG, test_timestamps)\n",
    "\n",
    "print(f\"Mean Linear {np.mean(mov_spr_linVAF)}\")\n",
    "print(f\"Mean LSTM {np.mean(mov_spr_LSTMVAF)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Iso, test Iso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_timestamps, train_firing, train_EMG, train_force, train_kin = load_josh_mat(data['IsoTrain'])\n",
    "test_timestamps, test_firing, test_EMG, test_force, test_kin = load_josh_mat(data['IsoTest'])\n",
    "iso_iso_linVAF = basic_decoder_comparison(train_firing, train_EMG, train_firing, train_EMG, test_firing, test_EMG, test_timestamps, nonlinear_type)\n",
    "iso_iso_LSTMVAF = LSTM_comparisons(train_firing, train_EMG, test_firing, test_EMG, test_timestamps)\n",
    "\n",
    "print(f\"Mean Linear {np.mean(iso_iso_linVAF)}\")\n",
    "print(f\"Mean LSTM {np.mean(iso_iso_LSTMVAF)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Iso, test WM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_timestamps, train_firing, train_EMG, train_force, train_kin = load_josh_mat(data['IsoTrain'])\n",
    "_, retrain_firing, retrain_EMG, _, _, = load_josh_mat(data['WmTrain'])\n",
    "test_timestamps, test_firing, test_EMG, test_force, test_kin = load_josh_mat(data['WmTest'])\n",
    "iso_mov_linVAF = basic_decoder_comparison(train_firing, train_EMG, retrain_firing, retrain_EMG, test_firing, test_EMG, test_timestamps, nonlinear_type)\n",
    "iso_mov_LSTMVAF = LSTM_comparisons(train_firing, train_EMG, test_firing, test_EMG, test_timestamps)\n",
    "\n",
    "print(f\"Mean Linear {np.mean(iso_mov_linVAF)}\")\n",
    "print(f\"Mean LSTM {np.mean(iso_mov_linVAF)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Iso, Test Spring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_timestamps, train_firing, train_EMG, train_force, train_kin = load_josh_mat(data['IsoTrain'])\n",
    "_, retrain_firing, retrain_EMG, _, _, = load_josh_mat(data['SprTrain'])\n",
    "test_timestamps, test_firing, test_EMG, test_force, test_kin = load_josh_mat(data['SprTest'])\n",
    "iso_spr_linVAF = basic_decoder_comparison(train_firing, train_EMG, retrain_firing, retrain_EMG, test_firing, test_EMG, test_timestamps, nonlinear_type)\n",
    "iso_spr_LSTMVAF = LSTM_comparisons(train_firing, train_EMG, test_firing, test_EMG, test_timestamps)\n",
    "\n",
    "print(f\"Mean Linear {np.mean(iso_spr_linVAF)}\")\n",
    "print(f\"Mean LSTM {np.mean(iso_spr_linVAF)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Spring, test each of the three"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_timestamps, train_firing, train_EMG, train_force, train_kin = load_josh_mat(data['SprTrain'])\n",
    "\n",
    "print('Test Spring')\n",
    "_, retrain_firing, retrain_EMG, _, _, = load_josh_mat(data['SprTrain'])\n",
    "test_timestamps, test_firing, test_EMG, test_force, test_kin = load_josh_mat(data['SprTest'])\n",
    "spr_spr_linVAF = basic_decoder_comparison(train_firing, train_EMG, retrain_firing, retrain_EMG, test_firing, test_EMG, test_timestamps, nonlinear_type)\n",
    "spr_spr_LSTMVAF = LSTM_comparisons(train_firing, train_EMG, test_firing, test_EMG, test_timestamps)\n",
    "\n",
    "print('Test Iso')\n",
    "_, retrain_firing, retrain_EMG, _, _, = load_josh_mat(data['IsoTrain'])\n",
    "test_timestamps, test_firing, test_EMG, test_force, test_kin = load_josh_mat(data['IsoTest'])\n",
    "spr_iso_linVAF = basic_decoder_comparison(train_firing, train_EMG, retrain_firing, retrain_EMG, test_firing, test_EMG, test_timestamps, nonlinear_type)\n",
    "spr_iso_LSTMVAF = LSTM_comparisons(train_firing, train_EMG, test_firing, test_EMG, test_timestamps)\n",
    "\n",
    "print('Test Movement')\n",
    "_, retrain_firing, retrain_EMG, _, _, = load_josh_mat(data['WmTrain'])\n",
    "test_timestamps, test_firing, test_EMG, test_force, test_kin = load_josh_mat(data['WmTest'])\n",
    "spr_mov_linVAF = basic_decoder_comparison(train_firing, train_EMG, retrain_firing, retrain_EMG, test_firing, test_EMG, test_timestamps, nonlinear_type)\n",
    "spr_mov_LSTMVAF = LSTM_comparisons(train_firing, train_EMG, test_firing, test_EMG, test_timestamps)\n",
    "\n",
    "dntxt.send('Spring Linear and non weighted done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train on hybrid, test on each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Hybrid 3 -- this should be a blend of all three, I think for training\n",
    "train_timestamps, train_firing, train_EMG, train_force, train_kin = load_josh_mat(data['Hybrid3'])\n",
    "\n",
    "print(\"test on movement\")\n",
    "_, retrain_firing, retrain_EMG, _, _, = load_josh_mat(data['WmTrain'])\n",
    "test_timestamps, test_firing, test_EMG, test_force, test_kin = load_josh_mat(data['WmTest'])\n",
    "basic_decoder_comparison(train_firing, train_EMG, retrain_firing, retrain_EMG, test_firing, test_EMG, test_timestamps, nonlinear_type)\n",
    "LSTM_comparisons(train_firing, train_EMG, test_firing, test_EMG, test_timestamps)\n",
    "\n",
    "print(\"\\n\\ntest on Iso\")\n",
    "_, retrain_firing, retrain_EMG, _, _, = load_josh_mat(data['IsoTrain'])\n",
    "test_timestamps, test_firing, test_EMG, test_force, test_kin = load_josh_mat(data['IsoTest'])\n",
    "basic_decoder_comparison(train_firing, train_EMG, retrain_firing, retrain_EMG, test_firing, test_EMG, test_timestamps, nonlinear_type)\n",
    "LSTM_comparisons(train_firing, train_EMG, test_firing, test_EMG, test_timestamps)\n",
    "\n",
    "\n",
    "print(\"\\n\\ntest on Spring\")\n",
    "_, retrain_firing, retrain_EMG, _, _, = load_josh_mat(data['SprTrain'])\n",
    "test_timestamps, test_firing, test_EMG, test_force, test_kin = load_josh_mat(data['SprTest'])\n",
    "basic_decoder_comparison(train_firing, train_EMG, retrain_firing, retrain_EMG, test_firing, test_EMG, test_timestamps, nonlinear_type)\n",
    "LSTM_comparisons(train_firing, train_EMG, test_firing, test_EMG, test_timestamps)\n",
    "\n",
    "dntxt.send('Hybrid basic testing complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Hybrid 3 -- this should be a blend of all three, I think for training\n",
    "train_timestamps, train_firing, train_EMG, train_force, train_kin = load_josh_mat(data['Hybrid3'])\n",
    "_, retrain_firing, retrain_EMG, _, _, = load_josh_mat(data['IsoTrain'])\n",
    "test_timestamps, test_firing, test_EMG, test_force, test_kin = load_josh_mat(data['IsoTest'])\n",
    "basic_decoder_comparison(train_firing, train_EMG, retrain_firing, retrain_EMG, test_firing, test_EMG, test_timestamps, nonlinear_type)\n",
    "LSTM_comparisons(train_firing, train_EMG, test_firing, test_EMG, test_timestamps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hybrid LSTMs with weighted loss functions\n",
    "\n",
    "This works a little different from Josh's -- I'm not basing it off of times; instead, I'm manually compiling the train sets I want to use\n",
    "\n",
    "\n",
    "Train on Iso and Movement, test on each of the three"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test on movement\n",
      "750/750 [==============================] - 1s 1ms/step\n",
      "188/188 [==============================] - 0s 1ms/step\n",
      "----------------------------------------\n",
      "FCU\n",
      "\tTrain VAF: 0.34739188492595563\n",
      "\tTest VAF: 0.12597952312288574\n",
      "FCR\n",
      "\tTrain VAF: 0.46741218646725335\n",
      "\tTest VAF: 0.24302609664027508\n",
      "ECU\n",
      "\tTrain VAF: 0.6899357994004709\n",
      "\tTest VAF: 0.4090998655342589\n",
      "ECR\n",
      "\tTrain VAF: 0.8767111764366623\n",
      "\tTest VAF: 0.5812105978308544\n",
      "test on iso\n",
      "750/750 [==============================] - 1s 2ms/step\n",
      "188/188 [==============================] - 1s 2ms/step\n",
      "----------------------------------------\n",
      "FCU\n",
      "\tTrain VAF: 0.3399285979677512\n",
      "\tTest VAF: 0.5510943695499535\n",
      "FCR\n",
      "\tTrain VAF: 0.4704707542821218\n",
      "\tTest VAF: 0.4561530393240244\n",
      "ECU\n",
      "\tTrain VAF: 0.6902085768392228\n",
      "\tTest VAF: 0.5554666732248317\n",
      "ECR\n",
      "\tTrain VAF: 0.8752305010951418\n",
      "\tTest VAF: 0.808967047918364\n",
      "test on Spring\n",
      "750/750 [==============================] - 1s 2ms/step\n",
      "188/188 [==============================] - 0s 1ms/step\n",
      "----------------------------------------\n",
      "FCU\n",
      "\tTrain VAF: 0.3283513752814945\n",
      "\tTest VAF: 0.19046536174297735\n",
      "FCR\n",
      "\tTrain VAF: 0.47748382019116586\n",
      "\tTest VAF: 0.24202933862502485\n",
      "ECU\n",
      "\tTrain VAF: 0.6673450159815746\n",
      "\tTest VAF: 0.25690831917820467\n",
      "ECR\n",
      "\tTrain VAF: 0.8707382234806184\n",
      "\tTest VAF: 0.4158170346751283\n"
     ]
    }
   ],
   "source": [
    "_, train_firing_0, train_EMG_0, _, _ = load_josh_mat(data['IsoTrain'])\n",
    "_, train_firing_1, train_EMG_1, _, _ = load_josh_mat(data['WmTrain'])\n",
    "\n",
    "print(\"test on movement\")\n",
    "test_timestamps, test_firing, test_EMG, test_force, test_kin = load_josh_mat(data['WmTest'])\n",
    "LSTM_across_weighted([train_firing_0, train_firing_1], [train_EMG_0, train_EMG_1], test_firing, test_EMG, test_timestamps)\n",
    "\n",
    "print('test on iso')\n",
    "test_timestamps, test_firing, test_EMG, test_force, test_kin = load_josh_mat(data['IsoTest'])\n",
    "LSTM_across_weighted([train_firing_0, train_firing_1], [train_EMG_0, train_EMG_1], test_firing, test_EMG, test_timestamps)\n",
    "\n",
    "print('test on Spring')\n",
    "test_timestamps, test_firing, test_EMG, test_force, test_kin = load_josh_mat(data['SprTest'])\n",
    "LSTM_across_weighted([train_firing_0, train_firing_1], [train_EMG_0, train_EMG_1], test_firing, test_EMG, test_timestamps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train on Movement and Spring, test on everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, train_firing_0, train_EMG_0, _, _ = load_josh_mat(data['SprTrain'])\n",
    "_, train_firing_1, train_EMG_1, _, _ = load_josh_mat(data['WmTrain'])\n",
    "\n",
    "print(f\"Test on Spring\")\n",
    "test_timestamps, test_firing, test_EMG, _, _ = load_josh_mat(data['SprTest'])\n",
    "LSTM_across_weighted([train_firing_0, train_firing_1], [train_EMG_0, train_EMG_1], test_firing, test_EMG, test_timestamps, plot=False)\n",
    "\n",
    "print(f\"Test on Movement\")\n",
    "test_timestamps, test_firing, test_EMG, _, _ = load_josh_mat(data['WmTest'])\n",
    "LSTM_across_weighted([train_firing_0, train_firing_1], [train_EMG_0, train_EMG_1], test_firing, test_EMG, test_timestamps, plot=False)\n",
    "\n",
    "print(f\"Test on Iso\")\n",
    "test_timestamps, test_firing, test_EMG, _, _ = load_josh_mat(data['IsoTest'])\n",
    "LSTM_across_weighted([train_firing_0, train_firing_1], [train_EMG_0, train_EMG_1], test_firing, test_EMG, test_timestamps, plot=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train on Spring and Iso, test on everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_, train_firing_0, train_EMG_0, _, _ = load_josh_mat(data['SprTrain'])\n",
    "_, train_firing_1, train_EMG_1, _, _ = load_josh_mat(data['IsoTrain'])\n",
    "\n",
    "print(f\"Test on Spring\")\n",
    "test_timestamps, test_firing, test_EMG, _, _ = load_josh_mat(data['SprTest'])\n",
    "LSTM_across_weighted([train_firing_0, train_firing_1], [train_EMG_0, train_EMG_1], test_firing, test_EMG, test_timestamps)\n",
    "\n",
    "print(f\"Test on Movement\")\n",
    "test_timestamps, test_firing, test_EMG, _, _ = load_josh_mat(data['WmTest'])\n",
    "LSTM_across_weighted([train_firing_0, train_firing_1], [train_EMG_0, train_EMG_1], test_firing, test_EMG, test_timestamps)\n",
    "\n",
    "print(f\"Test on Iso\")\n",
    "test_timestamps, test_firing, test_EMG, _, _ = load_josh_mat(data['IsoTest'])\n",
    "LSTM_across_weighted([train_firing_0, train_firing_1], [train_EMG_0, train_EMG_1], test_firing, test_EMG, test_timestamps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train on everything, test on each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, train_firing_0, train_EMG_0, _, _ = load_josh_mat(data['SprTrain'])\n",
    "_, train_firing_1, train_EMG_1, _, _ = load_josh_mat(data['IsoTrain'])\n",
    "_, train_firing_2, train_EMG_2, _, _ = load_josh_mat(data['IsoTrain'])\n",
    "\n",
    "print(f\"Test on Spring\")\n",
    "test_timestamps, test_firing, test_EMG, _, _ = load_josh_mat(data['SprTest'])\n",
    "LSTM_across_weighted([train_firing_0, train_firing_1, train_firing_2], [train_EMG_0, train_EMG_1, train_EMG_2], test_firing, test_EMG, test_timestamps, plot=False)\n",
    "\n",
    "print(f\"Test on Movement\")\n",
    "test_timestamps, test_firing, test_EMG, _, _ = load_josh_mat(data['WmTest'])\n",
    "LSTM_across_weighted([train_firing_0, train_firing_1, train_firing_2], [train_EMG_0, train_EMG_1, train_EMG_2], test_firing, test_EMG, test_timestamps, plot=False)\n",
    "\n",
    "print(f\"Test on Iso\")\n",
    "test_timestamps, test_firing, test_EMG, _, _ = load_josh_mat(data['IsoTest'])\n",
    "LSTM_across_weighted([train_firing_0, train_firing_1, train_firing_2], [train_EMG_0, train_EMG_1, train_EMG_2], test_firing, test_EMG, test_timestamps, plot=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM grid search\n",
    "\n",
    "Time to look at some non-linearities!\n",
    "\n",
    "Let's run through the grid search on hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, firing, EMG, _, _ = load_josh_mat(data['WmTrain'])\n",
    "\n",
    "log = LSTM_grid_search(firing, EMG, n_iter = 30, n_fold = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM with REx\n",
    "\n",
    "Run through the options, see what comes out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iso and movement\n",
      "\n",
      "movement test\n",
      "750/750 [==============================] - 1s 1ms/step\n",
      "188/188 [==============================] - 1s 1ms/step\n",
      "----------------------------------------\n",
      "FCU\n",
      "\tTrain VAF: 0.12627952979413648\n",
      "\tTest VAF: -0.41558191447096915\n",
      "FCR\n",
      "\tTrain VAF: 0.5214910500787987\n",
      "\tTest VAF: 0.22364571311703407\n",
      "ECU\n",
      "\tTrain VAF: 0.6669101874327397\n",
      "\tTest VAF: 0.3074203499401854\n",
      "ECR\n",
      "\tTrain VAF: 0.9106318329675519\n",
      "\tTest VAF: 0.5452099151856018\n",
      "\n",
      "Mean Testing VAF: 0.16517351594296303\n",
      "\n",
      "iso test\n",
      "750/750 [==============================] - 1s 2ms/step\n",
      "188/188 [==============================] - 1s 1ms/step\n",
      "----------------------------------------\n",
      "FCU\n",
      "\tTrain VAF: 0.15414708695919455\n",
      "\tTest VAF: 0.23583593961861438\n",
      "FCR\n",
      "\tTrain VAF: 0.5377173250654625\n",
      "\tTest VAF: 0.4156426355799909\n",
      "ECU\n",
      "\tTrain VAF: 0.6981920518967212\n",
      "\tTest VAF: 0.5848294917416827\n",
      "ECR\n",
      "\tTrain VAF: 0.9159520824162217\n",
      "\tTest VAF: 0.8473227296184451\n",
      "\n",
      "Mean Testing VAF: 0.5209076991396833\n",
      "\n",
      "spring test\n",
      "750/750 [==============================] - 1s 1ms/step\n",
      "188/188 [==============================] - 1s 1ms/step\n",
      "----------------------------------------\n",
      "FCU\n",
      "\tTrain VAF: 0.29881338931768264\n",
      "\tTest VAF: 0.05936171721440553\n",
      "FCR\n",
      "\tTrain VAF: 0.4968469382996571\n",
      "\tTest VAF: 0.005996671933352737\n",
      "ECU\n",
      "\tTrain VAF: 0.6460196445800385\n",
      "\tTest VAF: 0.25951779121295704\n",
      "ECR\n",
      "\tTrain VAF: 0.8861961036754881\n",
      "\tTest VAF: 0.3690299849358295\n",
      "\n",
      "Mean Testing VAF: 0.1734765413241362\n"
     ]
    }
   ],
   "source": [
    "print('iso and movement')\n",
    "\n",
    "_, train_firing_0, train_EMG_0, _, _ = load_josh_mat(data['IsoTrain'])\n",
    "_, train_firing_1, train_EMG_1, _, _ = load_josh_mat(data['WmTrain'])\n",
    "\n",
    "print('\\nmovement test')\n",
    "test_timestamps, test_firing, test_EMG, test_force, test_kin = load_josh_mat(data['WmTest'])\n",
    "LSTM_rex([train_firing_0, train_firing_1], [train_EMG_0, train_EMG_1], test_firing, test_EMG, test_timestamps)\n",
    "print('\\niso test')\n",
    "test_timestamps, test_firing, test_EMG, test_force, test_kin = load_josh_mat(data['IsoTest'])\n",
    "LSTM_rex([train_firing_0, train_firing_1], [train_EMG_0, train_EMG_1], test_firing, test_EMG, test_timestamps)\n",
    "print('\\nspring test')\n",
    "test_timestamps, test_firing, test_EMG, test_force, test_kin = load_josh_mat(data['SprTest'])\n",
    "LSTM_rex([train_firing_0, train_firing_1], [train_EMG_0, train_EMG_1], test_firing, test_EMG, test_timestamps)\n",
    "\n",
    "# doneTone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('movement and spring')\n",
    "\n",
    "\n",
    "_, train_firing_0, train_EMG_0, _, _ = load_josh_mat(data['SprTrain'])\n",
    "_, train_firing_1, train_EMG_1, _, _ = load_josh_mat(data['WmTrain'])\n",
    "\n",
    "print('\\nmovement test')\n",
    "test_timestamps, test_firing, test_EMG, test_force, test_kin = load_josh_mat(data['WmTest'])\n",
    "LSTM_rex([train_firing_0, train_firing_1], [train_EMG_0, train_EMG_1], test_firing, test_EMG, test_timestamps)\n",
    "print('\\niso test')\n",
    "test_timestamps, test_firing, test_EMG, test_force, test_kin = load_josh_mat(data['IsoTest'])\n",
    "LSTM_rex([train_firing_0, train_firing_1], [train_EMG_0, train_EMG_1], test_firing, test_EMG, test_timestamps)\n",
    "print('\\nspring test')\n",
    "test_timestamps, test_firing, test_EMG, test_force, test_kin = load_josh_mat(data['SprTest'])\n",
    "LSTM_rex([train_firing_0, train_firing_1], [train_EMG_0, train_EMG_1], test_firing, test_EMG, test_timestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('iso and spring')\n",
    "\n",
    "\n",
    "_, train_firing_0, train_EMG_0, _, _ = load_josh_mat(data['IsoTrain'])\n",
    "_, train_firing_1, train_EMG_1, _, _ = load_josh_mat(data['SprTrain'])\n",
    "\n",
    "print('\\nmovement test')\n",
    "test_timestamps, test_firing, test_EMG, test_force, test_kin = load_josh_mat(data['WmTest'])\n",
    "LSTM_rex([train_firing_0, train_firing_1], [train_EMG_0, train_EMG_1], test_firing, test_EMG, test_timestamps)\n",
    "print('\\niso test')\n",
    "test_timestamps, test_firing, test_EMG, test_force, test_kin = load_josh_mat(data['IsoTest'])\n",
    "LSTM_rex([train_firing_0, train_firing_1], [train_EMG_0, train_EMG_1], test_firing, test_EMG, test_timestamps)\n",
    "print('\\nspring test')\n",
    "test_timestamps, test_firing, test_EMG, test_force, test_kin = load_josh_mat(data['SprTest'])\n",
    "LSTM_rex([train_firing_0, train_firing_1], [train_EMG_0, train_EMG_1], test_firing, test_EMG, test_timestamps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, train_firing_0, train_EMG_0, _, _ = load_josh_mat(data['IsoTrain'])\n",
    "_, train_firing_1, train_EMG_1, _, _ = load_josh_mat(data['WmTrain'])\n",
    "_, train_firing_2, train_EMG_2, _, _ = load_josh_mat(data['SprTrain'])\n",
    "test_timestamps, test_firing, test_EMG, test_force, test_kin = load_josh_mat(data['SprTest'])\n",
    "\n",
    "\n",
    "print('\\nmovement test')\n",
    "test_timestamps, test_firing, test_EMG, test_force, test_kin = load_josh_mat(data['WmTest'])\n",
    "LSTM_rex([train_firing_0, train_firing_1, train_firing_2], [train_EMG_0, train_EMG_1, train_EMG_2], test_firing, test_EMG, test_timestamps)\n",
    "print('\\niso test')\n",
    "test_timestamps, test_firing, test_EMG, test_force, test_kin = load_josh_mat(data['IsoTest'])\n",
    "LSTM_rex([train_firing_0, train_firing_1, train_firing_2], [train_EMG_0, train_EMG_1, train_EMG_2], test_firing, test_EMG, test_timestamps)\n",
    "print('\\nspring test')\n",
    "test_timestamps, test_firing, test_EMG, test_force, test_kin = load_josh_mat(data['SprTest'])\n",
    "LSTM_rex([train_firing_0, train_firing_1, train_firing_2], [train_EMG_0, train_EMG_1, train_EMG_2], test_firing, test_EMG, test_timestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, train_firing_0, train_EMG_0, _, _ = load_josh_mat(data['IsoTrain'])\n",
    "_, train_firing_1, train_EMG_1, _, _ = load_josh_mat(data['WmTrain'])\n",
    "test_timestamps, test_firing, test_EMG, test_force, test_kin = load_josh_mat(data['IsoTest'])\n",
    "\n",
    "\n",
    "LSTM_rex([train_firing_0, train_firing_1], [train_EMG_0, train_EMG_1], test_firing, test_EMG, test_timestamps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the weighted version of the REx (doesn't change the function, just what's fed into the One Hot matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('iso and spring')\n",
    "\n",
    "\n",
    "_, train_firing_0, train_EMG_0, _, _ = load_josh_mat(data['IsoTrain'])\n",
    "_, train_firing_1, train_EMG_1, _, _ = load_josh_mat(data['SprTrain'])\n",
    "\n",
    "print('\\nmovement test')\n",
    "test_timestamps, test_firing, test_EMG, test_force, test_kin = load_josh_mat(data['WmTest'])\n",
    "LSTM_rex([train_firing_0, train_firing_1], [train_EMG_0, train_EMG_1], test_firing, test_EMG, test_timestamps, weighted=True)\n",
    "print('\\niso test')\n",
    "test_timestamps, test_firing, test_EMG, test_force, test_kin = load_josh_mat(data['IsoTest'])\n",
    "LSTM_rex([train_firing_0, train_firing_1], [train_EMG_0, train_EMG_1], test_firing, test_EMG, test_timestamps, weighted=True)\n",
    "print('\\nspring test')\n",
    "test_timestamps, test_firing, test_EMG, test_force, test_kin = load_josh_mat(data['SprTest'])\n",
    "LSTM_rex([train_firing_0, train_firing_1], [train_EMG_0, train_EMG_1], test_firing, test_EMG, test_timestamps, weighted=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('iso and movement')\n",
    "\n",
    "_, train_firing_0, train_EMG_0, _, _ = load_josh_mat(data['IsoTrain'])\n",
    "_, train_firing_1, train_EMG_1, _, _ = load_josh_mat(data['WmTrain'])\n",
    "\n",
    "print('\\nmovement test')\n",
    "test_timestamps, test_firing, test_EMG, test_force, test_kin = load_josh_mat(data['WmTest'])\n",
    "LSTM_rex([train_firing_0, train_firing_1], [train_EMG_0, train_EMG_1], test_firing, test_EMG, test_timestamps, weighted=True)\n",
    "print('\\niso test')\n",
    "test_timestamps, test_firing, test_EMG, test_force, test_kin = load_josh_mat(data['IsoTest'])\n",
    "LSTM_rex([train_firing_0, train_firing_1], [train_EMG_0, train_EMG_1], test_firing, test_EMG, test_timestamps, weighted=True)\n",
    "print('\\nspring test')\n",
    "test_timestamps, test_firing, test_EMG, test_force, test_kin = load_josh_mat(data['SprTest'])\n",
    "LSTM_rex([train_firing_0, train_firing_1], [train_EMG_0, train_EMG_1], test_firing, test_EMG, test_timestamps, weighted=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VRex with weightings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iso and movement\n",
      "\n",
      "movement test\n",
      "750/750 [==============================] - 2s 1ms/step\n",
      "188/188 [==============================] - 1s 1ms/step\n",
      "----------------------------------------\n",
      "FCU\n",
      "\tTrain VAF: 0.26726936650643374\n",
      "\tTest VAF: 0.044034460380692475\n",
      "FCR\n",
      "\tTrain VAF: 0.4727515591760293\n",
      "\tTest VAF: 0.22247074945514378\n",
      "ECU\n",
      "\tTrain VAF: 0.6957691536407435\n",
      "\tTest VAF: 0.4159505565223467\n",
      "ECR\n",
      "\tTrain VAF: 0.9093864991014596\n",
      "\tTest VAF: 0.5857296480129432\n",
      "\n",
      "Mean Testing VAF: 0.31704635359278155\n",
      "\n",
      "iso test\n",
      "750/750 [==============================] - 1s 1ms/step\n",
      "188/188 [==============================] - 1s 1ms/step\n",
      "----------------------------------------\n",
      "FCU\n",
      "\tTrain VAF: 0.1771525487448039\n",
      "\tTest VAF: 0.3284835527776939\n",
      "FCR\n",
      "\tTrain VAF: 0.5320681007664904\n",
      "\tTest VAF: 0.42103549236523563\n",
      "ECU\n",
      "\tTrain VAF: 0.6886921661521337\n",
      "\tTest VAF: 0.395799535657432\n",
      "ECR\n",
      "\tTrain VAF: 0.8871423621278122\n",
      "\tTest VAF: 0.8104421281579576\n",
      "\n",
      "Mean Testing VAF: 0.48894017723957983\n",
      "\n",
      "spring test\n",
      "750/750 [==============================] - 1s 1ms/step\n",
      "188/188 [==============================] - 1s 1ms/step\n",
      "----------------------------------------\n",
      "FCU\n",
      "\tTrain VAF: 0.25179354445223334\n",
      "\tTest VAF: -0.00442278259595108\n",
      "FCR\n",
      "\tTrain VAF: 0.517302355527247\n",
      "\tTest VAF: 0.020561858005251232\n",
      "ECU\n",
      "\tTrain VAF: 0.6906614241085645\n",
      "\tTest VAF: 0.249715797771493\n",
      "ECR\n",
      "\tTrain VAF: 0.9031746268748726\n",
      "\tTest VAF: 0.31605656439459306\n",
      "\n",
      "Mean Testing VAF: 0.14547785939384655\n"
     ]
    }
   ],
   "source": [
    "print('iso and movement')\n",
    "\n",
    "_, train_firing_0, train_EMG_0, _, _ = load_josh_mat(data['IsoTrain'])\n",
    "_, train_firing_1, train_EMG_1, _, _ = load_josh_mat(data['WmTrain'])\n",
    "\n",
    "print('\\nmovement test')\n",
    "test_timestamps, test_firing, test_EMG, test_force, test_kin = load_josh_mat(data['WmTest'])\n",
    "LSTM_rex([train_firing_0, train_firing_1], [train_EMG_0, train_EMG_1], test_firing, test_EMG, test_timestamps, weighted=True)\n",
    "print('\\niso test')\n",
    "test_timestamps, test_firing, test_EMG, test_force, test_kin = load_josh_mat(data['IsoTest'])\n",
    "LSTM_rex([train_firing_0, train_firing_1], [train_EMG_0, train_EMG_1], test_firing, test_EMG, test_timestamps, weighted=True)\n",
    "print('\\nspring test')\n",
    "test_timestamps, test_firing, test_EMG, test_force, test_kin = load_josh_mat(data['SprTest'])\n",
    "LSTM_rex([train_firing_0, train_firing_1], [train_EMG_0, train_EMG_1], test_firing, test_EMG, test_timestamps, weighted=True)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scratch Space\n",
    "Sometimes the variable viewer isn't very goood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting bits of code to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs/LSTM_exploration --port 6661"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_records([log])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([pd.DataFrame.from_records([log]),pd.DataFrame.from_records([log])], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl_MC = linear_model.LinearRegression()\n",
    "\n",
    "VAF_cols = [cols for cols in log.columns if \"VAF\" in cols]\n",
    "reg_cols = [cols for cols in log.columns if \"VAF\" not in cols]\n",
    "\n",
    "mdl_MC.fit(log[reg_cols],log[VAF_cols])\n",
    "\n",
    "# for iter,col in enumerate(reg_cols):\n",
    "#     print(col)\n",
    "#     print(f\"\\t{mdl_MC.coef_[:,iter]/np.mean(log[col])}\\n\")\n",
    "\n",
    "pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "range = np.linspace(np.min(log['drop_in']), np.max(log['drop_in']),2)\n",
    "\n",
    "for iter,col in enumerate(VAF_cols):\n",
    "    vals = mdl_MC.coef_[iter,1]*range + mdl_MC.intercept_[iter]\n",
    "    ax.plot(range, vals, label=col)\n",
    "    ax.legend()\n",
    "    ax.scatter(log['drop_in'], log[col])\n",
    "    ax.set_xlabel('Input Dropout Percentage')\n",
    "    ax.set_ylabel('Coefficient of Determination')\n",
    "    ax.set_ylim([-.1, 1.1])\n",
    "    for spine in ['top','bottom','left','right']:\n",
    "        ax.spines[spine].set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "\n",
    "for col in VAF_cols:\n",
    "    ax.scatter(log['n_units'], log[col], label=col)\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./monte_carlo_log_30runs_4fxval.pkl','wb') as fid:\n",
    "          pickle.dump(log,fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = np.array([[1,2,3],[1,2,3],[1,2,3]], dtype=float)\n",
    "\n",
    "np.mean(aa, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_timestamps, train_firing, train_EMG, train_force, train_kin = load_josh_mat(data['WmTrain'])\n",
    "test_timestamps, test_firing, test_EMG, test_force, test_kin = load_josh_mat(data['WmTest'])\n",
    "\n",
    "\n",
    "layer_0_units = 200\n",
    "drop_in = .25     # input dropout percentage for LSTM layer\n",
    "drop_rec = .25    # recurrent dropout for LSTM\n",
    "drop_lay = .25    # dropout layer?\n",
    "\n",
    "# # input hyper params -- reshape input vector\n",
    "# batch_size = 64 # why not? will test to see training accuracy after\n",
    "# seq_len = train_firing.shape[0]//batch_size # splitting out the batches\n",
    "n_neurons = train_firing.shape[1] # number of neurons\n",
    "n_EMGs = train_EMG.shape[1]\n",
    "seq_len = 10\n",
    "rnn_train_i = np.zeros((train_firing.shape[0],seq_len, train_firing.shape[1]))\n",
    "rnn_test_i = np.zeros((test_firing.shape[0],seq_len, test_firing.shape[1]))\n",
    "rnn_train_o = train_EMG.to_numpy()\n",
    "rnn_test_o = test_EMG.to_numpy()\n",
    "\n",
    "# normalize the EMGs\n",
    "EMG_std = np.std(rnn_train_o, axis=0)\n",
    "for ii in np.arange(rnn_train_o.shape[1]):\n",
    "    rnn_train_o[:,ii] = rnn_train_o[:,ii]/EMG_std[ii]\n",
    "    rnn_test_o[:,ii] = rnn_test_o[:,ii]/EMG_std[ii]\n",
    "\n",
    "# create the sequences\n",
    "for ii in np.arange(10):\n",
    "    rnn_train_i[:,ii,:] = train_firing.shift(-ii, fill_value=0).to_numpy()\n",
    "    rnn_test_i[:,ii,:] = test_firing.shift(-ii, fill_value=0).to_numpy()\n",
    "\n",
    "# add the \"condition\" term\n",
    "conds_rng = np.random.default_rng()\n",
    "condition_train = conds_rng.choice(np.arange(4),(rnn_train_o.shape[0],1))\n",
    "# condition_train = np.ones((rnn_train_i.shape[0],1))\n",
    "rnn_train_o = np.append(rnn_train_o, condition_train, axis=-1)\n",
    "condition_test = np.ones((rnn_test_o.shape[0],1))\n",
    "rnn_test_o = np.append(rnn_test_o, condition_test, axis=-1)\n",
    "\n",
    "# Set up the LSTMs\n",
    "mdl = tf.keras.models.Sequential()\n",
    "\n",
    "\n",
    "\n",
    "mdl.add(tf.keras.layers.LSTM(layer_0_units, input_shape = (seq_len,n_neurons), dropout=drop_in, recurrent_dropout=drop_rec))\n",
    "if drop_lay:\n",
    "    mdl.add(tf.keras.layers.Dropout(drop_lay)) # dropout layer if wanted\n",
    "mdl.add(tf.keras.layers.Dense(rnn_train_o.shape[1], activation='relu')) # dense combination layer\n",
    "# mdl.add(tf.keras.layers.Dense(rnn_train_o.shape[1])) # dense combination layer\n",
    "mdl.compile(loss=vrex_loss, optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "mdl.fit(rnn_train_i, rnn_train_o, epochs=40, verbose=True, batch_size=128)\n",
    "\n",
    "\n",
    "train_pred = mdl.predict(rnn_train_i)[:,:-1]\n",
    "test_pred = mdl.predict(rnn_test_i)[:,:-1]\n",
    "train_VAFs = metrics.explained_variance_score(rnn_train_o[:,:-1], train_pred, multioutput='raw_values')\n",
    "test_VAFs = metrics.explained_variance_score(rnn_test_o[:,:-1], test_pred, multioutput='raw_values')\n",
    "\n",
    "print('----------------------------------------')\n",
    "for ii in np.arange(len(train_EMG.columns)):\n",
    "    print(train_EMG.columns[ii])\n",
    "    print(f\"\\tTrain VAF: {train_VAFs[ii]}\")\n",
    "    print(f\"\\tTest VAF: {test_VAFs[ii]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vREx loss function\n",
    "def vrex_loss(target, pred):\n",
    "    # from the Risk Extrapolation paper\n",
    "    B = 3 #\n",
    "    \n",
    "    err = target[:,:-1] - pred[:,:-1] # without the condition flag\n",
    "    se = K.square(err) # squared error\n",
    "    mse = K.mean(se, axis=-1) # mean squared error for each sample\n",
    "    \n",
    "    # now create a one-hot matrix for timestamps with a one for the appropriate condition\n",
    "    conditions = target[:,-1] # condition flag\n",
    "    u_conds,i_conds = tf.unique(conditions)\n",
    "    cond_oh = tf.transpose(tf.one_hot(i_conds, len(u_conds)))\n",
    "    \n",
    "    # risk for each condition -- ie MSE for each condition\n",
    "    risk = tf.matmul(cond_oh,se)\n",
    "    \n",
    "    rex = B*K.var(risk) + K.sum(risk)\n",
    "\n",
    "#     num_targets = K.shape(target)[1]//2 # number of cols / 2\n",
    "#     err = (target[:, 0:num_targets] - pred[:,0:num_targets]) # subtract the values\n",
    "#     se = K.square(err) * target[:,num_targets:] # multiply the square error by the gains\n",
    "#     mse = K.mean(se, axis=-1)\n",
    "    \n",
    "#     tf.print(mse.shape)\n",
    "\n",
    "\n",
    "    return rex\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dntxt.send('Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dntxt.notif_email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.today().strftime('%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted = False\n",
    "\n",
    "weight_str = 'weighted' if weighted else 'notweighted'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f'{\"weighted\" if weighted else \"notweighted\"}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('MSDS')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "e6f5ab44297089514ffa059ea0d83d6392bebfea7e191fb6b7f26c8412c9553b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
