{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM decoding exploration\n",
    "\n",
    "Going to be looking at using LSTMs (with potentially some changes to the cost function) to decode EMGs from cortical data. This is all based off work from Steph and Josh.\n",
    "\n",
    "\n",
    "Going to start with the old Jango data, then update from there as necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import loadmat\n",
    "from scipy.optimize import least_squares\n",
    "from matplotlib import pyplot as plt\n",
    "# import ipympl\n",
    "\n",
    "# we'll use ridge regression as a comparisson\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "from tkinter import Tk\n",
    "from tkinter import filedialog as fd # just so I don't have to repeatedly manually enter filenames\n",
    "\n",
    "# and tf stuff\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# request the filename\n",
    "root = Tk()\n",
    "mat_fn = fd.askopenfilename(master=root,filetypes=[('matlab data','*.mat')])\n",
    "root.destroy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different loading code if it's data from Josh vs XDS stuff\n",
    "\n",
    "**Josh**\n",
    "It looks like this will input a dictionary containing (among other things) numpy arrays for each of the datasets for the day. We'll pull in each of them, and parse accordingly.\n",
    "\n",
    "In the \"binned\" numpy arrays (two levels down), the organization seems to be:\n",
    "\n",
    "0. timestamps\n",
    "1. metadata\n",
    "2. EMG names\n",
    "3. EMG data\n",
    "4. Force names\n",
    "5. Force data\n",
    "6. electrode and unit number\n",
    "7. channel and unit number\n",
    "8. Firing Rates (in hz)\n",
    "9. Kin (cursor kin?) names\n",
    "10. Kin (cursor kin?) data\n",
    "11. Vel Data\n",
    "12. Vel Names\n",
    "13. Accel Data\n",
    "14. Accel Names\n",
    "15. Digital Words and timestamps\n",
    "16. Targets:\n",
    "\n",
    "    0. corner locations and appearance time \n",
    "    1. rotations and appearance time\n",
    "\n",
    "17. Trial table data\n",
    "18. Trial Table Labels\n",
    "19. \n",
    "20. \n",
    "21. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load it in\n",
    "data = loadmat(mat_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_josh_mat(curr_data):\n",
    "    timestamps = curr_data[0][0][0].reshape(-1)\n",
    "    # create a couple of pandas data frames -- this will make things a bit easier\n",
    "\n",
    "    # EMG\n",
    "    emg_names = [curr_data[0][0][2][ii][0][0] for ii in np.arange(4)]\n",
    "    EMG = pd.DataFrame(curr_data[0][0][3], columns=emg_names, index=timestamps)\n",
    "\n",
    "    # Forces\n",
    "    force_names = [curr_data[0][0][4][ii][0][0] for ii in np.arange(2)]\n",
    "    force = pd.DataFrame(curr_data[0][0][5], columns=force_names, index=timestamps)\n",
    "\n",
    "    # Firing Rates\n",
    "    channel_names = [f\"cc{row[0]:03d}ee{row[1]}\" for row in curr_data[0][0][7]]\n",
    "    firing = pd.DataFrame(curr_data[0][0][8], columns=channel_names, index=timestamps)\n",
    "\n",
    "    # Kin -- not sure if cursor or ang of wrist. Will need to check\n",
    "    kin_names = curr_data[0][0][9]\n",
    "    vel_names = curr_data[0][0][12]\n",
    "    acc_names = curr_data[0][0][14]\n",
    "    kin = pd.DataFrame(curr_data[0][0][10], columns=kin_names, index=timestamps)\n",
    "    kin = kin.join(pd.DataFrame(curr_data[0][0][11], columns=vel_names, index=timestamps))\n",
    "    kin = kin.join(pd.DataFrame(curr_data[0][0][13], columns=acc_names, index=timestamps))\n",
    "\n",
    "    # trial table\n",
    "    trial_names = curr_data[0][0][18]\n",
    "    trial_table = pd.DataFrame(curr_data[0][0][17], columns=trial_names)\n",
    "\n",
    "    return timestamps, firing, EMG, force, kin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load specific data\n",
    "train_timestamps, train_firing, train_EMG, train_force, train_kin = load_josh_mat(data['WmTrain'])\n",
    "test_timestamps, test_firing, test_EMG, test_force, test_kin = load_josh_mat(data['WmTest'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XDS:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model building \n",
    "Look through a couple of different model types, look to see how they are trained\n",
    "\n",
    "### linear models\n",
    "Going to just start with a basic Wiener filter with 10 lags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the lagged input for the wiener filter\n",
    "wiener_input = pd.DataFrame() # empty dataframe\n",
    "n_lags = 10 # number of lags\n",
    "for ii in np.arange(n_lags): # create the lagged dataframe\n",
    "    col_dict = dict(zip(train_firing.columns, train_firing.columns+f\"_lag{ii}\"))\n",
    "    wiener_input = wiener_input.join(train_firing.shift(-ii, fill_value=0).rename(columns=col_dict), how='outer')\n",
    "\n",
    "wiener_test = pd.DataFrame() # empty dataframe\n",
    "n_lags = 10 # number of lags\n",
    "for ii in np.arange(n_lags): # create the lagged dataframe\n",
    "    col_dict = dict(zip(test_firing.columns, test_firing.columns+f\"_lag{ii}\"))\n",
    "    wiener_test = wiener_test.join(test_firing.shift(-ii, fill_value=0).rename(columns=col_dict), how='outer')\n",
    "\n",
    "# build the model\n",
    "# mdl = linear_model.LinearRegression() # try with fitting the intersect. I think that's right...\n",
    "mdl = linear_model.Ridge() # try with ridge regression. Curious which works better\n",
    "mdl.fit(wiener_input, train_EMG)\n",
    "\n",
    "# predicted values\n",
    "emg_preds_train = mdl.predict(wiener_input)\n",
    "emg_preds_test = mdl.predict(wiener_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plotting the data\n",
    "fig_lin, ax_lin = plt.subplots(nrows=2, ncols=2, sharex=True, constrained_layout=True)\n",
    "\n",
    "ax_lin[0,0].plot(train_timestamps,emg_preds_train[:,0], label='Predicted')\n",
    "ax_lin[0,0].plot(train_timestamps, train_EMG.iloc[:,0], label='Recorded')\n",
    "ax_lin[0,0].set_title(f\"{train_EMG.columns[0]}   vaf: {metrics.r2_score(train_EMG.iloc[:,0], emg_preds_train[:,0])}\")\n",
    "_ = ax_lin[0,0].legend()\n",
    "\n",
    "ax_lin[1,0].plot(train_timestamps,emg_preds_train[:,1], label='Predicted')\n",
    "ax_lin[1,0].plot(train_timestamps, train_EMG.iloc[:,1], label='Recorded')\n",
    "ax_lin[1,0].set_title(f\"{train_EMG.columns[1]}   vaf: {metrics.r2_score(train_EMG.iloc[:,1], emg_preds_train[:,1])}\")\n",
    "_ = ax_lin[1,0].legend()\n",
    "\n",
    "ax_lin[0,1].plot(train_timestamps,emg_preds_train[:,2], label='Predicted')\n",
    "ax_lin[0,1].plot(train_timestamps, train_EMG.iloc[:,2], label='Recorded')\n",
    "ax_lin[0,1].set_title(f\"{train_EMG.columns[2]}   vaf: {metrics.r2_score(train_EMG.iloc[:,2], emg_preds_train[:,2])}\")\n",
    "_ = ax_lin[0,1].legend()\n",
    "\n",
    "ax_lin[1,1].plot(train_timestamps,emg_preds_train[:,3], label='Predicted')\n",
    "ax_lin[1,1].plot(train_timestamps, train_EMG.iloc[:,3], label='Recorded')\n",
    "ax_lin[1,1].set_title(f\"{train_EMG.columns[3]}   vaf: {metrics.r2_score(train_EMG.iloc[:,3], emg_preds_train[:,3])}\")\n",
    "_ = ax_lin[1,1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot test data\n",
    "fig_lin_test, ax_lin_test = plt.subplots(nrows=2, ncols=2, sharex=True, constrained_layout=True)\n",
    "\n",
    "ax_lin_test[0,0].plot(test_timestamps,emg_preds_test[:,0], label='Predicted')\n",
    "ax_lin_test[0,0].plot(test_timestamps, test_EMG.iloc[:,0], label='Recorded')\n",
    "ax_lin_test[0,0].set_title(f\"{test_EMG.columns[0]}   vaf: {metrics.r2_score(test_EMG.iloc[:,0], emg_preds_test[:,0])}\")\n",
    "_ = ax_lin_test[0,0].legend()\n",
    "\n",
    "ax_lin_test[1,0].plot(test_timestamps,emg_preds_test[:,1], label='Predicted')\n",
    "ax_lin_test[1,0].plot(test_timestamps, test_EMG.iloc[:,1], label='Recorded')\n",
    "ax_lin_test[1,0].set_title(f\"{test_EMG.columns[1]}   vaf: {metrics.r2_score(test_EMG.iloc[:,1], emg_preds_test[:,1])}\")\n",
    "_ = ax_lin_test[1,0].legend()\n",
    "\n",
    "ax_lin_test[0,1].plot(test_timestamps,emg_preds_test[:,2], label='Predicted')\n",
    "ax_lin_test[0,1].plot(test_timestamps, test_EMG.iloc[:,2], label='Recorded')\n",
    "ax_lin_test[0,1].set_title(f\"{test_EMG.columns[2]}   vaf: {metrics.r2_score(test_EMG.iloc[:,2], emg_preds_test[:,2])}\")\n",
    "_ = ax_lin_test[0,1].legend()\n",
    "\n",
    "ax_lin_test[1,1].plot(test_timestamps,emg_preds_test[:,3], label='Predicted')\n",
    "ax_lin_test[1,1].plot(test_timestamps, test_EMG.iloc[:,3], label='Recorded')\n",
    "ax_lin_test[1,1].set_title(f\"{test_EMG.columns[3]}   vaf: {metrics.r2_score(test_EMG.iloc[:,3], emg_preds_test[:,3])}\")\n",
    "_ = ax_lin_test[1,1].legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear with Static Non-linearity\n",
    "\n",
    "Using the lab default -- build a wiener filter, fit it, then fit with a static non-linearity on top of the form\n",
    "\n",
    "$Ax^2 + Bx + C$\n",
    "\n",
    "Where $x$ is the original EMG prediction, and the output is the new EMG prediction\n",
    "\n",
    "Also giving the options for a sigmoid or an exponential\n",
    "\n",
    "\n",
    "**Starting with defining our nonlinearity methods**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using scipy's least_squares:\n",
    "def non_linearity(p, y_pred, nonlinear_type='poly'):\n",
    "    if nonlinear_type == 'poly':\n",
    "        return p[0] + p[1]*y_pred + p[2]*y_pred**2\n",
    "    elif nonlinear_type == 'exponential':\n",
    "        return p[0]*np.exp(p[0]*y_pred)\n",
    "    elif nonlinear_type == 'sigmoid':\n",
    "        return 1/(1 + np.exp(-10*(y_pred-p[0])))\n",
    "\n",
    "def non_linearity_residuals(p, y_pred, y_act, nonlinear_type = 'poly'):\n",
    "    if nonlinear_type == 'poly':\n",
    "        return y_act - (p[0] + p[1]*y_pred + p[2]*y_pred**2)\n",
    "    elif nonlinear_type == 'exponential':\n",
    "        return y_act - (p[0]*np.exp(p[0]*y_pred))\n",
    "    elif nonlinear_type == 'sigmoid':\n",
    "        return y_act - (1/(1 + np.exp(-10*(y_pred-p[0]))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------\n",
      "FCU\n",
      "Linear VAF: 0.2428636333628813\n",
      "NonLinear VAF: 0.28435727716325243\n",
      "--------------------------------------------------------\n",
      "FCR\n",
      "Linear VAF: 0.38902871138196926\n",
      "NonLinear VAF: 0.45766021381275035\n",
      "--------------------------------------------------------\n",
      "ECU\n",
      "Linear VAF: 0.603803720176696\n",
      "NonLinear VAF: 0.6154105885380085\n",
      "--------------------------------------------------------\n",
      "ECR\n",
      "Linear VAF: 0.6643602223081486\n",
      "NonLinear VAF: 0.671607473081607\n"
     ]
    }
   ],
   "source": [
    "# n_poly = 4 # degree of the polynomial\n",
    "\n",
    "nonlinear_type = 'poly'\n",
    "\n",
    "\n",
    "if nonlinear_type == 'poly':\n",
    "    init_pred = [.1, .1, .1]\n",
    "elif nonlinear_type == 'exponential':\n",
    "    init_pred = [1, .1]\n",
    "elif nonlinear_type == 'sigmoid':\n",
    "    init_pred = .5\n",
    "\n",
    "mdl_A = linear_model.LinearRegression(fit_intercept=True)\n",
    "mdl_B = {} # a dictionary of numpy polynomials. Probably a better way to do this, maybe Xuan's method... oh well\n",
    "\n",
    "mdl_A.fit(wiener_input, train_EMG)# fit the first model\n",
    "prefit_EMG = mdl_A.predict(wiener_input) # get the initially predicted EMGs\n",
    "prefit_VAF = metrics.r2_score(train_EMG, prefit_EMG, multioutput='raw_values')\n",
    "## Polynomial\n",
    "# for ii in np.arange(len(train_EMG.columns)):\n",
    "#     muscle = train_EMG.columns[ii]\n",
    "#     mdl_B[muscle] = np.polynomial.Polynomial.fit(prefit_EMG[:,ii]-mdl_A.intercept_[ii], train_EMG.iloc[:,ii]-mdl_A.intercept_[ii], deg=n_poly)\n",
    "#     print('--------------------------------------------------------')\n",
    "#     print(muscle)\n",
    "#     print(f\"Linear VAF: {prefit_VAF[ii]}\")\n",
    "#     print(f\"NonLinear VAF: {metrics.r2_score(train_EMG.iloc[:,ii],mdl_B[muscle](prefit_EMG[:,ii])+mdl_A.intercept_[ii])}\")\n",
    "\n",
    "\n",
    "for ii in np.arange(len(train_EMG.columns)):\n",
    "    muscle = train_EMG.columns[ii]\n",
    "    mdl_B[muscle] = least_squares(non_linearity_residuals, init_pred, args=(prefit_EMG[:,ii], train_EMG.iloc[:,ii].to_numpy(), nonlinear_type))\n",
    "    print('--------------------------------------------------------')\n",
    "    print(muscle)\n",
    "    print(f\"Linear VAF: {prefit_VAF[ii]}\")\n",
    "    print(f\"NonLinear VAF: {metrics.r2_score(train_EMG.iloc[:,ii],non_linearity(mdl_B[muscle].x,(prefit_EMG[:,ii])))}\")\n",
    "\n",
    "# constants = least_squares(non_linearity_residuals, init_pred, args=(prefit_EMG, train_EMG.to_numpy(), nonlinear_type))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scratch Space\n",
    "Sometimes the variable viewer isn't very goood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['FCU', 'FCR', 'ECU', 'ECR'], dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_EMG.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f40f4536100>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig,ax = plt.subplots()\n",
    "\n",
    "ax.plot(train_timestamps, train_EMG.iloc[:,0], label='Recorded')\n",
    "ax.plot(train_timestamps, prefit_EMG[:,0], label='Initial Prediction')\n",
    "ax.plot(train_timestamps, non_linearity(mdl_B['FCR'].x, prefit_EMG[:,0], nonlinear_type='poly'), label='Non-Linear')\n",
    "ax.plot(train_timestamps, np.maximum(prefit_EMG[:,0],0))\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FCU': Polynomial([0.00471293, 0.03770044, 0.03273303, 0.00897191, 0.00289362], domain=[-0.0245153,  0.0378285], window=[-1.,  1.]),\n",
       " 'FCR': Polynomial([ 0.08630874,  0.38194568,  0.26566659, -0.12920942, -0.12850422], domain=[-0.14492297,  0.3105863 ], window=[-1.,  1.]),\n",
       " 'ECU': Polynomial([ 0.04329101,  0.21050704,  0.04779372, -0.03414433,  0.00754418], domain=[-0.13909213,  0.23013873], window=[-1.,  1.]),\n",
       " 'ECR': Polynomial([ 0.03006526,  0.15071669, -0.0271577 , -0.02642181,  0.10646176], domain=[-0.10976289,  0.16909328], window=[-1.,  1.])}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl_A.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00851   , 0.01367154, 0.01013622, ..., 0.011456  , 0.01201614,\n",
       "       0.00841201])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.maximum(prefit_EMG[:,0],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.94008562e-03, 8.89894491e-02, 3.33041735e+01])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl_B['FCU']['x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('generalDevelopment')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6255548a5b2d2cac3262c32979492d3f22144548184fa8e1a26df246eb3f6dca"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
