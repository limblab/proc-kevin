{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM decoding exploration\n",
    "\n",
    "Going to be looking at using LSTMs (with potentially some changes to the cost function) to decode EMGs from cortical data. This is all based off work from Steph and Josh.\n",
    "\n",
    "\n",
    "Going to start with the old Jango data, then update from there as necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-10 16:35:16.035132: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-08-10 16:35:16.035157: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import loadmat\n",
    "from scipy.optimize import least_squares\n",
    "from matplotlib import pyplot as plt\n",
    "# import ipympl\n",
    "\n",
    "# we'll use ridge regression as a comparisson\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "from tkinter import Tk\n",
    "from tkinter import filedialog as fd # just so I don't have to repeatedly manually enter filenames\n",
    "\n",
    "# and tf stuff\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# request the filename\n",
    "root = Tk()\n",
    "mat_fn = fd.askopenfilename(master=root,filetypes=[('matlab data','*.mat')])\n",
    "root.destroy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different loading code if it's data from Josh vs XDS stuff\n",
    "\n",
    "**Josh**\n",
    "It looks like this will input a dictionary containing (among other things) numpy arrays for each of the datasets for the day. We'll pull in each of them, and parse accordingly.\n",
    "\n",
    "In the \"binned\" numpy arrays (two levels down), the organization seems to be:\n",
    "\n",
    "0. timestamps\n",
    "1. metadata\n",
    "2. EMG names\n",
    "3. EMG data\n",
    "4. Force names\n",
    "5. Force data\n",
    "6. electrode and unit number\n",
    "7. channel and unit number\n",
    "8. Firing Rates (in hz)\n",
    "9. Kin (cursor kin?) names\n",
    "10. Kin (cursor kin?) data\n",
    "11. Vel Data\n",
    "12. Vel Names\n",
    "13. Accel Data\n",
    "14. Accel Names\n",
    "15. Digital Words and timestamps\n",
    "16. Targets:\n",
    "\n",
    "    0. corner locations and appearance time \n",
    "    1. rotations and appearance time\n",
    "\n",
    "17. Trial table data\n",
    "18. Trial Table Labels\n",
    "19. \n",
    "20. \n",
    "21. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load it in\n",
    "data = loadmat(mat_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_josh_mat(curr_data):\n",
    "    timestamps = curr_data[0][0][0].reshape(-1)\n",
    "    # create a couple of pandas data frames -- this will make things a bit easier\n",
    "\n",
    "    # EMG\n",
    "    emg_names = [curr_data[0][0][2][ii][0][0] for ii in np.arange(len(curr_data[0][0][2]))]\n",
    "    EMG = pd.DataFrame(curr_data[0][0][3], columns=emg_names, index=timestamps)\n",
    "\n",
    "    # Forces\n",
    "    force_names = [curr_data[0][0][4][ii][0][0] for ii in np.arange(len(curr_data[0][0][4]))]\n",
    "    force = pd.DataFrame(curr_data[0][0][5], columns=force_names, index=timestamps)\n",
    "\n",
    "    # Firing Rates\n",
    "    channel_names = [f\"cc{row[0]:03d}ee{row[1]}\" for row in curr_data[0][0][7]]\n",
    "    firing = pd.DataFrame(curr_data[0][0][8], columns=channel_names, index=timestamps)\n",
    "\n",
    "    # Kin -- not sure if cursor or ang of wrist. Will need to check\n",
    "    kin_names = curr_data[0][0][9]\n",
    "    vel_names = curr_data[0][0][12]\n",
    "    acc_names = curr_data[0][0][14]\n",
    "    kin = pd.DataFrame(curr_data[0][0][10], columns=kin_names, index=timestamps)\n",
    "    kin = kin.join(pd.DataFrame(curr_data[0][0][11], columns=vel_names, index=timestamps))\n",
    "    kin = kin.join(pd.DataFrame(curr_data[0][0][13], columns=acc_names, index=timestamps))\n",
    "\n",
    "    # trial table\n",
    "    trial_names = curr_data[0][0][18]\n",
    "    trial_table = pd.DataFrame(curr_data[0][0][17], columns=trial_names)\n",
    "\n",
    "    return timestamps, firing, EMG, force, kin\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XDS:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model building \n",
    "Look through a couple of different model types, look to see how they are trained\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear with Static Non-linearity\n",
    "\n",
    "Using the lab default -- build a wiener filter, fit it, then fit with a static polynomial on top of the form\n",
    "\n",
    "$Ax^2 + Bx + C$\n",
    "\n",
    "Where $x$ is the original EMG prediction, and the output is the new EMG prediction\n",
    "\n",
    "Alternatively, I have also allowed to predict using an exponential activation \n",
    "\n",
    "$Ae^{Bx} + C$\n",
    "\n",
    "Also giving the options for a sigmoid or an exponential\n",
    "\n",
    "\n",
    "**Starting with defining our nonlinearity methods**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using scipy's least_squares:\n",
    "def non_linearity(p, y_pred, nonlinear_type):\n",
    "    if nonlinear_type == 'poly':\n",
    "        return p[0] + p[1]*y_pred + p[2]*y_pred**2\n",
    "    elif nonlinear_type == 'exponential':\n",
    "        return p[0]*np.exp(p[1]*y_pred) + p[2]\n",
    "    elif nonlinear_type == 'sigmoid':\n",
    "        return p[1] * 1/(1 + np.exp(-10*(y_pred-p[0])))\n",
    "\n",
    "def non_linearity_residuals(p, y_pred, y_act, nonlinear_type):\n",
    "    if nonlinear_type == 'poly':\n",
    "        return y_act - (p[0] + p[1]*y_pred + p[2]*y_pred**2)\n",
    "    elif nonlinear_type == 'exponential':\n",
    "        return y_act - (p[0]*np.exp(p[1]*y_pred) + p[2])\n",
    "    elif nonlinear_type == 'sigmoid':\n",
    "        return y_act - (p[1] * 1/(1 + np.exp(-10*(y_pred-p[0]))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next a function that compares Wiener filter models with Wiener cascades, reports the VAF (Cooefficient of Determination) and gives plots for the validation predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a function that we can just call multiple times, so then we can just quickly run through all of the different combinations\n",
    "\n",
    "\n",
    "def basic_decoder_comparison(train_firing, train_EMG, test_firing, test_EMG, test_timestamps, nonlinear_type):\n",
    "    wiener_input = pd.DataFrame() # empty dataframe\n",
    "    n_lags = 10 # number of lags\n",
    "    for ii in np.arange(n_lags): # create the lagged dataframe\n",
    "        col_dict = dict(zip(train_firing.columns, train_firing.columns+f\"_lag{ii}\"))\n",
    "        wiener_input = wiener_input.join(train_firing.shift(-ii, fill_value=0).rename(columns=col_dict), how='outer')\n",
    "\n",
    "    wiener_test = pd.DataFrame() # empty dataframe\n",
    "    n_lags = 10 # number of lags\n",
    "    for ii in np.arange(n_lags): # create the lagged dataframe\n",
    "        col_dict = dict(zip(test_firing.columns, test_firing.columns+f\"_lag{ii}\"))\n",
    "        wiener_test = wiener_test.join(test_firing.shift(-ii, fill_value=0).rename(columns=col_dict), how='outer')\n",
    "\n",
    "\n",
    "\n",
    "    if nonlinear_type == 'poly':\n",
    "        init_pred = [.1, .1, .1]\n",
    "    elif nonlinear_type == 'exponential':\n",
    "        init_pred = [1, .1, .2]\n",
    "    elif nonlinear_type == 'sigmoid':\n",
    "        init_pred = [.1, .5]\n",
    "\n",
    "    mdl_A = linear_model.LinearRegression(fit_intercept=True)\n",
    "    mdl_B = {} # a dictionary of numpy polynomials. Probably a better way to do this, maybe Xuan's method... oh well\n",
    "\n",
    "    mdl_A.fit(wiener_input, train_EMG)# fit the first model\n",
    "    prefit_EMG = mdl_A.predict(wiener_input) # get the initially predicted EMGs\n",
    "    prefit_VAF = metrics.r2_score(train_EMG, prefit_EMG, multioutput='raw_values')\n",
    "    nonlin_EMG = np.zeros(prefit_EMG.shape)\n",
    "\n",
    "    print('Training Results\\n')\n",
    "\n",
    "    for ii in np.arange(len(train_EMG.columns)):\n",
    "        muscle = train_EMG.columns[ii]\n",
    "        mdl_B[muscle] = least_squares(non_linearity_residuals, init_pred, args=(prefit_EMG[:,ii], train_EMG.iloc[:,ii].to_numpy(), nonlinear_type)).x\n",
    "        # print('--------------------------------------------------------')\n",
    "        print(muscle)\n",
    "        print(f\"\\tLinear VAF: {prefit_VAF[ii]:.03f}\")\n",
    "        nonlin_EMG[:,ii] = non_linearity(mdl_B[muscle],(prefit_EMG[:,ii]), nonlinear_type)\n",
    "        print(f\"\\tNonLinear VAF: {metrics.r2_score(train_EMG.iloc[:,ii],nonlin_EMG[:,ii]):.03f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # predicting the test set\n",
    "    prefit_test = mdl_A.predict(wiener_test)\n",
    "    prefit_test_VAF = metrics.r2_score(test_EMG, prefit_test, multioutput='raw_values')\n",
    "    nonlin_test = np.zeros(prefit_test.shape)\n",
    "    nonlin_within_test = np.zeros(prefit_test.shape)\n",
    "    nonlin_VAF = np.zeros(prefit_test_VAF.shape)\n",
    "    nonlin_within_VAF = np.zeros(prefit_test_VAF.shape)\n",
    "    mdl_C = {} # for a separate non-linearity, built for the second condition.\n",
    "\n",
    "    print('\\n------------------------------------------------------------\\n')\n",
    "    print('Testing Results\\n')\n",
    "    for ii in np.arange(len(train_EMG.columns)):\n",
    "        muscle = test_EMG.columns[ii]\n",
    "        mdl_C[muscle] = least_squares(non_linearity_residuals, init_pred, args=(prefit_test[:,ii], test_EMG.iloc[:,ii].to_numpy(), nonlinear_type)).x\n",
    "        # print('--------------------------------------------------------')\n",
    "        print(muscle)\n",
    "        print(f\"\\tLinear VAF: {prefit_test_VAF[ii]:.03f}\")\n",
    "        nonlin_test[:,ii] = non_linearity(mdl_B[muscle],(prefit_test[:,ii]), nonlinear_type)\n",
    "        nonlin_within_test[:,ii] = non_linearity(mdl_C[muscle],(prefit_test[:,ii]), nonlinear_type)\n",
    "        nonlin_VAF[ii] = metrics.r2_score(test_EMG.iloc[:,ii],nonlin_test[:,ii])\n",
    "        nonlin_within_VAF[ii] = metrics.r2_score(test_EMG.iloc[:,ii],nonlin_within_test[:,ii])\n",
    "        print(f\"\\tPre-built Nonlinearity VAF: {nonlin_VAF[ii]:.03f}\")\n",
    "        print(f\"\\tRe-built Nonlinearity VAF: {nonlin_within_VAF[ii]:.03f}\")\n",
    "\n",
    "    # Plotting the test data -- so that we can see how  the non-linearities act between types\n",
    "    n_rows = int(np.ceil(np.sqrt(len(train_EMG.columns))))\n",
    "    fig_nl_test, ax_nl_test = plt.subplots(nrows=n_rows, ncols=n_rows, sharex=True, constrained_layout=True)\n",
    "\n",
    "    for muscle_ii in np.arange(len(train_EMG.columns)):\n",
    "        row_i = int(muscle_ii//n_rows)\n",
    "        col_i = int(muscle_ii%n_rows)\n",
    "        ax_nl_test[row_i,col_i].plot(test_timestamps, test_EMG.iloc[:,muscle_ii], label='Recorded')\n",
    "        ax_nl_test[row_i,col_i].plot(test_timestamps,prefit_test[:,muscle_ii], label=f'Linear VAF: {prefit_test_VAF[muscle_ii]:.03f}')\n",
    "        ax_nl_test[row_i,col_i].plot(test_timestamps,nonlin_test[:,muscle_ii], label=f'NonLin VAF: {nonlin_VAF[muscle_ii]:.03f}')\n",
    "        ax_nl_test[row_i,col_i].plot(test_timestamps,nonlin_within_test[:,muscle_ii], label=f'Rebuilt NonLin VAF: {nonlin_within_VAF[muscle_ii]:.03f}')\n",
    "        ax_nl_test[row_i,col_i].set_title(f\"{test_EMG.columns[muscle_ii]}\")\n",
    "        _ = ax_nl_test[row_i,col_i].legend()\n",
    "\n",
    "        # turn off the spines\n",
    "        for spine in ['right','top','bottom','left']:\n",
    "            ax_nl_test[row_i,col_i].spines[spine].set_visible(False)\n",
    "\n",
    "    # let's also plot the VAFs in a clean manner so that it's easy to compare\n",
    "    fig_vaf, ax_vaf = plt.subplots()\n",
    "    i_muscles = np.arange(len(test_EMG.columns)) # indexing on the x axis\n",
    "    bar_width = .25\n",
    "\n",
    "    ax_vaf.bar(i_muscles, prefit_test_VAF, width = bar_width, label='Linear')\n",
    "    ax_vaf.bar(i_muscles + bar_width, nonlin_VAF, width = bar_width, label='Nonlinear')\n",
    "    ax_vaf.bar(i_muscles + 2*bar_width, nonlin_within_VAF, width = bar_width, label='Rebuilt Nonlinear')\n",
    "\n",
    "    ax_vaf.set_xticks(i_muscles + 1*bar_width)\n",
    "    ax_vaf.set_xticklabels(test_EMG.columns)\n",
    "\n",
    "    ax_vaf.set_ylim([-.05, 1.05])\n",
    "    ax_vaf.set_xlabel('Muscle')\n",
    "    ax_vaf.set_ylabel('Coefficient of Determination')\n",
    "\n",
    "    ax_vaf.legend()\n",
    "\n",
    "    # For each bar in the chart, add a text label.\n",
    "    for bar in ax_vaf.patches:\n",
    "        # The text annotation for each bar should be its height.\n",
    "        bar_value = bar.get_height()\n",
    "        # Format the text with commas to separate thousands. You can do\n",
    "        # any type of formatting here though.\n",
    "        text = f'{bar_value:.02f}'\n",
    "        # This will give the middle of each bar on the x-axis.\n",
    "        text_x = bar.get_x() + bar.get_width() / 2\n",
    "        # get_y() is where the bar starts so we add the height to it.\n",
    "        text_y = np.max([bar.get_y() + bar_value, 0.01]) # keep it from going too far below zero, and disappearing\n",
    "        # If we want the text to be the same color as the bar, we can\n",
    "        # get the color like so:\n",
    "        bar_color = bar.get_facecolor()\n",
    "        # If you want a consistent color, you can just set it as a constant, e.g. #222222\n",
    "        ax_vaf.text(text_x, text_y, text, ha='center', va='bottom', color=bar_color,\n",
    "                size=12)\n",
    "\n",
    "    # turn off the spines\n",
    "    for spine in ['right','top','bottom','left']:\n",
    "        ax_vaf.spines[spine].set_visible(False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare different combinations of train/test sets\n",
    "\n",
    "So that we can quickly run through all of the iterations\n",
    "\n",
    "Set the nonlinearity type, to compare across iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonlinear_type = 'poly'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "First train wrist movement, test wrist movement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results\n",
      "\n",
      "FCU\n",
      "\tLinear VAF: 0.370\n",
      "\tNonLinear VAF: 0.431\n",
      "ECU\n",
      "\tLinear VAF: 0.623\n",
      "\tNonLinear VAF: 0.665\n",
      "ECR\n",
      "\tLinear VAF: 0.736\n",
      "\tNonLinear VAF: 0.738\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "Testing Results\n",
      "\n",
      "FCU\n",
      "\tLinear VAF: 0.148\n",
      "\tPre-built Nonlinearity VAF: 0.245\n",
      "\tRe-built Nonlinearity VAF: 0.286\n",
      "ECU\n",
      "\tLinear VAF: 0.572\n",
      "\tPre-built Nonlinearity VAF: 0.651\n",
      "\tRe-built Nonlinearity VAF: 0.661\n",
      "ECR\n",
      "\tLinear VAF: 0.707\n",
      "\tPre-built Nonlinearity VAF: 0.710\n",
      "\tRe-built Nonlinearity VAF: 0.711\n"
     ]
    }
   ],
   "source": [
    "train_timestamps, train_firing, train_EMG, train_force, train_kin = load_josh_mat(data['WmTrain'])\n",
    "test_timestamps, test_firing, test_EMG, test_force, test_kin = load_josh_mat(data['WmTest'])\n",
    "basic_decoder_comparison(train_firing, train_EMG, test_firing, test_EMG, test_timestamps, nonlinear_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train wrist movement, test iso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_timestamps, train_firing, train_EMG, train_force, train_kin = load_josh_mat(data['WmTrain'])\n",
    "test_timestamps, test_firing, test_EMG, test_force, test_kin = load_josh_mat(data['IsoTest'])\n",
    "basic_decoder_comparison(train_firing, train_EMG, test_firing, test_EMG, test_timestamps, nonlinear_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Iso, test Iso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_timestamps, train_firing, train_EMG, train_force, train_kin = load_josh_mat(data['IsoTrain'])\n",
    "test_timestamps, test_firing, test_EMG, test_force, test_kin = load_josh_mat(data['IsoTest'])\n",
    "basic_decoder_comparison(train_firing, train_EMG, test_firing, test_EMG, test_timestamps, nonlinear_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Iso, test WM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_timestamps, train_firing, train_EMG, train_force, train_kin = load_josh_mat(data['IsoTrain'])\n",
    "test_timestamps, test_firing, test_EMG, test_force, test_kin = load_josh_mat(data['WmTest'])\n",
    "basic_decoder_comparison(train_firing, train_EMG, test_firing, test_EMG, test_timestamps, nonlinear_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hybrid 3 -- this should be a blend of all three, I think for training\n",
    "train_timestamps, train_firing, train_EMG, train_force, train_kin = load_josh_mat(data['Hybrid3'])\n",
    "test_timestamps, test_firing, test_EMG, test_force, test_kin = load_josh_mat(data['WmTest'])\n",
    "basic_decoder_comparison(train_firing, train_EMG, test_firing, test_EMG, test_timestamps, nonlinear_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM\n",
    "\n",
    "Time to look at some non-linearities!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'builtin_function_or_method' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_27576/3982952474.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mn_neurons\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_firing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# number of neurons\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mrnn_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_firing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtime_len\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtime_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_neurons\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'builtin_function_or_method' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# hyper params\n",
    "layer_0_units = 200\n",
    "drop_in = 0     # input dropout percentage for LSTM layer\n",
    "drop_rec = 0    # recurrent dropout for LSTM\n",
    "drop_lay = 0    # dropout layer?\n",
    "\n",
    "# input hyper params -- reshape input vector\n",
    "batch_size = 64 # why not? will test to see training accuracy after\n",
    "time_len = train_firing.shape[0]//batch_size # splitting out the batches\n",
    "n_neurons = train_firing.shape[1] # number of neurons\n",
    "\n",
    "rnn_train = train_firing.iloc[:time_len*batch_size,:].values.reshape[time_len, batch_size, n_neurons]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Set up the LSTMs\n",
    "mdl = tf.keras.models.Sequential()\n",
    "\n",
    "mdl.add(tf.keras.layers.LSTM(layer_0_units, input_shape = ))\n",
    "if drop_lay:\n",
    "    mdl.add(layer_drop = tf.keras.layers.Dropout(drop_lay)) # dropout layer if wanted\n",
    "mdl.add(layer_1 = tf.keras.layers.Dense(1, init='uniform')) # dense combination layer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scratch Space\n",
    "Sometimes the variable viewer isn't very goood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting bits of code to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the lagged input for the wiener filter\n",
    "wiener_input = pd.DataFrame() # empty dataframe\n",
    "n_lags = 10 # number of lags\n",
    "for ii in np.arange(n_lags): # create the lagged dataframe\n",
    "    col_dict = dict(zip(train_firing.columns, train_firing.columns+f\"_lag{ii}\"))\n",
    "    wiener_input = wiener_input.join(train_firing.shift(-ii, fill_value=0).rename(columns=col_dict), how='outer')\n",
    "\n",
    "wiener_test = pd.DataFrame() # empty dataframe\n",
    "n_lags = 10 # number of lags\n",
    "for ii in np.arange(n_lags): # create the lagged dataframe\n",
    "    col_dict = dict(zip(test_firing.columns, test_firing.columns+f\"_lag{ii}\"))\n",
    "    wiener_test = wiener_test.join(test_firing.shift(-ii, fill_value=0).rename(columns=col_dict), how='outer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# n_poly = 4 # degree of the polynomial\n",
    "\n",
    "nonlinear_type = 'poly'\n",
    "# nonlinear_type = 'exponential'\n",
    "# nonlinear_type = 'sigmoid'\n",
    "\n",
    "\n",
    "if nonlinear_type == 'poly':\n",
    "    init_pred = [.1, .1, .1]\n",
    "elif nonlinear_type == 'exponential':\n",
    "    init_pred = [1, .1, .2]\n",
    "elif nonlinear_type == 'sigmoid':\n",
    "    init_pred = [.1, .5]\n",
    "\n",
    "mdl_A = linear_model.LinearRegression(fit_intercept=True)\n",
    "mdl_B = {} # a dictionary of numpy polynomials. Probably a better way to do this, maybe Xuan's method... oh well\n",
    "\n",
    "mdl_A.fit(wiener_input, train_EMG)# fit the first model\n",
    "prefit_EMG = mdl_A.predict(wiener_input) # get the initially predicted EMGs\n",
    "prefit_VAF = metrics.r2_score(train_EMG, prefit_EMG, multioutput='raw_values')\n",
    "nonlin_EMG = np.zeros(prefit_EMG.shape)\n",
    "\n",
    "for ii in np.arange(len(train_EMG.columns)):\n",
    "    muscle = train_EMG.columns[ii]\n",
    "    mdl_B[muscle] = least_squares(non_linearity_residuals, init_pred, args=(prefit_EMG[:,ii], train_EMG.iloc[:,ii].to_numpy(), nonlinear_type))\n",
    "    print('--------------------------------------------------------')\n",
    "    print(muscle)\n",
    "    print(f\"Linear VAF: {prefit_VAF[ii]}\")\n",
    "    nonlin_EMG[:,ii] = non_linearity(mdl_B[muscle].x,(prefit_EMG[:,ii]), nonlinear_type)\n",
    "    print(f\"NonLinear VAF: {metrics.r2_score(train_EMG.iloc[:,ii],nonlin_EMG[:,ii])}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting the test set\n",
    "prefit_test = mdl_A.predict(wiener_test)\n",
    "prefit_test_VAF = metrics.r2_score(test_EMG, prefit_test, multioutput='raw_values')\n",
    "nonlin_test = np.zeros(prefit_test.shape)\n",
    "\n",
    "for ii in np.arange(len(train_EMG.columns)):\n",
    "    muscle = test_EMG.columns[ii]\n",
    "    print('--------------------------------------------------------')\n",
    "    print(muscle)\n",
    "    print(f\"Linear VAF: {prefit_test_VAF[ii]}\")\n",
    "    nonlin_test[:,ii] = non_linearity(mdl_B[muscle].x,(prefit_test[:,ii]), nonlinear_type)\n",
    "    print(f\"NonLinear VAF: {metrics.r2_score(test_EMG.iloc[:,ii],nonlin_test[:,ii])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_lin, ax_lin = plt.subplots(nrows=2, ncols=2, sharex=True, constrained_layout=True)\n",
    "\n",
    "\n",
    "ax_lin[0,0].plot(train_timestamps,emg_preds_train[:,0], label='Predicted')\n",
    "ax_lin[0,0].plot(train_timestamps, train_EMG.iloc[:,0], label='Recorded')\n",
    "ax_lin[0,0].set_title(f\"{train_EMG.columns[0]}   vaf: {metrics.r2_score(train_EMG.iloc[:,0], emg_preds_train[:,0])}\")\n",
    "_ = ax_lin[0,0].legend()\n",
    "\n",
    "ax_lin[1,0].plot(train_timestamps,emg_preds_train[:,1], label='Predicted')\n",
    "ax_lin[1,0].plot(train_timestamps, train_EMG.iloc[:,1], label='Recorded')\n",
    "ax_lin[1,0].set_title(f\"{train_EMG.columns[1]}   vaf: {metrics.r2_score(train_EMG.iloc[:,1], emg_preds_train[:,1])}\")\n",
    "_ = ax_lin[1,0].legend()\n",
    "\n",
    "ax_lin[0,1].plot(train_timestamps,emg_preds_train[:,2], label='Predicted')\n",
    "ax_lin[0,1].plot(train_timestamps, train_EMG.iloc[:,2], label='Recorded')\n",
    "ax_lin[0,1].set_title(f\"{train_EMG.columns[2]}   vaf: {metrics.r2_score(train_EMG.iloc[:,2], emg_preds_train[:,2])}\")\n",
    "_ = ax_lin[0,1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot test data\n",
    "fig_lin_test, ax_lin_test = plt.subplots(nrows=2, ncols=2, sharex=True, constrained_layout=True)\n",
    "\n",
    "ax_lin_test[0,0].plot(test_timestamps,emg_preds_test[:,0], label='Predicted')\n",
    "ax_lin_test[0,0].plot(test_timestamps, test_EMG.iloc[:,0], label='Recorded')\n",
    "ax_lin_test[0,0].set_title(f\"{test_EMG.columns[0]}   vaf: {metrics.r2_score(test_EMG.iloc[:,0], emg_preds_test[:,0])}\")\n",
    "_ = ax_lin_test[0,0].legend()\n",
    "\n",
    "ax_lin_test[1,0].plot(test_timestamps,emg_preds_test[:,1], label='Predicted')\n",
    "ax_lin_test[1,0].plot(test_timestamps, test_EMG.iloc[:,1], label='Recorded')\n",
    "ax_lin_test[1,0].set_title(f\"{test_EMG.columns[1]}   vaf: {metrics.r2_score(test_EMG.iloc[:,1], emg_preds_test[:,1])}\")\n",
    "_ = ax_lin_test[1,0].legend()\n",
    "\n",
    "ax_lin_test[0,1].plot(test_timestamps,emg_preds_test[:,2], label='Predicted')\n",
    "ax_lin_test[0,1].plot(test_timestamps, test_EMG.iloc[:,2], label='Recorded')\n",
    "ax_lin_test[0,1].set_title(f\"{test_EMG.columns[2]}   vaf: {metrics.r2_score(test_EMG.iloc[:,2], emg_preds_test[:,2])}\")\n",
    "_ = ax_lin_test[0,1].legend()\n",
    "\n",
    "# ax_lin_test[1,1].plot(test_timestamps,emg_preds_test[:,3], label='Predicted')\n",
    "# ax_lin_test[1,1].plot(test_timestamps, test_EMG.iloc[:,3], label='Recorded')\n",
    "# ax_lin_test[1,1].set_title(f\"{test_EMG.columns[3]}   vaf: {metrics.r2_score(test_EMG.iloc[:,3], emg_preds_test[:,3])}\")\n",
    "# _ = ax_lin_test[1,1].legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig_nl, ax_nl = plt.subplots(nrows=2, ncols=2, sharex=True, constrained_layout=True)\n",
    "\n",
    "\n",
    "ax_nl[0,0].plot(train_timestamps, train_EMG.iloc[:,0], label='Recorded')\n",
    "ax_nl[0,0].plot(train_timestamps,emg_preds_train[:,0], label='Initial Predicted')\n",
    "ax_nl[0,0].plot(train_timestamps,nonlin_EMG[:,0], label='NonLin Predicted')\n",
    "ax_nl[0,0].set_title(f\"{train_EMG.columns[0]}   vaf: {metrics.r2_score(train_EMG.iloc[:,0], nonlin_EMG[:,0])}\")\n",
    "_ = ax_nl[0,0].legend()\n",
    "\n",
    "ax_nl[1,0].plot(train_timestamps, train_EMG.iloc[:,1], label='Recorded')\n",
    "ax_nl[1,0].plot(train_timestamps,emg_preds_train[:,1], label='Initial Predicted')\n",
    "ax_nl[1,0].plot(train_timestamps,nonlin_EMG[:,1], label='NonLin Predicted')\n",
    "ax_nl[1,0].set_title(f\"{train_EMG.columns[1]}   vaf: {metrics.r2_score(train_EMG.iloc[:,1], nonlin_EMG[:,1])}\")\n",
    "_ = ax_nl[1,0].legend()\n",
    "\n",
    "ax_nl[0,1].plot(train_timestamps, train_EMG.iloc[:,2], label='Recorded')\n",
    "ax_nl[0,1].plot(train_timestamps,emg_preds_train[:,2], label='Initial Predicted')\n",
    "ax_nl[0,1].plot(train_timestamps,nonlin_EMG[:,2], label='NonLin Predicted')\n",
    "ax_nl[0,1].set_title(f\"{train_EMG.columns[2]}   vaf: {metrics.r2_score(train_EMG.iloc[:,2], nonlin_EMG[:,2])}\")\n",
    "_ = ax_nl[0,1].legend()\n",
    "\n",
    "# turn off the spines\n",
    "for axis in ax_nl.flat:\n",
    "    for spine in ['right','top','bottom','left']:\n",
    "        axis.spines[spine].set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plotting the test data -- so that we can see how  the non-linearities act between types\n",
    "fig_nl_test, ax_nl_test = plt.subplots(nrows=2, ncols=2, sharex=True, constrained_layout=True)\n",
    "\n",
    "muscle_ii = 0\n",
    "for axis in ax_nl_test.flatten():\n",
    "    axis.plot(test_timestamps, test_EMG.iloc[:,ii], label='Recorded')\n",
    "    axis.plot(test_timestamps,prefit_test[:,ii], label=f'Linear VAF: {prefit_test_VAF[ii]}')\n",
    "    axis.plot(test_timestamps,nonlin_test[:,ii], label=f'NonLin VAF: {nonlin_VAF[ii]}')\n",
    "    axis.plot(test_timestamps,nonlin_within_test[:,ii], label=f'Rebuilt NonLin VAF: {nonlin_within_VAF[ii]}')\n",
    "    axis.set_title(f\"{test_EMG.columns[ii]}\")\n",
    "    _ = axis.legend()\n",
    "\n",
    "    # turn off the spines\n",
    "    for spine in ['right','top','bottom','left']:\n",
    "        axis.spines[spine].set_visible(False)\n",
    "    \n",
    "    muscle_ii += 1\n",
    "    if muscle_ii == len(test_EMG.columns):\n",
    "        break # if we've plotted all of the muscles we hav\n",
    "# ax_nl_test[0,0].plot(test_timestamps, test_EMG.iloc[:,0], label='Recorded')\n",
    "# ax_nl_test[0,0].plot(test_timestamps,prefit_test[:,0], label='Linear Predicted')\n",
    "# ax_nl_test[0,0].plot(test_timestamps,nonlin_test[:,0], label='NonLin Predicted')\n",
    "# ax_nl_test[0,0].set_title(f\"{test_EMG.columns[0]}   vaf: {metrics.r2_score(test_EMG.iloc[:,0], nonlin_test[:,0])}\")\n",
    "# _ = ax_nl_test[0,0].legend()\n",
    "\n",
    "# ax_nl_test[1,0].plot(test_timestamps, test_EMG.iloc[:,1], label='Recorded')\n",
    "# ax_nl_test[1,0].plot(test_timestamps,prefit_test[:,1], label='Linear Predicted')\n",
    "# ax_nl_test[1,0].plot(test_timestamps,nonlin_test[:,1], label='NonLin Predicted')\n",
    "# ax_nl_test[1,0].set_title(f\"{test_EMG.columns[1]}   vaf: {metrics.r2_score(test_EMG.iloc[:,1], nonlin_test[:,1])}\")\n",
    "# _ = ax_nl_test[1,0].legend()\n",
    "\n",
    "# ax_nl_test[0,1].plot(test_timestamps, test_EMG.iloc[:,2], label='Recorded')\n",
    "# ax_nl_test[0,1].plot(test_timestamps,prefit_test[:,2], label='Linear Predicted')\n",
    "# ax_nl_test[0,1].plot(test_timestamps,nonlin_test[:,2], label='NonLin Predicted')\n",
    "# ax_nl_test[0,1].set_title(f\"{test_EMG.columns[2]}   vaf: {metrics.r2_score(test_EMG.iloc[:,2], nonlin_test[:,2])}\")\n",
    "# _ = ax_nl_test[0,1].legend()\n",
    "\n",
    "\n",
    "# # turn off the spines\n",
    "# for axis in ax_nl_test.flat:\n",
    "#     for spine in ['right','top','bottom','left']:\n",
    "#         axis.spines[spine].set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[array(['FCU'], dtype='<U3')],\n",
       "       [array(['ECU'], dtype='<U3')],\n",
       "       [array(['ECR'], dtype='<U3')]], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['WmBinned'][0][0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "187"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_firing.shape[0]//64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12000, 75)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_firing.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,  40,   0, ...,  20,   0,  40],\n",
       "       [  0,  80,   0, ...,  60,   0,  60],\n",
       "       [  0, 100,   0, ...,  20,   0,  20],\n",
       "       ...,\n",
       "       [  0,  60,   0, ...,  20,   0,  20],\n",
       "       [  0,  20,   0, ...,  20,   0,  20],\n",
       "       [  0,  20,   0, ...,  20,   0,  60]], dtype=uint8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_firing.iloc[:time_len*batch_size,:].values.reshape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(187, 64, 75)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "6255548a5b2d2cac3262c32979492d3f22144548184fa8e1a26df246eb3f6dca"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
